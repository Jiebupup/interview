1.线程状态
新建（New）
可运行（Runnable）：包含了操作系统线程状态中的 Running 和 Ready，可能正在运行或正在等待 CPU 时间片
阻塞（Blocked）：等待获取一个排它锁，如果其线程释放了锁就会结束此状态

等待（Waiting）：等待其它线程显式地唤醒。
进入方法：没有设置Timeout参数的Object.wait()或Thread.join()，LockSupport.park()。
退出方法：Object.notify() / Object.notifyAll()或Thread.join() 的线程执行完毕，LockSupport.unpark(Thread)

计时等待（Timed Waiting）：在指定的时间自行返回
进入方法：Thread.sleep()，设置了 Timeout 参数的 Object.wait()，设置了 Timeout 参数的 Thread.join()，LockSupport.parkNanos()，LockSupport.parkUntil()。
退出方法：时间结束，时间结束 / Object.notify() / Object.notifyAll()，时间结束 / 被调用的线程执行完毕，LockSupport.unpark(Thread)。

中止（Terminated）：线程自己结束任务，或者产生了异常而结束

Thread.sleep()线程睡眠，进入限期等待状态
Object.wait()挂起线程，进入限期等待或者无限期等待
sleep() 方法和 wait() 方法区别点：
1.两者最主要的区别在于：sleep 方法没有释放锁，而 wait 方法释放了锁 。
2.Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。
3.wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。

阻塞和等待的区别在于，阻塞是被动的，它是在等待获取一个排它锁。而等待是主动的，通过调用 Thread.sleep() 和 Object.wait() 等方法进入。

start()和run()的区别？
start()启动线程并使线程进入Runnable状态，一旦得到cpu时间片就开始执行相应线程的run()。这里的run()称为线程体，它包含了要执行的这个线程的内容，run()运行结束，此线程随即终止。用start方法来启动线程，真正实现了多线程运行，即无需等待某个线程的run方法体代码执行完毕就直接继续执行下面的代码。
run()当作普通方法的方式调用，程序还是要顺序执行，还是要等待run方法体执行完毕后才可继续执行下面的代码。如果直接调用run方法，并不会启动新线程，在主线程里执行。
start()不能被重复调用。run()可以被重复调用。

上下文切换：多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用。
Linux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。

volatile变量：保证变量的可见性，防止 JVM 的指令重排。对volatile变量的写操作先行发生happen-before后续的读操作（写入volatile变量相当于退出同步代码块，读取volatile变量相当于进入同步代码块）。
内存可见性:也就是每个线程获取的volatile变量都是最新值；并且每个线程对volatile变量的修改，都直接刷新到主存。
多线程访问volatile关键字不会发生阻塞。
volatile关键字能保证数据的可见性和有序性，但不能保证数据的原子性。

volatile的底层是通过lock前缀指令，相当于内存屏障（一组CPU处理指令）。内存屏障提供三个功能：
用来实现对内存操作的顺序限制（在执行到内存屏障这句指令时，在它前面的操作已经全部完成）。
强制将对缓存的修改操作立即写入主存。
如果是写操作，它会导致其他CPU中对应的缓存行无效。

多CPU的嗅探机制:缓存本身是独立的，但是内存是共享资源，所有的内存访问都要经过仲裁（同一个指令周期中，只有一个CPU缓存可以读写内存）。
CPU缓存不仅仅在做内存传输的时候才与总线打交道，而是不停在嗅探总线上发生的数据交换，跟踪其他缓存在做什么。所以当一个缓存代表它所属的处理器去读写内存时，其它处理器都会得到通知，它们以此来使自己的缓存保持同步。只要某个处理器一写内存，其它处理器马上知道这块内存在它们的缓存段中已失效。

Cache一致性协议之MESI：每个Cache的Cache控制器不仅知道自己的读写操作，而且也监听(snoop)其它Cache的读写操作。每个Cache line所处的状态根据本核和其它核的读写操作在4个状态间进行迁移。
每个Cache line有4个状态：
Modified：数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。数据是dirty的(和内存的不一致)。
Exclusive：数据和内存中的数据一致，数据只存在于本Cache中。数据是clean的(和内存的一致)。
Shared：数据和内存中的数据一致，数据存在于很多Cache中。只有clean的数据才能被多个Cache共享。
Invalid：这行数据无效。

AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。

2.使用线程
实现 Runnable 接口；
实现 Callable 接口；
两者的区别在于 Runnable 接口不会返回结果但是 Callable 接口有通过 Future 进行封装的返回值。
实现 Runnable 和 Callable 接口的类只能当做一个可以在线程中运行的任务，最后还需要通过 Thread 来调用。

Future接口：表示异步计算的结果，可以进行取消、查询是否完成、获取结果的操作。
FutureTask是一个可执行的异步对象：FutureTask 实现了 RunnableFuture 接口，该接口继承自 Runnable 和 Future 接口，这使得 FutureTask 既可以当做一个任务执行，也可以有返回值。
FutureTask 可用于异步获取执行结果或取消执行任务的场景。当一个计算任务需要执行很长时间，那么就可以用 FutureTask 来封装这个任务，主线程在完成自己的任务之后再去获取结果。

execute() 方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；submit() 方法用于提交需要返回值的任务。线程池会返回一个Future类型的对象，通过这个Future对象可以判断任务是否执行成功。
工具类Executors可以实现Runnable对象和Callable对象之间的相互转换。

继承 Thread 类。
ThreadLocal类：访问这个本地线程变量的每个线程都会有这个变量的本地副本，从而避免了线程安全问题。
ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用,而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候会 key 会被清理掉，而 value 不会被清理掉。

3.基础线程机制
Executor简化任务与线程的生命周期管理，将任务的提交和执行解耦，基于生产者-消费者模式，管理多个异步任务的执行。
ExecutorService接口实现了Executor接口，有两个实现：抽象类AbstractExecutorService和接口ScheduledExecutorService。
ThreadPoolExecutor继承了AbstractExecutorService，是线程池的真正实现。

线程池：
管理一组同构工作线程的资源池。线程池过大会使大量的线程CPU和内存资源上竞争，过小会空闲降低吞吐率。使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务。
线程池状态
RUNNING：当创建线程池后，初始时，线程池处于RUNNING状态；
SHUTDOWN：如果调用了shutdown()方法，则线程池处于SHUTDOWN状态，此时线程池不能够接受新的任务，它会等待所有任务执行完毕；
STOP：如果调用了shutdownNow()方法，则线程池处于STOP状态，此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务；
TERMINATED：当线程池处于SHUTDOWN或STOP状态，并且所有工作线程已经销毁，任务缓存队列已经清空或执行结束后，线程池被设置为TERMINATED状态。

任务提交给线程池
poolSize：线程池中当前线程的数量。
corePoolSize核心池大小：在没有任务需要执行的时候线程池的大小，并且只有在工作队列满了的情况下才会创建超出这个数量的线程。
maximumPoolSize最大池大小：线程池中允许的最大线程数，线程池中的当前线程数目不会超过该值。

如果poolSize<corePoolSize，新增加一个线程处理新的任务。
如果poolSize=corePoolSize，新任务会被放入阻塞队列等待。
如果阻塞队列的容量达到上限，且这时poolSize<maximumPoolSize，新增线程来处理任务。
如果阻塞队列满了，且poolSize=maximumPoolSize，那么线程池已经达到极限，会根据饱和策略RejectedExecutionHandler拒绝新的任务。

超时机制销毁线程
allowCoreThreadTimeOut：该属性用来控制是否允许核心线程超时退出。
keepAliveTime：如果一个线程处在空闲状态的时间超过了该属性值，就会因为超时而退出。poolSize>corePoolSize时生效。

分类（工厂模式）：
CachedThreadPool：一个任务创建一个线程，使用SynchronousQueue
ScheduledThreadPool
可能会创建大量线程

FixedThreadPool：所有任务只能使用固定大小的线程；
SingleThreadExecutor：相当于大小为 1 的 FixedThreadPool。
可能堆积大量的请求，默认使用无界的LinkedBlockingQueue

安全性问题：
线程饥饿死锁：线程池中任务依赖于其他任务。
拥塞：运行时间较长的任务和运行时间较短的任务混合在一起。

线程池的优点：
降低资源消耗。 通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
提高响应速度。 当任务到达时，任务可以不需要的等到线程创建就能立即执行。
提高线程的可管理性。 线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

阻塞队列BlockingQueue：“生产者-消费者”问题
FIFO 队列 ：LinkedBlockingQueue（单向链表）、ArrayBlockingQueue（固定长度）
优先级队列 ：PriorityBlockingQueue
提供了阻塞的 take() 和 put() 方法：如果队列为空 take() 将阻塞，直到队列中有内容；如果队列为满 put() 将阻塞，直到队列有空闲位置。
自己实现BlockingQueue：参考ArrayBlockingQueue，put()、take()用ReentrantLock和Condition实现可中断、公平、选择性通知，消费者wait()/生产者notify()，enqueue()、dequeue()。

LinkedBlockingQueue满了的饱和（拒绝）策略：
中止：抛出运行时异常
抛弃
抛弃最老的任务：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）
调用者运行：将任务退回到调用者，平缓的性能降低

Daemon守护线程是程序运行时在后台提供服务的线程，不是不可或缺的，当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。main() 属于非守护线程。

4.中断
interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。
如果一个线程的 run() 方法执行一个无限循环，并且没有执行 sleep() 等会抛出 InterruptedException 的操作，那么调用线程的 interrupt() 方法就无法使线程提前结束。
interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。
调用 Executor 的 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。

5.互斥同步
Java 提供了两种锁机制来控制多个线程对共享资源的互斥访问，第一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock（需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成）。都可重入。

synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。
synchronized同步代码块，同步方法。
synchronized是基于原子性的内部锁机制，是可重入的。在一个线程调用synchronized方法的同时在其方法体内部调用该对象另一个synchronized方法，也就是说一个线程得到一个对象锁后再次请求该对象锁，是允许的。

synchronized底层实现：基于进入和退出管程Monitor对象实现，无论是显式同步(有明确的 monitorenter 和 monitorexit 指令,即同步代码块)还是隐式同步（由方法调用指令读取运行时常量池中方法的 ACC_SYNCHRONIZED 标志，即同步方法）都是如此。
JVM中对象在内存中的布局分为三块区域：对象头、实例变量和填充数据。
对象头：synchronized使用的锁对象是存储在Java对象头里的，jvm中采用2个字来存储对象头(如果对象是数组则会分配3个字，多出来的1个字记录的是数组长度)，其主要由 Mark Word 和 Class Metadata Address 组成。
Mark Word：存储对象的hashCode、锁信息或分代年龄或GC标志等信息。考虑到JVM的空间效率，Mark Word 被设计成为一个非固定的数据结构，以便存储更多有效的数据，它会根据对象本身的状态复用自己的存储空间
其中锁状态可能会有轻量级锁和偏向锁（锁优化）和重量级锁synchronized的对象锁。

synchronized锁标识位为10，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式。
monitor对象存在于每个Java对象的对象头中(存储的指针的指向)，synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因，同时也是notify/notifyAll/wait等方法存在于顶级对象Object中的原因。

同步语句块执行monitorenter指令，objectref 的 monitor 的进入计数器为 0，那线程可以成功取得 monitor，并将计数器值设置为 1，取锁成功。
如果当前线程已经拥有 objectref 的 monitor 的持有权，那它可以重入这个 monitor，重入时计数器的值也会加 1。倘若其他线程已经拥有 objectref 的 monitor 的所有权，那当前线程将被阻塞。
执行monitorexit指令，执行线程将释放 monitor(锁)并设置计数器值为0 ，其他线程将有机会持有 monitor。
monitor是依赖于底层的操作系统的Mutex Lock来实现的，而操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的synchronized效率低的原因。

synchronized和ReentrantLock 的区别：
1.等待可中断：当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。因此ReentrantLock性能更好。
ReentrantLock 可中断，而 synchronized 不行。

2.实现公平锁：公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。
synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但是也可以是公平的。

3.实现选择性通知：wait()和notify()/notifyAll()实现等待-通知机制。
一个 ReentrantLock 可以同时绑定多个 Condition 对象实现选择性通知。

4.性能：synchronized 进行了很多优化，与 ReentrantLock 大致相同。

除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。

6.线程之间的协作
join()，在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。

调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。
wait() notify() notifyAll()都属于 Object 的一部分，而不属于 Thread。只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateException。
使用 wait() 挂起期间，线程会释放锁。这是因为，如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行 notify() 或者 notifyAll() 来唤醒挂起的线程，造成死锁。
放在同步代码块中保证同时只进行生产或消费避免并发进行引发生产上溢或消费下溢。判断条件用 while 循环保证消费者不断等待生产者的通知。

await() signal() signalAll()。
java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。
相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。

sleep()
yield()声明了当前线程已经完成了生命周期中最重要的部分，可以切换给其它线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其它线程可以运行。

7.J.U.C - AQS
java.util.concurrent（J.U.C）大大提高了并发性能，AbstractQueuedSynchronizer被认为是 J.U.C 的核心。AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器。
AQS通过一个int类型的状态变量state和一个FIFO队列来完成共享资源的获取，线程的排队等待等。
AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。
AQS定义两种资源共享方式：Exclusive（独占）和Share（共享）
AQS底层使用了模板方法模式

ReentrantLock基于AQS实现。同步队列存放着竞争同步资源的线程的引用，Condition的等待队列存放着待唤醒的线程的引用。同步队列和等待队列互相协同。
states 状态是用 CAS 算法更新的。
自旋/挂起：通过挂起线程前的低频自旋保证了AQS阻塞线程上下文切换开销及CUP时间片占用的最优化选择。保证在等待时间短通过自旋去占有锁而不需要挂起，而在等待时间长时将线程挂起。实现锁性能的最大化。

CountDownLatch闭锁：用来控制一个线程等待多个线程。维护了一个计数器 cnt，每次调用 countDown() 方法会让计数器的值减 1，减到 0 的时候，那些因为调用 await() 方法而在等待的线程就会被唤醒。
CyclicBarrier：用来控制多个线程互相等待，只有当多个线程都到达时，这些线程才会继续执行。和 CountdownLatch 相似，都是通过维护计数器来实现的。
CyclicBarrier 和 CountdownLatch 的一个区别是，CyclicBarrier 的计数器通过调用 reset() 方法可以循环使用，所以它才叫做循环屏障。

Semaphore，类似于操作系统中的信号量，可以控制对互斥资源的访问线程数。
ReentrantReadWriterLock读写锁：维护了一对相关的锁，一个用于只读操作，另一个用于写入操作。只要没有writer，读取锁可以由多个reader线程同时保持。写入锁是独占的。同时可以有一个线程写操作，多个线程读操作。 
StampedLock读写锁：乐观锁，在读线程非常多而写线程非常少的场景下非常适用，同时还避免了写饥饿情况的发生。

8.J.U.C - 其它组件
FutureTask
BlockingQueue

ForkJoin，主要用于并行计算中，和 MapReduce 原理类似，都是把大的计算任务拆分成多个小任务并行计算。
ForkJoin 使用 ForkJoinPool 来启动，它是一个特殊的线程池，线程数量取决于 CPU 核数。
ForkJoinPool 实现了工作窃取算法来提高 CPU 的利用率。每个线程都维护了一个双端队列，用来存储需要执行的任务。
工作窃取算法允许空闲的线程从其它线程的双端队列中窃取一个任务来执行。窃取的任务必须是最晚的任务，避免和队列所属线程发生竞争。队列中只有一个任务时还是会发生竞争。
fork()：开启一个新线程（或是重用线程池内的空闲线程），将任务交给该线程处理。
join()：等待该任务的处理线程处理完毕，获得返回值。

9.Java 内存模型JMM
Java 内存模型试图屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。
目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。

所有的变量都存储在主内存中，每个线程还有自己的工作内存，工作内存存储在高速缓存或者寄存器中，保存了该线程使用的变量的主内存副本拷贝。线程只能直接操作工作内存中的变量，不同线程之间的变量值传递需要通过主内存来完成。
而JMM就作用于工作内存和主存之间数据同步过程。他规定了如何做数据同步以及什么时候做数据同步。

内存模型三大特性：
原子性：Java 内存模型保证了 read、load、use、assign、store、write、lock 和 unlock 操作具有原子性，Java 内存模型允许虚拟机将没有被 volatile 修饰的 64 位数据（long，double）的读写操作划分为两次 32 位的操作来进行，即 load、store、read 和 write 操作可以不具备原子性。原子类和synchronized 互斥锁实现。
可见性：指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改。Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。volatile、synchronized和final（被 final 关键字修饰的字段在构造器中一旦初始化完成，并且没有发生 this 逃逸（其它线程通过 this 引用访问到初始化了一半的对象），那么其它线程就能看见 final 字段的值。）实现。         
有序性：在本线程内观察，所有操作都是有序的。在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排序。在 Java 内存模型中，允许编译器和处理器对指令进行重排序，重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。volatile 关键字通过添加内存屏障的方式来禁止指令重排（重排序时不能把后面的指令放到内存屏障之前。），也可以通过 synchronized 来保证有序性。            

先行发生原则

10.线程安全
多个线程不管以何种方式访问某个类，并且在主调代码中不需要进行同步，都能表现正确的行为。

不可变：不可变（Immutable）的对象一定是线程安全的。final 关键字修饰的基本数据类型；String；枚举类型；Number 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为 Number 的原子类 AtomicInteger 和 AtomicLong 则是可变的。

互斥同步：synchronized 和 ReentrantLock。互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。无论共享数据是否真的会出现竞争，它都要进行加锁（这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁）、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。

非阻塞同步（乐观锁）：CAS和版本号机制
基于冲突检测的乐观并发策略：先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施（不断地重试，直到成功为止，重试的过程被称为自旋）。
乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。硬件支持的原子性操作最典型的是：比较并交换（Compare-and-Swap，CAS）。是CPU的一个指令。
CAS：更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。
CAS适用于写比较少的情况下（多读场景，冲突一般较少）。
J.U.C 包里面的整数原子类 AtomicInteger 的方法调用了 Unsafe 类（直接操作内存）的 CAS 操作。原子类通过CAS实现原子性。

乐观锁的问题：ABA 问题，自旋CAS循环时间长开销大，只能保证一个变量的原子性操作。
ABA问题：如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。
版本号机制：带有标记的原子引用类 AtomicStampedReference 来解决ABA问题。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。

无同步方案：不涉及共享数据
栈封闭：多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。	
线程本地存储ThreadLocal：把共享数据的可见范围限制在同一个线程之内
可重入代码（纯代码）：可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法

11.锁优化
JVM 对 synchronized 的优化。
自旋锁：让一个线程在请求一个共享数据的锁时执行忙循环（自旋）一段时间，如果在这段时间内能获得锁，就可以避免进入阻塞状态。自旋锁虽然能避免进入阻塞状态从而减少开销，但是它需要进行忙循环操作占用 CPU 时间，它只适用于共享数据的锁定状态很短的场景。自适应的自旋锁。

锁消除：指对于被检测出不可能存在竞争的共享数据的锁进行消除。锁消除主要是通过逃逸分析来支持，如果堆上的共享数据不可能逃逸出去被其它线程访问到，那么就可以把它们当成私有数据对待，也就可以将它们的锁进行消除。

锁粗化：一串零碎的操作都对同一个对象加锁，将会把加锁的范围扩展（粗化）到整个操作序列的外部。

轻量级锁：使用 CAS 操作来避免重量级锁使用互斥量的开销。可以先采用 CAS 操作进行同步，如果 CAS 失败了再改用互斥量进行同步。如果 CAS 操作成功了，那么线程就获取了该对象上的锁，表示该对象处于轻量级锁状态。

偏向锁：偏向于让第一个获取锁对象的线程，这个线程在之后获取该锁就不再需要进行同步操作，甚至连 CAS 操作也不再需要。

synchronized的底层实现主要依靠 Lock-Free 的队列，基本思路是 自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。

12.并发容器
ConcurrentHashMap：在进行读操作时(几乎)不需要加锁，而在写操作时通过锁分段技术只对所操作的段加锁而不影响客户端对其它段的访问。

CopyOnWriteArrayList：通过创建底层数组的新副本，当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。

ConcurrentLinkedQueue

ConcurrentSkipListMap：这是一个Map，使用跳表的数据结构进行快速查找。
跳表有点类似于平衡树。
对平衡树的插入和删除往往很可能导致平衡树进行一次全局的调整。而对跳表的插入和删除只需要对整个数据结构的局部进行操作即可。
这样带来的好处是：在高并发的情况下，你会需要一个全局锁来保证整个平衡树的线程安全。而对于跳表，你只需要部分锁即可。

13.并发Concurrent与并行Parallel
并行是指多个任务在同一时刻进行。并发是指多个任务在同一时间段内发生。
并行是物理上的同时发生，而并发是逻辑上的同时发生。
并行是指多个CPU内核在同一时刻，同时运行多个任务。并发是指单个CPU内，通过CPU调度算法，让用户感觉在同时运行多个任务。
如果是在单核CPU上，多线程肯定是并发运行的。如果是在多核CPU上，这些多线程也可能是并行运行。

14.线程调度策略和线程优先级
抢占式调度：每条线程执行的时间、线程的切换都由系统控制，一个线程的堵塞不会导致整个进程堵塞。
协同式调度：某一线程执行完后主动通知系统切换到另一线程上执行，线程的执行时间由线程本身控制，线程切换可以预知，不存在多线程同步问题。

Java使用的线程调度是抢占式调度，在JVM中体现为让可运行池中优先级高的线程拥有CPU使用权，如果可运行池中线程优先级一样则随机选择线程，但要注意的是实际上一个绝对时间点只有一个线程在运行（对于一个CPU）
不一一对应，程序不应该依赖于优先级，Java线程是通过映射到系统的原生线程上来实现的，所以线程调度最终还是取决于操作系统。


三个线程如何实现交替打印ABC：
1.Synchronized
使用同步块和wait（）、notify（），每一个线程同时持有两个对象锁prev和self
打印完后count--，self.notifyAll()释放self锁
进入try-catch，如果count=0，prev.notifyAll()，否则prev.wait()释放prev锁

2.ReentrantLock
lock.lock()和lock.unlock()，打印前lock.lock()其他线程阻塞，打印完lock.unlock()释放锁，用state全局变量控制交替打印（state%3）

3.ReentrantLock结合Condition
和Synchronized相似使用await()和signal()以及在try-catch-finally使用lock.lock()和lock.unlock()

4.Semaphore
初始信号量A=1，B=0，C=0
A.acquire()， A获取信号执行,A信号量减1,当A为0时将无法继续获得该信号量，然后打印A
B.release()， B释放信号，B信号量加1（初始为0），此时可以获取B信号量

5.AtomicInteger
ai.get()与state相似，打印完后ai.getAndIncrement()
