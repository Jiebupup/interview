1.简介
MySQL 是一个关系型数据库管理系统，属于 Oracle 旗下产品。关系数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。MySQL 所使用的 SQL 语言是用于访问数据库的最常用标准化语言。

数据类型：整型，浮点数，字符串，时间和日期。
一般 MySQL 默认的最大连接数在 150 左右，最大连接数还只是一个指标，CPU，内存，磁盘，网络等物理条件都是其运行指标，这些指标都会限制其并发能力！所以，一般 3000 的并发请求就能打死大部分数据库了。

2.索引
B Tree：非叶根节点最少有两个子树，所有叶子节点位于同一层，每个节点最多 k 个子树，非根非叶节点最少 k/2 向上取整个子树，有 k 个子树的中间节点包含有 k-1 个元素。
B+ Tree：叶子节点自小而大顺序链接，通过顺序访问指针来提高区间查询的性能，叶子结点中包含了全部元素的信息，有 k 个子树的中间节点包含有 k 个元素。所有的中间节点元素都同时存在于子节点中，在子节点元素中是最大或最小的元素。

操作：
进行查找操作时，首先在根节点进行二分查找，找到一个 key 所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出 key 所对应的 data。 
插入删除操作会破坏平衡树的平衡性，因此在插入删除操作之后，需要对树进行一个分裂、合并、旋转等操作来维护平衡性。

文件系统及数据库系统普遍采用 B+ Tree 作为索引结构。B+ Tree 的优势：
平衡树查找操作的时间复杂度和树高 h 相关。B+ Tree 相对于红黑树出度大，相对于 B Tree 叶子节点存放所有的卫星数据，相同数据量下 B+ Tree 更加矮胖，会有更少的查找次数。
利用磁盘预读特性，顺序读取不需要进行磁盘寻道，并且只需要很短的磁盘旋转时间，速度会非常快。减少磁盘 I/O 操作。
所有查询都要查找到叶子节点，查询性能稳定。
所有叶子节点形成有序链表，便于部分和范围查找。还可用于排序与分组。

B+ Tree 索引：
是大多数 MySQL 存储引擎的默认索引类型。InnoDB 和 MyISAM 的实现方式不同：InnoDB 聚簇索引，MyISAM 非聚簇索引。
不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。
因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。
可以指定多个列作为索引列，多个索引列共同组成键。
适用于全键值、键值范围和最左键前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。

最左前缀查找：
创建了 lname_fname_age 多列索引，相当于创建了 lname 单列索引，(lname,fname) 联合索引以及 (lname,fname,age) 联合索引。
联合索引 (col1,col2,col3) 也是一棵 B+ Tree，其节点存储的则是三个关键字 col1、col2、col3 三个关键字的数据，且按照 col1、col2、col3 的顺序进行排序。直接对 col2 或 col3 查询，无法发挥索引的作用，变为全表查询。
在创建多列索引时，要根据业务需求，WHERE 子句中使用最频繁的一列放在最左边。多列索引对应 WHERE 中多个条件。ORDER BY 子句也遵循此规则。
要想使用第二个索引，必须先使用第一个索引，而且第一个索引必须是等值匹配。
最左前缀匹配用到了 B+ Tree 的排序特性，type:ref 快速查找。还用到了多列索引。
查询的时候如果所有条件都用上了，但是顺序不同，现在的查询引擎会自动优化为匹配联合索引的顺序，这样是能够命中索引的。
《阿里巴巴 Java 开发手册》：页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。由于最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。

InnoDB 的 B+ Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。
辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。

MyISAM 的非聚簇索引中，B+ Tree 叶节点的 data 域存放的是数据记录的地址。在索引检索的时候，首先按照 B+ Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。
InnoDB 中，其数据文件本身就是索引文件。相比 MyISAM 的索引文件和数据文件是分离的，InnoDB 表数据文件本身就是按 B+ Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引。这被称为聚簇索引。
InnoDB 其余的索引都作为辅助索引，辅助索引的 data 域存储相应记录主键的值而不是地址，这也是和 MyISAM 不同的地方。在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。
因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。

聚簇索引对磁盘上实际数据重新组织以按指定的一个或多个列的值排序。特点是数据的物理存放顺序与索引顺序是一致的。
一般情况下主键会默认创建聚簇索引，没有定义主键则 InnoDB 会选择一个唯一的非空索引代替。 
聚簇索引的索引和数据保存在同一个 B+ Tree 中，查询效率要比非聚簇索引高。

创建索引时，你需要确保该索引是应用在 SQL 查询语句的条件 (一般作为 WHERE 子句的条件)。
索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。

其他 MySQL 索引
哈希索引：能以 O(1) 时间进行查找，但是失去了有序性。在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快
自适应哈希索引：InnoDB 存储引擎中，当某个索引值被使用的非常频繁时，会在 B+ Tree 索引之上再创建一个哈希索引，这样就让 B+ Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。

全文索引 FULLTEXT：MyISAM 存储引擎中，用于查找文本中的关键词，而不是直接比较是否相等。查找条件使用 MATCH AGAINST，而不是普通的 WHERE。全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。
空间数据索引 SPATIAL（R-Tree）：MyISAM 存储引擎用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。必须使用 GIS 相关的函数来维护数据。

约束
MySQL 的 key 是同时具有 constraint 和 index 的意义。

主键约束 PRIMARY KEY：一种特殊的唯一索引，不允许有空值。主键：能唯一标识记录的字段。一个表只能有一个主键，主键字段的值不能为 null，主键可以由多个字段共同组成。InnoDB 中要使用与业务无关的自增主键作为主键，即逻辑主键。INT 类主键自增 auto_increment，跟上一条记录的值有关。

外键约束 FOREIGN KEY：用于限制主表与从表数据完整性。主表的主键来关联，表之间多个从表指向同一个主表的主键来构成一对多关系，中间表实现表的多对多关系。
级联更新：主键更新引起外键更新。外键与级联更新适用于单机低并发，不适合分布式和高并发集群。级联更新是强阻塞，存在数据库更新风暴的风险。外键影响数据库的插入速度。
《阿里巴巴 Java 开发手册》：不得使用外键与级联，一切外键概念必须在应用层解决。
优点：保证了数据库数据的一致性和完整性。级联操作方便，减轻了程序代码量。
缺点
增加了复杂性：每次 DELETE 或者 UPDATE 都必须考虑外键约束。外键的主从关系是定的，需求变动增加很多麻烦。
增加了额外工作：数据库需要增加维护外键的工作，增删改操作后，需要触发相关操作去检查外键，为了保证数据的的一致性和正确性，这样会不得不消耗资源，降低性能。
因为需要请求对其他表内部加锁而容易出现死锁情况
对分不分表不友好：因为分库分表下外键是无法生效的。

唯一约束 UNIQUE：索引每一行的值必须唯一，但允许有空值（只能有一条 NULL）。
联合索引：索引以一定顺序引用多列。

索引优化：
独立的列：在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。
多列索引：在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。
索引列的顺序：让选择性最强的索引列放在前面。索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。
前缀索引：对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。前缀长度的选取需要根据索引选择性来确定。
避免冗余索引：在大多数情况下，都应该尽量扩展已有的索引而不是创建新索引。

覆盖索引：索引包含所有需要查询的字段的值。优点：
索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。
一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。
对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。

查询回表：InnoDB 中查询辅助索引时需要再通过主键查询主索引。覆盖索引不需要回表操作。

索引的优点：
大大加快了数据的检索速度，减少了服务器需要扫描的数据行数。
帮助服务器避免进行排序和分组，以及避免创建临时表（B+ Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，因为不需要排序和分组，也就不需要创建临时表）。
将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。

加快多表连接。唯一索引保证行数据的唯一。

缺点：额外空间开销，生成和维护索引的额外时间开销。

索引的使用条件：
对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效。
对于中到大型的表，索引就非常有效。
对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到分区分出需要查询的一组数据，而不是一条记录一条记录地匹配。

索引无法使用的情况：模糊匹配，OR 前后没有同时使用，联合索引的最左匹配，存在索引列的数据类型隐形转换，where 字句里对索引列有数学运算或者使用函数。
不推荐使用索引的情况：数据唯一性差（一个字段的取值只有几种情况，会和全表扫描相近），频繁更新的字段。

3.查询性能优化
使用 Explain 进行分析：
分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。
比较重要的字段有：查询类型 select_type、索引 key 和扫描的行数 rows。

优化数据访问
减少请求的数据量：
只返回必要的列：最好不要使用 SELECT * 语句。
只返回必要的行：使用 LIMIT 语句来限制返回的数据。
缓存重复查询的数据。

减少服务器端扫描的行数：最有效的方式是使用索引来覆盖查询。

重构查询方式
切分查询：一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源和阻塞很多小的但重要的查询。

分解连接查询：将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联。好处：
可以让缓存更高效。分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。
分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。
减少锁竞争。
在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。
查询本身效率也可能会有所提升。

优化特定类型的查询

库表结构优化：
范式和反范式，优缺点
缓存表和汇总表
加快 ALTER TABLE 操作的速度

4.存储引擎
InnoDB：
MySQL 默认的事务型存储引擎（5.5 版本后），只有在需要它不支持的特性时，才考虑使用其它存储引擎。
实现了四个标准的隔离级别，默认级别是可重复读 REPEATABLE READ。
主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。
内部优化：从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。
支持真正的在线热备份，读写混合。其它存储引擎不支持在线热备份。
默认使用行级锁，在无索引无主键情况更新才会锁表。并发度高。
支持外键，MVCC，宕机恢复。
MySQL5.6 以前的版本，只有 MyISAM 存储引擎支持全文索引。MySQL5.6 及以后的版本，MyISAM 和 InnoDB 存储引擎均支持全文索引。只有字段的数据类型为 char、varchar、text 及其系列才可以建全文索引。

MyISAM：
设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。
支持压缩表（对于不会进行修改的表，极大减少磁盘空间占用）和空间数据索引。
不支持事务。
只支持表级锁，不支持行级锁。只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入 CONCURRENT INSERT。
崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。
如果指定了延迟更新索引 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。
MyISAM 强调的是性能，每次查询具有原子性，其执行速度比 InnoDB 更快，但不是绝对的。MyISAM 适合 SELECT 密集型的表。

5.切分
拓展写能力，应对高并发和大数据。
水平切分 Sharding：将同一个表中的记录按行拆分到多个结构相同的表中，每个库的表结构都一样，只不过每个库表放的数据是不同的。水平拆分可以支撑非常大的数据量。表的行数超过 200 万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。
当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓解单个数据库的压力，达到分布式的目的。
如果表的数据还是在同一台机器上，其实对于提升 MySQL 并发能力没有什么意义，所以水平拆分最好分库。
水平拆分能够支持非常大的数据量存储，应用端改造也少，但分片事务难以解决，跨界点 Join 性能较差，逻辑复杂难扩展难维护。尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络 I/O。

垂直切分：将一张表按列切分成多个表。根据数据库里面数据表的相关性进行拆分，使用主键关联。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。
垂直拆分的优点：可以使得行数据变小，在查询时减少读取的 Block 数，减少 I/O 次数。简化表的结构，易于维护，提升单表查询效率。将不常变的字段放一起，将经常改变的放一起，可以达到最大化利用 Cache 的目的。
垂直拆分的缺点：主键会出现冗余，需要管理冗余列，并会引起 Join 操作从而增加 CPU 开销，可以通过在应用层进行 Join 来解决。让事务变得更加复杂。表间关系复杂外键过多，数据表难以维护。

Sharding 策略
哈希取模：hash(key) % N。
范围 range：可以是 ID 范围也可以是时间范围。
映射表：使用单独的一个数据库来存储映射关系。

range 来分，好处在于说，扩容的时候很简单；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。
hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。

Sharding 存在的问题
事务问题：使用分布式事务来解决，比如 XA 接口。
连接 Join：可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。
ID 唯一性：使用全局唯一 ID（GUID）、为每个分片指定一个 ID 范围、分布式 ID 生成器 (如 Snowflake 算法)。

如何设计才可以让系统从未分库分表动态切换到分库分表上？
停机迁移方案
双写迁移方案：常用，在线上系统里面，之前所有写库的地方，增删改操作，除了对老库增删改，都加上对新库的增删改，这就是所谓的双写，同时写俩库，老库和新库。
然后系统部署之后，新库数据差太远，用之前说的导数工具，跑起来读老库数据写新库，写的时候要根据 gmt_modified 这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写。简单来说，就是不允许用老数据覆盖新数据。
导完一轮之后，有可能数据还是存在不一致，那么就程序自动做一轮校验，比对新老库每个表的每条数据，接着如果有不一样的，就针对那些不一样的，从老库读数据再次写。反复循环，直到两个库每个表的数据都完全一致为止。

如何设计可以动态扩容缩容的分库分表方案？
停机扩容
优化后的方案：设定好几台数据库服务器，每台服务器上几个库，每个库多少个表。
扩容的时候，申请增加更多的数据库服务器，装好 mysql，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器。
由 dba 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的。
我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址。
重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。

分库分表之后，id 主键如何处理？全局唯一的 id。 
基于数据库
数据库自增 id：系统里每次得到一个 id，都是往一个库的一个表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个 id。拿到这个 id 之后再往对应的分库分表里去写入。
好处就是方便简单，缺点就是单库生成自增 id，要是高并发的话，就会有瓶颈。
适合的场景：并发不高，但是数据量太大导致的分库分表扩容。

设置数据库 sequence 或者表自增字段步长：水平伸缩。
适合的场景：在用户防止产生的 ID 重复时，这种方案实现起来比较简单，也能达到性能目标。但是服务节点固定，步长也固定，将来如果还要增加服务节点，就不好搞了。

本地：UUID，太长了、占用空间大，作为主键性能太差了；更重要的是，UUID 不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作。在写的时候不能产生有顺序的 append 操作，而需要进行 insert 操作，将会读取整个 B+ 树节点到内存，在插入这条记录后会将整个节点写回磁盘，这种操作在记录占用空间比较大的情况下，性能下降明显。
获取系统当前时间：问题是，并发很高的时候，会有重复的情况，这个是肯定不合适的。

snowflake 算法：twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bit 作为毫秒数，用 10 bit 作为工作机器 id，12 bit 作为序列号。

数据库中间件：用来分库分表。
数据库分片的两种常见方案
客户端：分片逻辑在应用端，封装在 JAR 包中，通过修改或者封装 JDBC 层来实现。Sharding-JDBC 和 TDDL。
优点：应用直连数据库，降低外围系统依赖所带来的宕机风险。集成成本低，无需额外运维的组件。
缺点：限于只能在数据库访问层上做文章，扩展性一般，对于比较复杂的系统可能会力不从心。将分片逻辑的压力放在应用服务器上，造成额外风险。

代理端：在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。MyCAT 和 Atlas。
优点：能够处理非常复杂的需求，不受数据库访问层原来实现的限制，扩展性强。对于应用服务器透明且没有增加任何额外负载。
缺点：需部署和运维独立的代理中间件，成本高。应用需经过代理来连接数据库，网络上多了一跳，性能有损失且有额外风险。

Sharding-JDBC：客户端方案的优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要耦合 Sharding-JDBC 的依赖。中小型公司选用 Sharding-JDBC，客户端方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多。
MyCAT：代理端方案的缺点在于需要部署，自己运维一套中间件，运维成本高，但是好处在于对于各个项目是透明的，如果遇到升级之类的都是自己中间件那里搞就行了。但是中大型公司最好还是选用 MyCAT 这类代理端方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 MyCAT，然后大量项目直接透明使用即可。

6.复制
MySQL 支持两种复制方式：基于行的复制和基于语句（逻辑）的复制。这两种方式都是在主库上记录二进制日志，在备库重放日志的方式来实现异步的数据复制。在同一时间点备库的数据可能与主库的不一致。
通过复制可以将读操作指向备库来扩展读。不适合扩展写操作，因为一主库多备库的架构中，整个系统的性能取决于写入最慢的那部分。不能像分发读操作那样把写操作等同地分发到更多服务器上。

主从复制
binlog 线程：在主库上把数据更改记录到二进制日志 Binary log 中。
I/O 线程：备库读取二进制日志并写入到自己的中继日志 Relay log 中。
SQL 线程：备库读取中继日志，解析出主库已经执行的数据更改并在从备库中重放 Replay。

从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行。在高并发场景下，从库的数据一定会比主库慢一些，是有延时的。
如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。
半同步复制，用来解决主库数据丢失问题。主库写入 binlog 日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到至少一个从库的 ack 之后才会认为写操作完成了。
并行复制，用来解决主从同步延时问题。从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。

MySQL 主从同步延时问题的解决方案：
分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。
打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。
重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。
如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询设置直连主库。不推荐这种方法，你要是这么搞，读写分离的意义就丧失了。

复制拓扑

读写分离：
主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。
读写分离能提高性能的原因：
主从服务器负责各自的读和写，极大程度缓解了锁的争用。
从服务器可以使用 MyISAM，提升查询性能以及节约系统开销。
增加冗余，提高可用性。

读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。

7.并发一致性问题
丢失修改：T1 和 T2 两个事务都对一个数据进行修改，T1 先修改，T2 随后修改，T2 的修改覆盖了 T1 的修改。
两类：回滚和覆盖，分别发生在未提交读，未提交读和提交读。

读脏数据：T1 修改一个数据，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。
发生在未提交读。数据过期失效会产生脏读。

不可重复读：T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。
发生在未提交读和提交读。不可重复读强调的是修改。

幻读：T1 读取某个范围（多行）的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。
发生在未提交读和提交读、可重复读。幻读强调的是插入和删除。

产生并发不一致性问题主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性。并发控制可以通过封锁来实现，但是封锁操作需要用户自己控制，相当复杂。
数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。

8.隔离级别
未提交读 READ UNCOMMITTED：事务中的修改，即使没有提交，对其它事务也是可见的。
提交读 READ COMMITTED：一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。大部分数据库系统的隔离级别都是 READ COMMITTED。
可重复读 REPEATABLE READ：保证在同一个事务中多次读取同样数据的结果是一样的。MySQL 默认是 REPEATABLE READ。通过 MVCC + Next-Key Locks 防止幻读。
可串行化 SERIALIZABLE：强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。需要加锁实现，保证同一时间只有一个事务执行。

9.封锁
MySQL 中提供了两种封锁粒度：行级锁以及表级锁。
应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。
但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。
在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。

封锁类型
读写锁：
排它锁 Exclusive，简写为 X 锁，又称写锁。一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。
共享锁 Shared，简写为 S 锁，又称读锁。一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。

在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。

意向锁 Intention Locks：意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。可以更容易地支持多粒度封锁。有以下两个规定：
一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁。
一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。
通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。
任意 IS/IX 锁之间都是兼容的，因为它们只表示想要对表加锁，而不是真正加锁。
这里兼容关系针对的是表级锁，而表级的 IX 锁和行级的 X 锁兼容，两个事务可以对两个数据行加 X 锁。（事务 T1 想要对数据行 R1 加 X 锁，事务 T2 想要对同一个表的数据行 R2 加 X 锁，两个事务都需要对该表加 IX 锁，但是 IX 锁是兼容的，并且 IX 锁与行级的 X 锁也是兼容的，因此两个事务都能加锁成功，对同一个表中的两个数据行做修改。）

对于 update、delete 和 insert 语句，InnoDB 会自动给涉及数据集加排它锁 X。而对于普通 select 语句，InnoDB 不会加任何锁。

封锁协议
三级封锁协议
一级封锁协议：事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。
二级封锁协议：在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据一级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。
三级封锁协议：在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。

两段锁协议：加锁和解锁分为两个阶段进行，事务遵循两段锁协议是保证可串行化调度的充分非必要条件。
MySQL 隐式与显示锁定：InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。
InnoDB 也可以使用特定的语句进行显示锁定。加的 S 锁和 X 锁。

行锁：锁粒度最小，锁冲突发生的概率最低，支持的并发度也最高，但系统消耗成本也相对较高。加锁慢，会出现死锁。
InnoDB 行锁是通过给索引上的索引项加锁来实现的，只有通过索引条件检索数据时 InnoDB 才使用行级锁，否则 InnoDB 将使用表锁。只在存储引擎层实现。

Record Locks：锁定一个记录上的索引，而不是记录本身。如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。适用于使用主键索引或者唯一索引作查询条件更新。
Gap Locks：锁定索引之间的间隙，但是不包含索引本身。阻止多个事务将记录插入到同一范围内，防止幻读问题。关闭 Gap Locks：将事务的隔离级别设成 RC。将参数 innodblocksunsafeforbinlog 设置为 1。

间隙锁 Next-Key Locks：是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。锁定一个左开右闭区间。
当查询的索引含有唯一属性时，将 Next-Key Locks 降级为 Record Locks。

BDB 支持页锁，介于表锁和行锁之间，会出现死锁。
更新锁：用来避免先 S 后 X 死锁问题。
一次封锁法：每个事务必须一次将所有要使用的数据全部加锁，否则就不能继续执行。用来预防死锁。
锁根据持续时间还可以分为临时锁和持续锁。

10.多版本并发控制 MVCC
MVCC 是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，要求很低，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。
封锁中，加锁能解决多个事务同时执行时出现的并发一致性问题。在实际场景中读操作往往多于写操作，因此又引入了读写锁来避免不必要的加锁操作，例如读和读没有互斥关系。读写锁中读和写操作仍然是互斥的，而 MVCC 利用了多版本的思想，写操作更新最新的版本快照，而读操作去读旧版本快照，没有互斥关系，这一点和 CopyOnWrite 类似。
在 MVCC 中事务的 DELETE、INSERT、UPDATE 会为数据行新增一个版本快照。
脏读和不可重复读最根本的原因是事务读取到其它事务未提交的修改。在事务进行读取操作时，为了解决脏读和不可重复读问题，MVCC 规定只能读取已经提交的快照。当然一个事务可以读取自身未提交的快照，这不算是脏读。

采用 MVCC 来支持高并发比单纯的加锁更高效。是行级锁的变种，实现非锁定读。不管执行多少时间，同一个事务看到的数据都是一致的，多个事务看到同一行数据可能是不同的。

版本号
系统版本号 SYS_ID：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。
事务版本号 TRX_ID：事务开始时的系统版本号。

MVCC 在每行记录后面都保存着两个隐藏的列，用来存储：
创建版本号：指示创建一个数据行的快照时的系统版本号。
删除版本号：如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。

Undo 日志：MVCC 的多版本指的是多个版本的快照，快照存储在 Undo 日志中，该日志通过回滚指针 ROLL_PTR 把一个数据行的所有快照连接起来。
INSERT、UPDATE、DELETE 操作会创建一个日志，并将事务版本号 TRX_ID 写入。DELETE 可以看成是一个特殊的 UPDATE，还会额外将 DEL 字段设置为 1。

ReadView：主要包含了当前系统未提交的事务列表 TRX_IDs {TRX_ID_1, TRX_ID_2, ...}，还有该列表的最小值 TRX_ID_MIN 和 TRX_ID_MAX。
在进行 SELECT 操作时，根据数据行快照的 TRX_ID 与 TRX_ID_MIN 和 TRX_ID_MAX 之间的关系，从而判断数据行快照是否可以使用：
TRX_ID < TRX_ID_MIN，表示该数据行快照时在当前所有未提交事务之前进行更改的，因此可以使用。
TRX_ID > TRX_ID_MAX，表示该数据行快照是在事务启动之后被更改的，因此不可使用。

TRX_ID_MIN <= TRX_ID <= TRX_ID_MAX，需要根据隔离级别再进行判断。
提交读：如果 TRX_ID 在 TRX_IDs 列表中，表示该数据行快照对应的事务还未提交，则该快照不可使用。否则表示已经提交，可以使用。
可重复读：都不可以使用。因为如果可以使用的话，那么其它事务也可以读到这个数据行快照并进行修改，那么当前事务再去读这个数据行得到的值就会发生改变，也就是出现了不可重复读问题。

在数据行快照不可使用的情况下，需要沿着 Undo Log 的回滚指针 ROLL_PTR 找到下一个快照，再进行上面的判断。

快照读：MVCC 的 SELECT 操作是快照中的数据，不需要进行加锁操作。
当前读：MVCC 会对 INSERT、UPDATE、DELETE 进行加锁操作，从而读取最新的数据。可以看到 MVCC 并不是完全不用加锁，而只是避免了 SELECT 的加锁操作。
在进行 SELECT 操作时，可以强制指定进行加锁操作。

MVCC 不能解决幻读问题，适合对读的响应速度和并发性要求比较高，且 retry 代价小的场景。

11.一条 SQL 语句执行得很慢的原因有哪些
大多数情况下很正常，偶尔很慢：
内存中更新的字段不会马上同步持久化到磁盘中去，而是把这些更新的记录写入到 redo log 日记中去，等到空闲的时候，在通过 redo log 里的日记把最新的数据同步到磁盘中去。当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。
1.数据库在刷新脏页 flush：redolog 写满了或内存不够用了
2.执行的时候拿不到锁。

一直执行的很慢：
没有用索引：字段没有索引或有索引却没有用索引（where c - 1 = 1000，字段的左边做了运算就不会用上索引。或 pow(c,2) = 1000，函数操作导致没有用上索引。或未将打算加索引的列设置为 NOT NULL）。
数据库选错了索引：系统会预测导致走全表扫描而不走索引的，根据索引的区分度和基数来判断的，又是根据采样来知道基数的，采样失误就会导致系统就不走索引，直接走全部扫描了。

12.一条 SQL 语句执行的流程
服务器程序处理来自客户端的查询请求大致需要经过三个部分，分别是连接管理、解析与优化、存储引擎。
解析与优化包括查询缓存、语法解析和查询优化。
为了管理方便，人们把连接管理、查询缓存、语法解析、查询优化这些并不涉及真实数据存储的功能划分为 MySQL server 的功能，把真实存取数据的功能划分为存储引擎的功能。

连接管理：
客户端进程可以采用 TCP/IP、命名管道或共享内存、Unix 域套接字来与服务器进程建立连接。
每当有一个客户端进程连接到服务器进程时，服务器进程都会创建一个线程来专门处理与这个客户端的交互。
当该客户端退出时会与服务器断开连接，服务器并不会立即把与该客户端交互的线程销毁掉，而是把它缓存起来，在另一个新的客户端再进行连接时，把这个缓存的线程分配给该新客户端。这样就起到了不频繁创建和销毁线程的效果，从而节省开销。
MySQL 服务器会为每一个连接进来的客户端分配一个线程，但是线程分配的太多了会严重影响系统性能，所以我们也需要限制一下可以同时连接到服务器的客户端数量。
在客户端程序发起连接的时候，需要携带主机信息、用户名、密码，服务器程序会对客户端程序提供的这些信息进行认证，如果认证失败，服务器程序会拒绝连接。
如果客户端程序和服务器程序不运行在一台计算机上，我们还可以采用使用了 SSL 的网络连接进行通信，来保证数据传输的安全性。

查询缓存：
服务器先检查查询缓存，如果命中了缓存，则立刻返回存储在缓存中的结果。否则进入正式的查询阶段。MySQL 将缓存存放在一个引用表中，通过一个哈希值引用。
当判断缓存是否命中时，MySQL 不会进行解析查询语句，而是直接使用 SQL 语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，例如空格、注释等都会导致缓存的不命中。
如果查询请求中包含某些系统函数（同样的函数的两次调用会产生不一样的结果，比如函数 NOW）、用户自定义变量和函数、一些系统表，如 mysql、information_schema、performance_schema 数据库中的表，那这个请求就不会被缓存。
当查询语句中有一些不确定的数据时，则不会被缓存。但是仍然会查询缓存。
查询缓存系统会跟踪查询中涉及的每个表，如果这些表发生了变化，那么和这个表相关的所有缓存数据都将失效。
缓存同时也带来了额外的开销，比如每次都要去查询缓存中检索，查询请求处理完需要更新查询缓存，维护该查询缓存对应的内存区域。从 MySQL5.7.20 开始，不推荐使用查询缓存，并在 MySQL8.0 中删除。

语法解析：MySQL 服务器程序首先要对客户端程序发送过来的请求本文做分析，判断请求的语法是否正确，然后从文本中将要查询的表、各种查询条件都提取出来放到 MySQL 服务器内部使用的一些数据结构上来。从指定的文本中提取出我们需要的信息本质上算是一个编译过程，涉及词法解析、语法分析、语义分析等阶段。服务器程序获得到了需要的信息，比如要查询的列是哪些，表是哪个，搜索条件是什么等等。
查询优化：MySQL 的优化程序会对我们的语句做一些优化，如外连接转换为内连接、表达式简化、子查询转为连接等。优化的结果就是生成一个执行计划，这个执行计划表明了应该使用哪些索引进行查询，表之间的连接顺序是啥样的。我们可以使用 EXPLAIN 语句来查看某个语句的执行计划。

存储引擎：
MySQL 服务器把数据的存储和提取操作都封装到了一个叫存储引擎的模块里。我们知道表是由一行一行的记录组成的，但这只是一个逻辑上的概念，物理上如何表示记录，怎么从表中读取数据，怎么把数据写入具体的物理存储器上，这都是存储引擎负责的事情。
它的功能就是接收上层传下来的指令，然后对表中的数据进行提取或写入操作。
各种不同的存储引擎向上边的 MySQL server 层提供统一的调用接口（也就是存储引擎 API），包含了几十个底层函数，像读取索引第一条内容、读取索引下一条内容、插入记录等等。

在 MySQL server 完成了查询优化后，只需按照生成的执行计划调用底层存储引擎提供的 API，获取到数据后返回给客户端就好了。

13.binlog&undo log&redo log
二进制日志 binlog 用于记录所有更新且提交了数据或者已经潜在更新提交了数据（例如，没有匹配任何行的一个 DELETE）的所有语句。语句以事件的形式保存，它描述数据更改。
binlog 作用：
恢复使能够最大可能地更新数据库，因为二进制日志包含备份后进行的所有更新。
在主复制服务器上记录所有将发送给从服务器的语句。 

回滚日志 undo log 为了实现事务的原子性。在 MySQL 数据库 InnoDB 存储引擎中，还用 undo log 来实现 MVCC。
原理：在操作任何数据之前，首先将数据备份到 undo log。然后进行数据的修改。如果出现了错误或者用户执行了 ROLLBACK 语句，系统可以利用 undo log 中的备份将数据恢复到事务开始之前的状态。
除了可以保证事务的原子性，undo log 也可以用来辅助完成事务的持久化。
缺陷：每个事务提交前将数据和 undo log 写入磁盘，这样会导致大量的磁盘 I/O，因此性能很低。

重做日志 redo log 记录新数据的备份。在事务提交前，只要将 redo log 持久化即可，不需要将数据持久化。当系统崩溃时，虽然数据没有持久化，但是 redo log 已经持久化。系统可以根据 redo log 的内容，将所有数据恢复到最新的状态。
redo log 包括两部分：一是内存中的日志缓冲 buffer，该部分日志是易失性的。二是磁盘上的重做日志文件 file，该部分日志是持久的。

binlog 和 redo log 的区别：
binlog 是 MySQL Server 层记录的日志，redo log 是 InnoDB 存储引擎层的日志。两者都记录了某些操作的日志（不是所有），有些重复，但两者记录的格式不同。binlog 先于 redo log 被记录。
binlog 属于逻辑日志，基于行格式的记录。redo log 属于物理日志，记录的是数据库中每个页的修改。逻辑日志有个缺点是难以并行，而物理日志可以比较好的并行操作。
binlog 只在每次事务提交的时候一次性写入缓存中日志文件。而 redo log 在数据准备修改前写入缓存中的 redo log 中，然后才对缓存中的数据执行修改操作。而且保证在发出事务提交指令时，先向缓存中的 redo log 写入日志，写入完成后才执行提交动作。
binlog 只在提交的时候一次性写入，所以 binlog 中的记录方式和提交顺序有关，且一次提交对应一次记录。而 redo log 中是记录的物理页的修改，redo log 文件中同一个事务可能多次记录，最后一个提交的事务记录会覆盖所有未提交的事务记录。
binlog 记录的是所有影响数据的操作，记录的内容较多。而 redo log 记录的是物理页的情况，它具有幂等性，因此记录日志的方式极其简练。

undo log 和 redo log 的区别：
undo 用来回滚行记录到某个版本。undo log 一般是逻辑日志，根据每行记录进行记录。
redo log 通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页，且只能恢复到最后一次提交的位置。
