1.简介
MySQL 是一个关系型数据库管理系统，属于 Oracle 旗下产品。关系数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。MySQL 所使用的 SQL 语言是用于访问数据库的最常用标准化语言。
数据类型：整型，浮点数，字符串（CHAR 和 VARCHAR 变长、BLOB 二进制和 TEXT 字符存储很大数据），时间和日期。
一般 MySQL 默认的最大连接数在 150 左右，最大连接数还只是一个指标，cpu，内存，磁盘，网络等物理条件都是其运行指标，这些指标都会限制其并发能力！所以，一般 3000 的并发请求就能打死大部分数据库了。

2.索引
B Tree：非叶根节点最少有两个子树，所有叶子节点位于同一层，每个节点最多 k 个子树，非根非叶节点最少 k/2 向上取整个子树，有 k 个子树的中间节点包含有 k-1 个元素。
B+ Tree：叶子节点自小而大顺序链接，叶子结点中包含了全部元素的信息，有 k 个子树的中间节点包含有 k 个元素。所有的中间节点元素都同时存在于子节点中，在子节点元素中是最大（或最小）元素。

操作：
进行查找操作时，首先在根节点进行二分查找，找到一个 key 所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出 key 所对应的 data。 
插入删除操作会破坏平衡树的平衡性，因此在插入删除操作之后，需要对树进行一个分裂、合并、旋转等操作来维护平衡性。

文件系统及数据库系统普遍采用 B+ Tree 作为索引结构。B+ Tree 的优势：
相对于红黑树出度大，相对于 B Tree 叶子节点存放所有的卫星数据，相同数据量下 B+ Tree 更加矮胖，会有更少的查找次数。
利用磁盘预读特性，顺序读取不需要进行磁盘寻道，并且只需要很短的磁盘旋转时间，速度会非常快，减少磁盘 I/O 操作。
所有查询都要查找到叶子节点，查询性能稳定。
所有叶子节点形成有序链表，便于部分和范围查找。还可用于排序与分组。

B+ Tree 索引：
是大多数 MySQL 存储引擎的默认索引类型。InnoDB 和 MyISAM 的实现方式不同。InnoDB 聚簇索引，MyISAM 非聚簇索引。
不再需要进行全表扫描，只需要对树进行搜索即可，所以查找速度快很多。
因为 B+ Tree 的有序性，所以除了用于查找，还可以用于排序和分组。
可以指定多个列作为索引列，多个索引列共同组成键。
适用于全键值、键值范围和键前缀查找（最左）。如果不是按照索引列的顺序进行查找，则无法使用索引。

最左前缀查找：
创建了 lname_fname_age 多列索引,相当于创建了 (lname) 单列索引，(lname,fname) 联合索引以及 (lname,fname,age) 联合索引。
联合索引 (col1, col2,col3) 也是一棵 B+ Tree，其节点存储的则是三个关键字 col1、col2、col3 三个关键字的数据，且按照 col1、col2、col3 的顺序进行排序。直接对 col2 或 col3 查询，无法发挥索引的作用，变为全表查询。
在创建多列索引时，要根据业务需求，WHERE 子句中使用最频繁的一列放在最左边。多列索引对应 WHERE 中多个条件。ORDER BY 子句也遵循此规则。
要想使用第二个索引，必须先使用第一个索引，而且第一个索引必须是等值匹配。
最左前缀匹配用到了 B+ Tree 的排序特性，type:ref 快速查找。还用到了多列索引。
查询的时候如果所有条件都用上了，但是顺序不同，现在的查询引擎会自动优化为匹配联合索引的顺序，这样是能够命中索引的。

InnoDB 的 B+ Tree 索引分为主索引和辅助索引，主索引的叶子节点 data 域记录着完整的数据记录（称为聚簇索引）。因为无法把数据行存放在两个不同的地方，一张表只允许存在一个聚簇索引。
辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。

MyISAM 的非聚簇索引中， B+ Tree 叶节点的 data 域存放的是数据记录的地址。在索引检索的时候，首先按照 B+ Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。
InnoDB 中，其数据文件本身就是索引文件。相比 MyISAM 的索引文件和数据文件是分离的，InnoDB 表数据文件本身就是按 B+ Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引。这被称为聚簇索引。
InnoDB 其余的索引都作为辅助索引，辅助索引的 data 域存储相应记录主键的值而不是地址，这也是和 MyISAM 不同的地方。在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。
因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。

聚簇索引对磁盘上实际数据重新组织以按指定的一个或多个列的值排序。特点是数据的物理存放顺序与索引顺序是一致的。
一般情况下主键会默认创建聚簇索引，没有定义主键则 InnoDB 会选择一个唯一的非空索引代替。 
聚簇索引的索引和数据保存在同一个 B+ Tree 中，查询效率要比非聚簇索引高。

创建索引时，你需要确保该索引是应用在 SQL 查询语句的条件 (一般作为 WHERE 子句的条件)。
索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。

其他 MySQL 索引：
哈希索引：能以 O(1) 时间进行查找，但是失去了有序性。在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快
自适应哈希索引：InnoDB 存储引擎中，当某个索引值被使用的非常频繁时，会在 B+ Tree 索引之上再创建一个哈希索引，这样就让 B+ Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。

全文索引 FULLTEXT：MyISAM 存储引擎中，用于查找文本中的关键词，而不是直接比较是否相等。查找条件使用 MATCH AGAINST，而不是普通的 WHERE。全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。
空间数据索引 SPATIAL（R-Tree）：MyISAM 存储引擎。

约束
主键约束 PRIMARY KEY：一种特殊的唯一索引，不允许有空值。主键：能唯一标识记录的字段。一个表只能有一个主键，主键字段的值不能为 null，主键可以由多个字段共同组成。InnoDB 中要使用与业务无关的自增主键作为主键，即逻辑主键。INT 类主键自增 auto_increment，跟上一条记录的值有关。
外键约束 FOREIGN KEY：用于限制主表与从表数据完整性。主表的主键来关联，表之间多个从表指向同一个主表的主键来构成一对多关系，中间表实现表的多对多关系。设置级联更新/删除。
唯一约束 UNIQUE：索引每一行的值必须唯一，但允许有空值（只能有一条 NULL）。
联合索引：索引以一定顺序引用多列。

索引优化：
独立的列：在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。
多列索引：在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。
索引列的顺序：让选择性最强的索引列放在前面。索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。
前缀索引：对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。前缀长度的选取需要根据索引选择性来确定。
避免冗余索引：在大多数情况下，都应该尽量扩展已有的索引而不是创建新索引。

覆盖索引：索引包含所有需要查询的字段的值。优点：
索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。
一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。
对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。

查询回表：InnoDB 中查询辅助索引时需要再通过主键查询主索引。覆盖索引不需要回表操作。

索引的优点：
大大加快了数据的检索速度（将无序的数据变为有序），减少了服务器需要扫描的数据行数。
帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，因为不需要排序和分组，也就不需要创建临时表）。
将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。
加快多表连接。唯一索引保证行数据的唯一。

缺点：额外空间开销，维护索引的额外时间开销。

索引的使用条件：
对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效。
对于中到大型的表，索引就非常有效。
对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配（使用分区技术）。

索引无法使用的情况：模糊匹配，OR 前后没有同时使用，联合索引的最左匹配，存在索引列的数据类型隐形转换，where 字句里对索引列有数学运算或者使用函数。
不推荐使用索引的情况：数据唯一性差（一个字段的取值只有几种情况，会和全表扫描相近），频繁更新的字段。

3.查询性能优化&库表结构优化
查询
Explain ：用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。
比较重要的字段有 select_type 查询类型、key 使用的索引和 rows 扫描的行数。

优化数据访问
减少请求的数据量：只返回必要的列：最好不要使用 SELECT * 语句。只返回必要的行：使用 LIMIT 语句来限制返回的数据。缓存重复查询的数据。
减少服务器端扫描的行数：最有效的方式是使用索引来覆盖查询。

重构查询方式
切分查询：一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。
分解连接查询：将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联。

分解连接查询的好处：
可以让缓存更高效。分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。
分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。
减少锁竞争。
在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。
查询本身效率也可能会有所提升。

优化特定类型的查询：COUNT() 查询、关联查询、子查询、GROUP BY 和 DISTINCT、LIMIT 分页、SQL_CALC_FOUND_ROWS、UNION 查询以及静态查询分析和用户自定义变量。

库表
范式和反范式、优缺点
缓存表和汇总表
加快 ALTER TABLE 操作的速度

4.存储引擎
InnoDB：
MySQL 默认的事务型存储引擎（5.5 版本后），只有在需要它不支持的特性时，才考虑使用其它存储引擎。
实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ）。
主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。
内部优化：从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。
支持真正的在线热备份，读写混合。
默认使用行级锁。
支持外键，MVCC，宕机恢复。

MyISAM：
多了支持压缩表和空间数据索引。设计简单，不支持事务，读密集下适用。MyISAM 强调的是性能，每次查询具有原子性,其执行速度比 InnoDB 类型更快（不是绝对的）。
不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入。
崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。

5.切分
拓展写能力，应对高并发和大数据。
水平切分 Sharding：将同一个表中的记录按行拆分到多个结构相同的表中，每个库的表结构都一样，只不过每个库表放的数据是不同的。水平拆分最好分库。
当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓解单个数据库的压力，达到分布式的目的。

垂直切分：将一张表按列切分成多个表。一般来说，会将较少的访问频率很高的字段放到一个表里去，然后将较多的访问频率很低的字段放到另外一个表里去。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。
在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中。
垂直拆分的优点：可以使得列数据变小，在查询时减少读取的 Block 数，减少 I/O 次数。此外，垂直分区可以简化表的结构，易于维护。
垂直拆分的缺点：主键会出现冗余，需要管理冗余列，并会引起 Join 操作，可以通过在应用层进行 Join 来解决。此外，垂直分区会让事务变得更加复杂。

Sharding 策略：哈希取模 hash，范围 range，映射表。
range 来分，好处在于说，扩容的时候很简单；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。
hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。

Sharding 存在的问题：事务问题，连接，ID 唯一性。

如何设计才可以让系统从未分库分表动态切换到分库分表上？
停机迁移方案
双写迁移方案：常用，在线上系统里面，之前所有写库的地方，增删改操作，除了对老库增删改，都加上对新库的增删改，这就是所谓的双写，同时写俩库，老库和新库。
然后系统部署之后，新库数据差太远，用之前说的导数工具，跑起来读老库数据写新库，写的时候要根据 gmt_modified 这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写。简单来说，就是不允许用老数据覆盖新数据。
导完一轮之后，有可能数据还是存在不一致，那么就程序自动做一轮校验，比对新老库每个表的每条数据，接着如果有不一样的，就针对那些不一样的，从老库读数据再次写。反复循环，直到两个库每个表的数据都完全一致为止。

如何设计可以动态扩容缩容的分库分表方案？
停机扩容
优化后的方案：设定好几台数据库服务器，每台服务器上几个库，每个库多少个表。
扩容的时候，申请增加更多的数据库服务器，装好 mysql，呈倍数扩容，4 台服务器，扩到 8 台服务器，再到 16 台服务器。
由 dba 负责将原先数据库服务器的库，迁移到新的数据库服务器上去，库迁移是有一些便捷的工具的。
我们这边就是修改一下配置，调整迁移的库所在数据库服务器的地址。
重新发布系统，上线，原先的路由规则变都不用变，直接可以基于 n 倍的数据库服务器的资源，继续进行线上系统的提供服务。

分库分表之后，id 主键如何处理？全局唯一的 id 
基于数据库
数据库自增 id：系统里每次得到一个 id，都是往一个库的一个表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个 id。拿到这个 id 之后再往对应的分库分表里去写入。
好处就是方便简单，缺点就是单库生成自增 id，要是高并发的话，就会有瓶颈。
适合的场景：并发不高，但是数据量太大导致的分库分表扩容。

设置数据库 sequence 或者表自增字段步长：水平伸缩。
适合的场景：在用户防止产生的 ID 重复时，这种方案实现起来比较简单，也能达到性能目标。但是服务节点固定，步长也固定，将来如果还要增加服务节点，就不好搞了。

本地：UUID， 太长了、占用空间大，作为主键性能太差了；更重要的是，UUID 不具有有序性，会导致 B+ 树索引在写的时候有过多的随机写操作。在写的时候不能产生有顺序的 append 操作，而需要进行 insert 操作，将会读取整个 B+ 树节点到内存，在插入这条记录后会将整个节点写回磁盘，这种操作在记录占用空间比较大的情况下，性能下降明显。
获取系统当前时间：问题是，并发很高的时候，会有重复的情况，这个是肯定不合适的。

snowflake 算法：twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bit 作为毫秒数，用 10 bit 作为工作机器 id，12 bit 作为序列号。

6.复制
MySQL 支持两种复制方式：基于行的复制和基于语句（逻辑）的复制。这两种方式都是在主库（服务器）上记录二进制日志，在备库重放日志的方式来实现异步的数据复制。在同一时间点备库的数据可能与主库的不一致。
通过复制可以将读操作指向备库来扩展读。不适合扩展写操作，因为一主库多备库的架构中，整个系统的性能取决于写入最慢的那部分。不能像分发读操作那样把写操作等同地分发到更多服务器上。

主从复制：
binlog 线程：在主库上把数据更改记录到二进制日志 Binary log 中
I/O 线程：备库将主库上的日志复制到自己的中继日志 Relay log 中
SQL 线程：备库读取中继日志中的事件并将其重放 Replay 到备库数据之上

从库同步主库数据的过程是串行化的，也就是说主库上并行的操作，在从库上会串行执行。在高并发场景下，从库的数据一定会比主库慢一些，是有延时的。
如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上是没有的，有些数据可能就丢失了。
半同步复制，用来解决主库数据丢失问题。主库写入 binlog 日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到至少一个从库的 ack 之后才会认为写操作完成了。
并行复制，用来解决主从同步延时问题。从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。

MySQL 主从同步延时问题的解决方案：
分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。
打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。
重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。
如果确实是存在必须先插入，立马要求就查询到，然后立马就要反过来执行一些操作，对这个查询设置直连主库。不推荐这种方法，你要是这么搞，读写分离的意义就丧失了。

复制拓扑：一主库多备库，主-主模式下的主-主复制，主-被模式下的主-主复制，拥有备库的主-主结构，环形复制，主库&分发主库&备库，树形，自定义。

读写分离：
主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。
读写分离能提高性能的原因：
主从服务器负责各自的读和写，极大程度缓解了锁的争用；
从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；
增加冗余，提高可用性。

读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。

7.并发一致性问题
丢失修改:T1 和 T2 两个事务都对一个数据进行修改，T1 先修改，T2 随后修改，T2 的修改覆盖了 T1 的修改。
第一类：回滚丢失。第二类：覆盖丢失

读脏数据:T1 修改一个数据，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。
发生在未提交读。数据过期失效会产生脏读。

不可重复读:T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。
发生在未提交读和提交读。不可重复读强调的是修改。

幻读:T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。
发生在未提交读和提交读、可重复读。幻读强调的是插入和删除。

产生并发不一致性问题主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性。并发控制可以通过封锁来实现，但是封锁操作需要用户自己控制，相当复杂。
数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。

8.隔离级别
未提交读（READ UNCOMMITTED）:事务中的修改，即使没有提交，对其它事务也是可见的。
提交读（READ COMMITTED）:一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。大部分数据库系统的隔离级别都是 READ-COMMITTED。
可重复读（REPEATABLE READ）:保证在同一个事务中多次读取同样数据的结果是一样的。MVCC + Next-Key Locks 可以解决幻读问题。MySQL 默认。
可串行化（SERIALIZABLE）:强制事务串行执行。需要加锁实现，而其它隔离级别通常不需要。

9.锁机制
MySQL 中提供了两种封锁粒度：行级锁以及表级锁。应该尽量只锁定需要修改的那部分数据，而不是所有的资源。封锁粒度越小，系统开销就越大。
读写锁：
排它锁（Exclusive），简写为 X 锁，又称写锁。一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。
共享锁（Shared），简写为 S 锁，又称读锁。一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。

意向锁：意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。为了支持多种粒度锁同时存在。解决行表锁冲突。
对于 update、delete 和 insert 语句，innodb 会自动给涉及数据集加排它锁（X）；对于普通 select 语句，innodb 不会加任何锁。

三级封锁协议
一级封锁协议：事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。可以解决丢失修改问题。
二级封锁协议：在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。可以解决读脏数据问题。
三级封锁协议：在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。可以解决不可重复读的问题。

两段锁协议：加锁和解锁分为两个阶段进行，事务遵循两段锁协议是保证可串行化调度的充分非必要条件。
MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定。InnoDB 也可以使用特定的语句进行显示锁定。

隐式锁定：MySQL 的 InnoDB 存储引擎采用两段锁协议，会根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放。
显示锁定：SELECT ... LOCK In SHARE MODE;SELECT ... FOR UPDATE;加的 S 锁和 X 锁。

行锁：锁粒度最小，锁冲突发生的概率最低，支持的并发度也最高，但系统消耗成本也相对较高。加锁慢，会出现死锁。基于索引实现。
InnoDB 行锁是通过给索引上的索引项加锁来实现的，只有通过索引条件检索数据时 InnoDB 才使用行级锁，否则 InnoDB 将使用表锁。只在存储引擎层实现。

Record Locks:锁定一个记录上的索引，而不是记录本身。如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引。
Gap Locks:锁定索引之间的间隙，但是不包含索引本身。阻止多个事务将记录插入到同一范围内，防止幻读问题。

Next-Key Locks 间隙锁：Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。
当查询的索引含有唯一属性时，将 next-key lock 降级为 record key。

BDB 支持页锁，介于表锁和行锁之间，会出现死锁。
更新锁：用来避免先 S 后 X 死锁问题。
一次封锁法：每个事务必须一次将所有要使用的数据全部加锁，否则就不能继续执行。用来预防死锁。
锁根据持续时间还可以分为临时锁和持续锁。

10.多版本并发控制 MVCC
采用 MVCC 来支持高并发比单纯的加锁更高效。行级锁的变种，很多情况下避免了加锁。通过保存在数据的某个时间点的快照来实现的。不管执行多少时间，同一个事务看到的数据都是一致的，多个事务看到同一行数据可能是不同的。
用于隔离每个事物的数据版本，使得多个事物的操作读锁与写锁不冲突，不会互相阻塞。把数据库的行锁与行的多个版本结合起来，只需要很小的开销,就可以实现非锁定读。
MVCC 是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。
MVCC 可以使用 乐观 (optimistic) 锁 和 悲观 (pessimistic) 锁来实现，各数据库中 MVCC 实现并不统一。

版本号
系统版本号：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。
事务版本号：事务开始时的系统版本号。

隐藏的列:MVCC 在每行记录后面都保存着两个隐藏的列，用来存储:
创建版本号：指示创建一个数据行的快照时的系统版本号；
删除版本号：如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。

Undo 日志:MVCC 使用到的快照存储在 Undo 日志中，该日志通过回滚指针把一个数据行（Record）的所有快照连接起来。从 Undo log 读到行的数据和版本，实现非锁定读。

实现过程：SELECT、INSERT、DELETE、UPDATE。
当开始一个事务时，该事务的版本号肯定大于当前所有数据行快照的创建版本号
对于 select：
多个事务必须读取到同一个数据行的快照，并且这个快照是距离现在最近的一个有效快照。但是也有例外，如果有一个事务正在修改该数据行，那么它可以读取事务本身所做的修改，而不用和其它事务的读取结果一致。
把没有对一个数据行做修改的事务称为 T，T 所要读取的数据行快照的创建版本号必须小于等于 T 的版本号，T 所要读取的数据行快照的删除版本号必须是未定义或者大于 T 的版本号。

快照读：使用 MVCC 读取的是快照中的数据，这样可以减少加锁所带来的开销。第一次执行 select 的时候生成快照。
当前读：读取的是最新的数据，需要加锁。Next-Key Locks 实现。

MVCC 不能解决幻影读问题。
MVCC 的适用场景：对读的响应速度和并发性要求比较高，且 retry 代价小。

11.一条 SQL 语句执行得很慢的原因有哪些
大多数情况下很正常，偶尔很慢：
内存中更新的字段不会马上同步持久化到磁盘中去，而是把这些更新的记录写入到 redo log 日记中去，等到空闲的时候，在通过 redo log 里的日记把最新的数据同步到磁盘中去。当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。
1.数据库在刷新脏页 flush：redolog 写满了或内存不够用了
2.执行的时候拿不到锁。

一直执行的很慢：
没有用索引：字段没有索引或有索引却没有用索引（where c - 1 = 1000，字段的左边做了运算就不会用上索引。或 pow(c,2) = 1000，函数操作导致没有用上索引。或未将打算加索引的列设置为 NOT NULL）。
数据库选错了索引：系统会预测导致走全表扫描而不走索引的，根据索引的区分度和基数来判断的，又是根据采样来知道基数的，采样失误就会导致系统就不走索引，直接走全部扫描了。

12.数据库中间件
用来分库分表
数据库分片的两种常见方案
客户端代理：分片逻辑在应用端，封装在 jar 包中，通过修改或者封装 JDBC 层来实现。
中间件代理：在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。

Cobar（阿里），TDDL（淘宝），MySQL Route 官方。
Sharding-jdbc：client 层方案的优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要耦合 Sharding-jdbc 的依赖。
Mycat：proxy 层方案的缺点在于需要部署，自己运维一套中间件，运维成本高，但是好处在于对于各个项目是透明的，如果遇到升级之类的都是自己中间件那里搞就行了。

中小型公司选用 Sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；
但是中大型公司最好还是选用 Mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 Mycat，然后大量项目直接透明使用即可。

13.一条 SQL 语句执行的流程
对于查询
权限校验---》查询缓存---》分析器---》优化器---》权限校验---》执行器---》引擎
客户端发送一条查询给服务器。

服务器先检查查询缓存，如果命中了缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段。MySQL 8.0 版本后移除，因为这个功能不太实用。
具体：查询缓存系统会跟踪查询中涉及的每个表，如果这些表发生了变化，那么和这个表相关的所有缓存数据都将失效。MySQL 将缓存存放在一个引用表中，通过一个哈希值引用。
当判断缓存是否命中时，MySQL 不会进行解析查询语句，而是直接使用 SQL 语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，例如空格、注解等都会导致缓存的不命中。
当查询语句中有一些不确定的数据时，则不会被缓存。但是仍然会查询缓存。
缓存同时也带来了额外的开销，每次查询后都要做一次缓存操作，失效后还要销毁。

服务器端进行 SQL 解析、预处理，再由优化器生成对应的执行计划。具体：
解析器通过关键字将 SQL 语句进行解析，并生成对应的解析树。MySQL 解析器将使用 MySQL 语法规则验证和解析查询。  
预处理器则根据一些 MySQL 规则进行进一步检查解析书是否合法，例如检查数据表和数据列是否存在，还会解析名字和别名，看看它们是否有歧义。
查询优化器会将解析树转化成执行计划。一条查询可以有多种执行方法，最后都是返回相同结果。优化器的作用就是找到这其中最好的执行计划。

MySQL 根据优化器生成的执行计划，再调用存储引擎的 API 来执行查询。连接器、查询缓存、分析器、优化器、执行器都属于 Server 层。引擎层是插件式的。

将结果返回给客户端。
具体：如果查询可以被缓存，那么 MySQL 在这个阶段页会将结果存放到查询缓存中。  
MySQL 将结果集返回给客户端是一个增量、逐步返回的过程。在查询生成第一条结果时，MySQL 就可以开始向客户端逐步返回结果集了。

对于更新
分析器----》权限校验----》执行器---》引擎---redo log prepare---》binlog---》redo log commit
redo log 是 InnoDB 引擎特有的（InnoDB 引擎就是通过 redo log 来支持事务的），其他存储引擎都没有（binlog 所有执行引擎都可以共用），这就导致会没有 crash-safe 的能力 (crash-safe 的能力即使数据库发生异常重启，之前提交的记录都不会丢失)，binlog 日志只能用来归档。
为什么 redo log 要引入 prepare 预提交状态：
先写 redo log 直接提交，然后写 binlog，假设写完 redo log 后，机器挂了，binlog 日志没有被写入，那么机器重启后，这台机器会通过 redo log 恢复数据，但是这个时候 bingog 并没有记录该数据，后续进行机器备份的时候，就会丢失这一条数据，同时主从同步也会丢失这一条数据。
先写 binlog，然后写 redo log，假设写完了 binlog，机器异常重启了，由于没有 redo log，本机是无法恢复这一条记录的，但是 binlog 又有记录，那么和上面同样的道理，就会产生数据不一致的情况。

假设 redo log 处于预提交状态，binglog 也已经写完了，这个时候发生了异常重启会怎么样呢？依赖于 MySQL 的处理机制解决数据一致性问题：
判断 redo log 是否完整，如果判断是完整的，就立即提交。
如果 redo log 只是预提交但不是 commit 状态，这个时候就会去判断 binlog 是否完整，如果完整就提交 redo log, 不完整就回滚事务。

14.binlog，undo log，redo log
二进制日志 binlog 用于记录所有更新且提交了数据或者已经潜在更新提交了数据（例如，没有匹配任何行的一个 DELETE）的所有语句。语句以“事件”的形式保存，它描述数据更改。
binlog 作用：
恢复使能够最大可能地更新数据库，因为二进制日志包含备份后进行的所有更新。
在主复制服务器上记录所有将发送给从服务器的语句。 

回滚日志 undo log 是为了实现事务的原子性。在 MySQL 数据库 InnoDB 存储引擎中，还用 UndoLog 来实现 MVCC。
原理：在操作任何数据之前，首先将数据备份到一个地方（这个存储数据备份的地方称为 UndoLog）。然后进行数据的修改。如果出现了错误或者用户执行了 ROLLBACK 语句，系统可以利用 UndoLog 中的备份将数据恢复到事务开始之前的状态。
除了可以保证事务的原子性，Undo Log 也可以用来辅助完成事务的持久化。
缺陷：每个事务提交前将数据和 Undo Log 写入磁盘，这样会导致大量的磁盘 IO，因此性能很低。

重做日志 redo log 记录的是新数据的备份。在事务提交前，只要将 Redo Log 持久化即可，不需要将数据持久化。当系统崩溃时，虽然数据没有持久化，但是 RedoLog 已经持久化。系统可以根据 RedoLog 的内容，将所有数据恢复到最新的状态。
redo log 包括两部分：一是内存中的日志缓冲 (redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件 (redo log file)，该部分日志是持久的。

binlog 和 redo log 的区别
binlog 是 MySQL Server 层记录的日志，redo log 是 InnoDB 存储引擎层的日志。两者都是记录了某些操作的日志 (不是所有) 自然有些重复（但两者记录的格式不同）。binlog 先于 redo log 被记录。
binlog 属于逻辑日志，基于行格式的记录。innodb redo log 属于物理日志，记录的是数据库中每个页的修改。逻辑日志有个缺点是难以并行，而物理日志可以比较好的并行操作。
binlog 只在每次事务提交的时候一次性写入缓存中的日志"文件"。而 redo log 在数据准备修改前写入缓存中的 redo log 中，然后才对缓存中的数据执行修改操作；而且保证在发出事务提交指令时，先向缓存中的 redo log 写入日志，写入完成后才执行提交动作。
binlog 只在提交的时候一次性写入，所以 binlog 中的记录方式和提交顺序有关，且一次提交对应一次记录。而 redo log 中是记录的物理页的修改，redo log 文件中同一个事务可能多次记录，最后一个提交的事务记录会覆盖所有未提交的事务记录。
binlog 记录的是所有影响数据的操作，记录的内容较多。而 redo log 记录的是物理页的情况，它具有幂等性，因此记录日志的方式极其简练。

undo log 和 redo log 的区别
undo 用来回滚行记录到某个版本。undo log 一般是逻辑日志，根据每行记录进行记录。
redo log 通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页 (恢复数据页，且只能恢复到最后一次提交的位置)。

15.大表优化
当 MySQL 单表记录数过大时，数据库的 CRUD 性能会明显下降，一些常见的优化措施如下：
限定数据的范围
读/写分离 
分库分表
