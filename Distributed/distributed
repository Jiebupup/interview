分布式系统：分布式系统是由一组通过网络进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。分布式系统的出现是为了用廉价的、普通的机器完成单个计算机无法完成的计算、存储任务。其目的是利用更多的机器，处理更多的数据。
集群：每个节点执行相同的任务。

1.分布式锁
数据库唯一索引：创建一张锁表，当需要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录，用这个记录是否存在来判断是否存于锁定状态。
问题：锁没有失效时间，解锁失败的话其它进程无法再获得该锁；只能是非阻塞锁，插入失败直接就报错了，无法重试；不可重入，已经获得锁的进程也必须重新获取锁。

Redis的 SETNX 指令（set if not exist）：指令插入一个键值对，如果 Key 已经存在，那么会返回 False，否则插入成功并返回 True。
保证了只存在一个 Key 的键值对，那么可以用一个 Key 的键值对是否存在来判断是否存于锁定状态。
EXPIRE 指令可以为一个键值对设置一个过期时间，从而避免了数据库唯一索引实现方式中释放锁失败的问题。

Redis 的 RedLock 算法:使用了多个 Redis 实例构成集群来实现分布式锁，这是为了保证在发生单点故障时仍然可用。
尝试从 N 个互相独立 Redis 实例获取锁；
计算获取锁消耗的时间，只有当这个时间小于锁的过期时间，并且从大多数（N / 2 + 1）实例上获取了锁，那么就认为锁获取成功了；
如果锁获取失败，就到每个实例上释放锁。

特性:
安全特性：互斥访问，即永远只有一个 client 能拿到锁
避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区
容错性：只要大部分 Redis 节点存活就可以正常提供服务

Redlock 实在不是一个好的选择，对于需求性能的分布式锁应用它太重了且成本高，对于需求正确性的应用来说它不够安全。
如果你的应用只需要高性能的分布式锁不要求多高的正确性，那么单节点 Redis 够了。如果你的应用想要保住正确性，那么不建议 Redlock，建议使用一个合适的一致性协调系统，例如 Zookeeper，且保证存在 fencing token。

Zookeeper 的有序节点：创建临时序列节点来实现分布式锁，适用于顺序执行的程序。
大致思想为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。

会话超时
如果一个已经获得锁的会话超时了，因为创建的是临时节点，所以该会话对应的临时节点会被删除，其它会话就可以获得锁了。
可以看到，Zookeeper 分布式锁不会出现数据库的唯一索引实现的分布式锁释放锁失败问题。

羊群效应：一个节点未获得锁，只需要监听自己的前一个子节点，这是因为如果监听所有的子节点，那么任意一个子节点状态改变，其它所有子节点都会收到通知（羊群效应），而我们只希望它的后一个子节点收到通知。

Zookeeper性能上不如使用Redis且实现复杂，但是更加可靠。首推Zookeeper。

2.分布式事务
指事务的操作位于不同的节点上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了保证不同数据库的数据一致性。

基于XA协议的2PC两阶段提交：通过引入协调者（Coordinator）来协调参与者的行为，并最终决定这些参与者是否要真正执行事务。
运行过程
准备阶段：协调者询问参与者事务是否执行成功，参与者发回事务执行结果。
提交阶段：如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。

存在的问题：
同步阻塞：所有事务参与者在等待其它参与者响应的时候都处于同步阻塞状态，无法进行其它操作。
单点问题：协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响。特别是在阶段二发生故障，所有参与者会一直等待，无法完成其它操作。
数据不一致：在阶段二，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。
太过保守：任意一个节点失败就会导致整个事务失败，没有完善的容错机制。

3PC：三阶段提交协议是两阶段提交协议的改进版本。它通过超时机制解决了阻塞的问题，并且多了询问阶段（在准备阶段和提交阶段之间）。
询问阶段：协调者询问参与者是否可以完成指令，协调者只需要回答是还是不是，而不需要做真正的操作，这个阶段超时导致中止

2PC和3PC比较：
询问阶段可以确保尽可能早的发现无法执行操作而需要中止的行为，但是它并不能发现所有的这种行为，只会减少这种情况的发生。
在准备阶段以后，协调者和参与者执行的任务中都增加了超时，一旦超时，协调者和参与者都继续提交事务，默认为成功，这也是根据概率统计上超时后默认成功的正确性最大。
但是一旦发生超时，系统仍然会发生不一致，只不过这种情况很少见罢了，好处就是至少不会阻塞和永远锁定资源。

TCC（Try、Confirm、Cancel）：采用的补偿机制
Try阶段：尝试执行,完成所有业务检查（一致性）,预留必须业务资源（准隔离性）
Confirm阶段：确认执行真正执行业务，不作任何业务检查，只使用Try阶段预留的业务资源，Confirm操作满足幂等性。要求具备幂等设计，Confirm失败后需要进行重试。
Cancel阶段：取消执行，释放Try阶段预留的业务资源 Cancel操作满足幂等性Cancel阶段的异常和Confirm阶段异常处理方案基本上一致。

本地消息表：本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终一致性。
在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。
之后将本地消息表中的消息转发到消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。
在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。

MQ事务：RocketMQ支持事务，类似于二阶段提交。
优点：实现了最终一致性，不需要依赖本地数据库事务。
缺点：实现难度大，主流MQ不支持。

3.CAP
一致性（Consistency）：一致性指的是多个数据副本是否能保持一致的特性，在一致性的条件下，系统在执行数据更新操作之后能够从一致性状态转移到另一个一致性状态。对系统的一个数据更新成功之后，如果所有用户都能够读取到最新的值，该系统就被认为具有强一致性。
可用性（Availability）：可用性指分布式系统在面对各种异常时可以提供正常服务的能力，在可用性条件下，要求系统提供的服务一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。  
分区容忍性（Partition Tolerance）：分布式系统在遇到任何网络分区故障的时候，仍然需要能对外提供一致性和可用性的服务。

在分布式系统中，分区容忍性必不可少，可用性和一致性往往是冲突的。
CP：不能访问未同步完成的节点，也就失去了部分可用性。
AP：允许读取所有节点的数据，但是数据可能不一致。

4.BASE
基本可用（Basically Available）：指分布式系统在出现故障的时候，保证核心可用，允许损失部分可用性。
软状态（Soft State）：指允许系统中的数据存在中间状态，并认为该中间状态不会影响系统整体可用性，即允许系统不同节点的数据副本之间进行同步的过程存在时延。
最终一致性（Eventually Consistent）：最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能达到一致的状态。

BASE 理论是对 CAP 中一致性和可用性权衡的结果，它的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。
ACID 要求强一致性，通常运用在传统的数据库系统上。而 BASE 要求最终一致性，通过牺牲强一致性来达到可用性，通常运用在大型分布式系统中。
在实际的分布式场景中，不同业务单元和组件对一致性的要求是不同的，因此 ACID 和 BASE 往往会结合在一起使用。

针对数据库领域，BASE思想的主要实现是对业务数据进行拆分，让不同的数据分布在不同的机器上，以提升系统的可用性。拆分后会涉及分布式事务问题。

5.分布式一致性算法
Paxos：用于达成共识性问题，即对多个节点产生的值，该算法能保证只选出唯一一个值。
Raft：竞选主节点。

6.负载均衡
集群中的应用服务器（节点）通常被设计成无状态，用户可以请求任何一个节点。负载均衡器会根据集群中每个节点的负载情况，将用户请求转发到合适的节点上。
负载均衡器可以用来实现高可用以及伸缩性。
高可用：当某个节点故障时，负载均衡器会将用户请求转发到另外的节点上，从而保证所有服务持续可用；
伸缩性：根据系统整体负载情况，可以很容易地添加或移除节点。

负载均衡算法
轮询（Round Robin）：把每个请求轮流发送到每个服务器上。
该算法比较适合每个服务器的性能差不多的场景，如果有性能存在差异的情况下，那么性能较差的服务器可能无法承担过大的负载。

加权轮询（Weighted Round Robbin）：在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值，性能高的服务器分配更高的权值。

由于每个请求的连接时间不一样，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数过大，而另一台服务器的连接过小，造成负载不均衡。

最少连接（least Connections）：将请求发送给当前最少连接数的服务器上。

加权最少连接（Weighted Least Connection）：在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。

随机算法（Random）：和轮询算法类似，该算法比较适合服务器性能差不多的场景。

源地址哈希法 (IP Hash)：源地址哈希通过对客户端 IP 计算哈希值之后，再对服务器数量取模得到目标服务器的序号。
可以保证同一 IP 的客户端的请求会转发到同一台服务器上，用来实现会话粘滞（Sticky Session）

转发实现
HTTP 重定向：HTTP 重定向负载均衡服务器使用某种负载均衡算法计算得到服务器的 IP 地址之后，将该地址写入 HTTP 重定向报文中，状态码为 302。客户端收到重定向报文之后，需要重新向服务器发起请求。
缺点：
需要两次请求，因此访问延迟比较高；HTTP 负载均衡器处理能力有限，会限制集群的规模。
实际场景中很少使用。

DNS 域名解析：在 DNS 解析域名的同时使用负载均衡算法计算服务器 IP 地址。
优点：DNS 能够根据地理位置进行域名解析，返回离用户最近的服务器 IP 地址。
缺点：由于 DNS 具有多级结构，每一级的域名记录都可能被缓存，当下线一台服务器需要修改 DNS 记录时，需要过很长一段时间才能生效。 
大型网站基本使用了 DNS 作为第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡。也就是说，域名解析的结果为内部的负载均衡服务器 IP 地址。

反向代理服务器：反向代理服务器位于源服务器前面，用户的请求需要先经过反向代理服务器才能到达源服务器。反向代理可以用来进行缓存、日志记录等，同时也可以用来做为负载均衡服务器。
在这种负载均衡转发方式下，客户端不直接请求源服务器，因此源服务器不需要外部 IP 地址，而反向代理需要配置内部和外部两套 IP 地址。
优点：与其它功能集成在一起，部署简单。
缺点：所有请求和响应都需要经过反向代理服务器，它可能会成为性能瓶颈。

网络层：在操作系统内核进程获取网络数据包，根据负载均衡算法计算源服务器的 IP 地址，并修改请求数据包的目的 IP 地址，最后进行转发。
源服务器返回的响应也需要经过负载均衡服务器，通常是让负载均衡服务器同时作为集群的网关服务器来实现。
优点：在内核进程中进行处理，性能比较高。  
缺点：和反向代理一样，所有的请求和响应都经过负载均衡服务器，会成为性能瓶颈。

链路层：在链路层根据负载均衡算法计算源服务器的 MAC 地址，并修改请求数据包的目的 MAC 地址，并进行转发。
通过配置源服务器的虚拟 IP 地址和负载均衡服务器的 IP 地址一致，从而不需要修改 IP 地址就可以进行转发。也正因为 IP 地址一样，所以源服务器的响应不需要转发回负载均衡服务器，可以直接转发给客户端，避免了负载均衡服务器的成为瓶颈。
这是一种三角传输模式，被称为直接路由。对于提供下载和视频服务的网站来说，直接路由避免了大量的网络传输数据经过负载均衡服务器。
这是目前大型网站使用最广负载均衡转发方式，在 Linux 平台可以使用的负载均衡服务器为 LVS（Linux Virtual Server）。

7.如何设计一个高并发系统？
高峰期每秒并发量千万级，读多写少
  
dubbo系统拆分，每个系统连一个数据库
redis缓存，读的时候大量走缓存
MQ，大量的写请求灌入 MQ 里排队，控制在 mysql 承载范围之内
分库分表
读写分离
ElasticSearch

8.分布式计算
数据在各个计算机节点上流动，同时各个计算机节点都能以某种方式访问共享数据，最终分布式计算后的输出结果被持久化存储和输出。

Actor
并行计算模型，异步并发。
并行计算原语：一个Actor对接收到的消息做出响应，进行本地决策，可以创建更多的Actor（子Actor），或者发送更多的消息；同时准备接收下一条消息。
优点：
1）将消息收发、线程调度、处理竞争和同步的所有复杂逻辑都委托给了Actor框架本身，而且对应用来说是透明的，我们可以认为Actor只是一个实现了Runnable接口的对象。关注多线程并发问题时，只需要关注多个Actor之间的消息流即可。 
2）符合Actor模型的程序很容易进行测试，因为任意一个Actor都可以被单独进行单元测试。如果测试案例覆盖了该Actor所能响应的所有类型的消息，我们就可以确定该Actor的代码十分可靠。

缺点：
1) Actor完全避免共享并且仅通过消息来进行交流，使得程序失去了精细化并发调控能力，所以不适合实施细粒度的并行且可能导致系统响应时延的增加。如果在Actor程序中引入一些并行框架，就可能会导致系统的不确定性。 
2）尽管使用Actor模型的程序 比使用线程和锁模型的程序更容易调试，Actor模型仍会碰到死锁这一类的共性问题，也会碰到一些Actor模型独有的问题（例如信箱移溢出）。

AKKA
Akka 是一个用 Scala 编写的库，用于简化编写容错的、高可伸缩性的 Java 和 Scala 的 Actor 模型应用。
Akka处理并发的方法基于Actor模型。在Akka里，Actor之间通信的唯一机制就是消息传递。
好处：
AKKA提供一种Actor并发模型，其粒度比线程小很多，这意味着你可以在项目中使用大量的Actor。
Akka提供了一套容错机制，允许在Actor出错时进行一些恢复或者重置操作
AKKA不仅可以在单机上构建高并发程序，也可以在网络中构建分布式程序，并提供位置透明的Actor定位服务

Storm
提供的是面向连续的消息流（Stream）的一种通用的分布式计算解决框架。实时流式计算。
应用场景：日志处理和电商商品推荐
Hadoop 是强大的大数据处理系统（批处理），但是在实时计算方面不够擅长；Storm的核心功能就是提供强大的实时处理能力，但没有涉及存储；所以 Storm 与 Hadoop 互补。

MapReduce
用于大规模数据集的并行运算
“分而治之”，Mapper负责“分”，即把复杂的大任务分解为若干个小任务来处理，彼此之间没有依赖关系，以便可以分布到多个计算节点上实现高度的并行计算能力；Reducer则负责对map阶段的结果进行汇总和输出。
这个框架充分利用了磁盘，处处存在着排序和合并。所以适合于实时性不高的离线计算。
Hadoop

Spark
Spark使用了存储器内运算技术，能在数据尚未写入硬盘时即在存储器内分析运算。Spark允许用户将数据加载至集群存储器，并多次对其进行查询，非常适合用于机器学习算法。内存计算框架，适合在线、离线快速的大数据处理。
