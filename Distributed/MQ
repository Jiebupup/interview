1.简介
消息队列 MQ 是一种进程间通信或同一进程的不同线程间的通信方式，软件的贮列用来处理一系列的输入，通常是来自用户。
消息队列提供了异步的通信协议，每一个贮列中的纪录包含详细说明的数据，包含发生的时间，输入设备的种类，以及特定的输入参数，也就是说：消息的发送者和接收者不需要同时与消息队列交互。消息会保存在队列中，直到接收者取回它。

请求服务方把请求队列放到队列中即可返回，然后等待服务提供方去队列中获取请求进行处理，之后通过回调等机制把结果返回给请求服务方。
MQ 用在解决分布式事务上，达到最终一致性。
不推荐用 Redis 做消息队列。

JMS 消息模型
点对点：消息生产者向消息队列中发送了一个消息之后，只能被一个消费者消费一次。队列作为消息通信载体，满足生产者与消费者模式。
发布/订阅：消息生产者向频道发送一个消息之后，多个消费者可以从该频道订阅到这条消息并消费。主题 Topic 作为消息通信载体，类似于广播模式。

消息队列两者都是用到，比较常用的是发布-订阅模式。
事件驱动架构。对新增业务，只要对该类消息感兴趣，即可订阅该消息，对原有系统和业务没有任何影响，从而实现网站业务的可扩展性设计。

发布与订阅模式 Pub-Sub 和观察者模式 Observer 有以下不同：
观察者模式中，观察者和主题都知道对方的存在；而在发布与订阅模式中，生产者与消费者不知道对方的存在，它们之间通过频道进行通信。
观察者模式是同步的，当事件触发时，主题会调用观察者的方法，然后等待方法返回；而发布与订阅模式是异步的，生产者向频道发送一个消息之后，就不需要关心消费者何时去订阅这个消息，可以立即返回。

JMS 和 AMQP
JMS：Java 消息服务，JMS 的客户端之间可以通过 JMS 服务进行异步的消息传输。JMS API 是一个消息服务的标准或者说是规范，允许应用程序组件基于 JavaEE 平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。尽管 JMS 规范出台已经是很久的事情了,但是 JMS 在当今的 J2EE 应用中间仍然扮演着特殊的地位。
AMQP：高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计，兼容 JMS。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件同产品，不同的开发语言等条件的限制。

区别：
AMQP 为消息定义了线路层的协议，而 JMS 所定义的是 API 规范。
AMQP 天然具有跨平台、跨语言特性。在 Java 体系中，多个 client 均可以通过 JMS 进行交互，不需要应用修改代码，但是其对跨平台的支持较差。
AMQP 仅支持 byte[] 消息类型（复杂的类型可序列化后发送），而 JMS 支持 TextMessage、MapMessage 等复杂的消息类型。
AMQP 可以提供多样化的路由方式来传递消息到消息队列，而 JMS 仅支持队列和主题/订阅方式两种。

2.使用场景(为什么使用消息队列|好处)
异步处理：发送者将消息发送给消息队列之后，不需要同步等待消息接收者处理完毕，而是立即返回进行其它操作。消息接收者从消息队列中订阅消息之后异步处理。
流量削峰：在高并发的场景下，如果短时间有大量的请求到达会压垮服务器。可以将请求发送到消息队列中，服务器按照其处理能力从消息队列中订阅消息进行处理。
应用解耦：模块之间不直接进行调用，模块之间耦合度很低，修改一个模块或者新增一个模块对其它模块的影响会很小，从而实现可扩展性。通过使用消息队列，一个模块只需要向消息队列中发送消息，其它模块可以选择性地从消息队列中订阅消息从而完成调用。

其中异步达到了削峰的效果。只有在业务流程允许异步处理的情况下才能这么做。通过异步处理提高系统性能（削峰、减少响应所需时间）。
消息队列服务器处理速度快于数据库，也比数据库有更好的伸缩性，因此响应速度得到大幅改善。
用户请求数据写入消息队列之后就立即返回给用户了，但是请求数据在后续的业务校验、写数据库等操作中可能失败。因此使用消息队列进行异步处理之后，需要适当修改业务流程进行配合。
比如用户在提交订单之后，订单数据写入消息队列，不能立即返回用户订单提交成功，需要在消息队列的订单消费者进程真正处理完该订单之后，甚至出库后，再通过电子邮件或短信通知用户订单成功。
为了避免消息队列服务器宕机造成消息丢失，会将成功发送到消息队列的消息存储在消息生产者服务器上，等消息真正被消费者服务器处理后才删除消息。

坏处：系统可用性降低，复杂度提高，带来一致性问题。

3.可靠性
发送端：发送端完成操作后一定能将消息成功发送到消息队列中。
实现方法：在本地数据库建一张消息表，将消息数据与业务数据保存在同一数据库实例里，这样就可以利用本地数据库的事务机制。事务提交成功后，将消息表中的消息转移到消息队列中，若转移消息成功则删除消息表中的数据，否则继续重传。

接收端：接收端能够从消息队列成功消费一次消息。
实现方法：保证接收端处理消息的业务逻辑具有幂等性：只要具有幂等性，那么消费多少次消息，最后处理的结果都是一样的；保证消息具有唯一编号，并使用一张日志表来记录已经消费的消息编号。

4.常见消息队列 ActiveMQ、RabbitMQ、RocketMQ、Kafka 比较
ActiveMQ：Apache 出品
吞吐量比 RocketMQ、Kafka 低
延迟 ms 级
基于主从架构实现高可用	
有较低的概率丢失数据
MQ 领域的功能极其完备
基于 JMS 规范实现
社区比较成熟，版本迭代很慢，性能最差，流行

RabbitMQ：Erlang 语言开发
吞吐量比 RocketMQ、Kafka 低
延迟 us 级，延迟最低，这是 RabbitMQ 的一大特点
基于主从架构实现高可用
有较低的概率丢失数据
并发能力很强，性能极其好
RabbitMQ 有稳定的支持，活跃度也高
基于 AMQP 协议实现

RocketMQ：阿里出品，Java 系开源项目
高吞吐，topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic
延迟 ms 级
可用性高，分布式架构
消息可靠性高，经过参数优化配置可以做到 0 丢失
MQ 功能较为完善，扩展性好
活跃度不算高，有风险
接口这块不是按照标准 JMS 规范走的，有些系统要迁移需要修改大量代码
RocketMQ 思路起源于 Kafka，具有高吞吐量、高可用性、适合大规模分布式系统应用的特点

RocketMQ 用 2PC 实现分布式消息。
RocketMQ 不使用 ZooKeeper 作为注册中心，而使用自制的 NameServer。
ZooKeeper 支持顺序一致性，在某些情况下，它为了满足一致性，会丢失一定时间内的可用性。RocketMQ 需要注册中心只是为了发现组件地址，在某些情况下，NameServer 可以出现数据不一致性，因为 NameServer 集群间互不通信。 当有新的服务器加入时，NameServer 并不会立马通知到 Produer，而是由 Produer 定时去请求 NameServer 获取最新的 Broker/Consumer 信息（这种情况是通过 Producer 发送消息时，负载均衡解决）。
组件通信间使用 Netty 的自定义协议。
Dubbo 负载均衡策略。
消息过滤器：Producer 发送消息到 Broker，Broker 存储消息信息，Consumer 消费时请求 Broker 端从磁盘文件查询消息文件时,在 Broker 端就使用过滤服务器进行过滤。
Broker 同步双写和异步双写中 Master 和 Slave 的交互。
Broker 在 4.5.0 版本更新中引入了基于 Raft 协议的多副本选举。
消息丢失：当你系统需要保证百分百消息不丢失，你可以使用生产者每发送一个消息，Broker 同步返回一个消息发送成功的反馈消息。即每发送一个消息，同步落盘后才返回生产者消息发送成功，这样只要生产者得到了消息发送生成的返回，事后除了硬盘损坏，都可以保证不会消息丢失。
加快同步落盘：使用 FileChannel + DirectBuffer 池，使用堆外内存，加快内存拷贝。使用数据和索引分离，当消息需要写入时，使用 commitlog 文件顺序写，当需要定位某个消息时，查询 index 文件来定位，从而减少文件 IO 随机读写的性能损耗。
消息堆积：后台定时任务每隔 72 小时，删除旧的没有使用过的消息信息。根据不同的业务实现不同的丢弃任务。消息定时转移，或者对某些重要的 TAG 型（支付型）消息真正落库。
定时消息：newSingleThreadScheduledExecutor 定时执行任务。
顺序消息：MessageQueue，锁。
消息的 push 延迟问题：因为这并不是真正的将消息主动的推送到消费者，而是 Broker 定时任务每 5s 将消息推送到消费者。
消息重复发送的避免：由于网络延迟不可避免，默认允许消息重复发送。RocketMQ 让使用者在消费者端去解决该问题。最简单的解决方案是每条消费记录有个消费状态字段，根据这个消费状态字段来是否消费或者使用一个集中式的表，来存储所有消息的消费状态，从而避免重复消费。
广播消费与集群消费：广播消费，订阅该 Topic 的消息者们都会消费每个消息，每个消费者都独立的去消费每个消息，因此每个消费者各自保存自己的消息消费进度。集群消费，订阅该 Topic 的消息者们只会有一个去消费某个消息，总体的消费进度保存在 Broker 上集中的管理。

Kafka：
和 RocketMQ 相似，功能较为简单，主要支持简单的 MQ 功能。
大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准，社区活跃度很高。
Kafka 主要特点是基于 Pull 的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输。0.8 版本开始支持复制，不支持事务，对消息的重复、丢失、错误没有严格要求，适合产生大量数据的互联网服务的数据收集业务。
同时 kafka 最好是支撑较少的 topic 数量即可，保证其超高吞吐量。
kafka 唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响。
基于发布/订阅。

topic：消息的主题、队列，每一个消息都有它的topic，Kafka 通过 topic 对消息进行归类。Kafka 中可以将 topic 从物理上划分成一个或多个分区 partition，每个分区在物理上对应一个文件夹，以 ”topicName_partitionIndex” 的命名方式命名，该 dir 包含了这个分区的所有消息（.log）和索引文件（.index），这使得 Kafka 的吞吐率可以水平扩展。
partition：每个分区都是一个顺序的、不可变的消息队列，并且可以持续的添加。分区中的消息都被分了一个序列号，称之为偏移量 offset，在每个分区中此偏移量都是唯一的。producer 在发布消息的时候，可以为每条消息指定 key，这样消息被发送到 broker 时，会根据分区算法把消息存储到对应的分区中（一个分区存储多个消息），如果分区规则设置的合理，那么所有的消息将会被均匀的分布到不同的分区中，这样就实现了负载均衡。 
broker：Kafka server，用来存储消息，Kafka 集群中的每一个服务器都是一个 broker，消费者将从 broker 拉取订阅的消息 producer 向 Kafka 发送消息，生产者会根据 topic 分发消息。生产者也负责把消息关联到 topic 上的哪一个分区。最简单的方式从分区列表中轮流选择。也可以根据某种算法依照权重选择分区。算法可由开发者定义。
cousumer：consermer 实例可以是独立的进程，负责订阅和消费消息。消费者用 consumerGroup 来标识自己。同一个消费组可以并发地消费多个分区的消息，同一个 partition 也可以由多个 consumerGroup 并发消费，但是在 consumerGroup 中一个 partition 只能由一个 consumer 消费。同一个 consumerGroup 中的 consumers，Kafka 将相应 topic 中的每个消息只发送给其中一个 consumer。

Kafka producer 发送消息的流程：序列化消息和计算 partition，发送到 batch 和唤醒 sender 线程，确定 tp relica leader 所在的 broker 和 sender 有序&幂等性发送消息，sender 处理 broker 发来的 produce response。
sender 线程和长连接：每初始化一个 producer 实例，都会初始化一个 sender 实例，新增到 broker 的长连接。

consumer：
poll 消息
位移管理
Kafka group 状态
重平衡 reblance，过程&存在的问题&改进

broker：
broker zk 注册
broker 消息存储
broker 状态数据
broker 负载均衡

Kafka 高可用：Isr 动态更新，controller 负责 broker 故障检查&&故障转移（fail/recover），controller 挂掉。
幂等性：consumer 拉取到消息先保存，commit 成功后删除缓存数据。
可靠性：首先 kafka 保证了对已提交消息的 at least 保证 sender 有重试机制 producer 业务方在使用 producer 发送消息时，注册回调函数。在 onError 方法中重发消息 consumer 拉取到消息后，处理完毕再 commit，保证 commit 的消息一定被处理完毕。
高性能：partition 提升了并发，zero-copy 顺序写入，消息聚集 batch，页缓存，业务方对 Kafka producer的优化。增大 producer 数量，ack 配置，batch。

5.如何保证高可用
RabbitMQ 的高可用性（主从式）：
单机模式
普通集群模式：普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。
没做到分布式，无高可用，主要为了提高吞吐量。要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。

镜像集群模式：真正的高可用。创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。
性能开销太大，不是分布式，不能扩展。

Kafka 的高可用性（分布式）：
Kafka 由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。天然的分布式消息队列。
Kafka 0.8 以后，提供了 HA 机制，就是 replica（复制品） 副本机制：每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。
写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。写每个 follower 时就要 care 数据一致性的问题。Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。
如果某个 broker 宕机了，没事儿，那个 broker上面的 partition 在其他机器上都有副本的。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中重新选举一个新的 leader 出来，大家继续读写那个新的 leader 即可。
写数据的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。
消费的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。

6.如何保证消息消费的幂等性（不被重复消费）
Kafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，每隔一段时间（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。

要是消费到第二次的时候，自己判断一下是否已经消费过了，若是就直接扔了，这样不就保留了一条数据，从而保证了数据的正确性。
数据要写库，先根据主键查一下，如果这数据都有了，就别插入了，update 一下。
写 Redis，每次都是 set，天然幂等性。
让生产者发送每条数据的时候，里面加一个全局唯一的 id。消费前查一下之前有没有消费过。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

7.如何保证消息的可靠性传输（处理消息丢失的问题）
RabbitMQ：
生产者弄丢了数据：事务机制（同步Rollback和Commit，导致吞吐量下降，性能降低）和confirm机制（异步消息回调）。一般在生产者避免数据丢失，都是用 confirm 机制的。               
RabbitMQ 弄丢了数据：开启 RabbitMQ 的持久化，故障恢复。可以跟生产者那边的 confirm 机制配合起来,只有消息被持久化到磁盘之后，才会通知生产者 ack。                            
消费端弄丢了数据：ack 机制。

Kafka：
生产者设置了 acks=all，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。。
Kafka 弄丢了数据: leader 所在的 broker 宕机，重新选举 leader 的过程中有 follower 刚好还有些数据没有同步。配置 topic,Kafka 服务端,producer 端。
消费端弄丢了数据:关闭自动提交 offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。此时可能会有重复消费，需要自己保证幂等性。

8.如何保证消息的顺序性？
RabbitMQ：拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。 
Kafka：
一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。
写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。

9.如何解决大量消息在 mq 里积压
先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。
新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。
然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。
接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。
等快速消费完积压数据之后，得恢复原先部署的架构

mq 中的消息过期失效了导致数据丢失：批量重导，把丢失的数据补回来

10.让你写一个消息队列，该如何进行架构设计？
可伸缩性：需要的时候快速扩容以增加吞吐量和容量。参考kakfa分布式系统，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，给 topic 增加 partition，然后做数据迁移，增加机器。
持久化：保证数据不会丢失，顺序I/O读写性能高。磁盘随机读写有寻址开销。
可用性：多副本 -> leader&follower -> broker 挂了重新选举 leader。
可靠性

11.RabbitMQ
Exchange：
生产者与消费者模型，Producer->Exchange->Queue->Consumer。更像是一种交换机模型。
交换器 Exchange 用来接收生产者发送的消息并将这些消息路由给服务器中的队列中，如果路由不到，或许会返回给生产者 Producer，或许会被直接丢弃掉。
RabbitMQ 的 Exchange 有 4 种类型，不同的类型对应着不同的路由策略：direct（默认），fanout，topic，和 headers（不推荐）。AMQP 规范里还提到两种 Exchange Type，分别为 system 与自定义。
生产者将消息发给交换器的时候，一般会指定一个路由键 RoutingKey，用来指定这个消息的路由规则，而这个 RoutingKey 需要与交换器类型和绑定键 BindingKey 联合使用才能最终生效。
RabbitMQ 中通过绑定 Binding 将 Exchange 与消息队列 Queue 关联起来，在绑定的时候一般会指定一个 BindingKey，这样 RabbitMQ 就知道如何正确将消息路由到队列了。
可以将交换器理解成一个由绑定构成的路由表。Exchange 和 Queue 的绑定可以是多对多的关系。当 BindingKey 和 RoutingKey 相匹配时，消息会被路由到对应的队列中。

Queue：
Queue 用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。消息一直在队列里面，等待消费者连接到这个队列将其取走。
RabbitMQ 中消息只能存储在队列中，这一点和 Kafka 这种消息中间件相反。Kafka 将消息存储在主题 topic 这个逻辑层面，而相对应的队列逻辑只是 topic 实际存储文件中的位移标识。
一个消息可投入一个或多个队列。多个消费者可以订阅同一个队列，这时队列中的消息会被平均分摊（Round-Robin，即轮询）给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理，这样避免的消息被重复消费。RabbitMQ 不支持队列层面的广播消费。

Broker：消息中间件的服务节点或者服务实例，大多数情况下也可以将一个 RabbitMQ Broker 看作一台 RabbitMQ 服务器。

12.RocketMQ






