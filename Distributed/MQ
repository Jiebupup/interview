1.消息模型
点对点：消息生产者向消息队列中发送了一个消息之后，只能被一个消费者消费一次。
发布/订阅：消息生产者向频道发送一个消息之后，多个消费者可以从该频道订阅到这条消息并消费。
发布与订阅模式和观察者模式有以下不同：
观察者模式中，观察者和主题都知道对方的存在；而在发布与订阅模式中，生产者与消费者不知道对方的存在，它们之间通过频道进行通信。
观察者模式是同步的，当事件触发时，主题会调用观察者的方法，然后等待方法返回；而发布与订阅模式是异步的，生产者向频道发送一个消息之后，就不需要关心消费者何时去订阅这个消息，可以立即返回。

2.使用场景(为什么使用消息队列|好处)
异步处理：发送者将消息发送给消息队列之后，不需要同步等待消息接收者处理完毕，而是立即返回进行其它操作。消息接收者从消息队列中订阅消息之后异步处理。
流量削锋：在高并发的场景下，如果短时间有大量的请求到达会压垮服务器。可以将请求发送到消息队列中，服务器按照其处理能力从消息队列中订阅消息进行处理。
应用解耦：采用Pub/Sub 发布订阅模型，模块之间不直接进行调用，模块之间耦合度很低，修改一个模块或者新增一个模块对其它模块的影响会很小，从而实现可扩展性。通过使用消息队列，一个模块只需要向消息队列中发送消息，其它模块可以选择性地从消息队列中订阅消息从而完成调用。

坏处：系统可用性降低，复杂度提高，带来一致性问题

3.可靠性
发送端：在本地数据库建一张消息表，将消息数据与业务数据保存在同一数据库实例里，这样就可以利用本地数据库的事务机制。事务提交成功后，将消息表中的消息转移到消息队列中，若转移消息成功则删除消息表中的数据，否则继续重传。
接收端：保证接收端处理消息的业务逻辑具有幂等性：只要具有幂等性，那么消费多少次消息，最后处理的结果都是一样的；保证消息具有唯一编号，并使用一张日志表来记录已经消费的消息编号。

4.Kafka、ActiveMQ、RabbitMQ、RocketMQ比较
ActiveMQ：
吞吐量比RocketMQ、Kafka 低
延迟ms级
基于主从架构实现高可用	
有较低的概率丢失数据
MQ 领域的功能极其完备

RabbitMQ：
吞吐量比RocketMQ、Kafka 低
延迟us级，延迟最低，这是 RabbitMQ 的一大特点
基于主从架构实现高可用
基本不丢失数据
基于 erlang 开发，并发能力很强，性能极好，延时很低
RabbitMQ有稳定的支持，活跃度也高

RocketMQ：
高吞吐
topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic
延迟ms级
可用性高，分布式架构
消息可靠性高，经过参数优化配置可以做到 0 丢失
MQ 功能较为完善，扩展性好
阿里出品，活跃度不算高，有风险

Kafka：
和RocketMQ相似，功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用
大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准。社区活跃度很高

5.如何保证高可用
RabbitMQ 的高可用性（主从式）：
单机模式
普通集群模式：普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。
没做到分布式，无高可用，主要为了提高吞吐量

镜像集群模式：真正的高可用。创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。
性能开销太大，不是分布式，不能扩展

Kafka 的高可用性（分布式）：
一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据。
副本机制保证高可用：如果某个 broker 宕机了，没事儿，那个 broker上面的 partition 在其他机器上都有副本的。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中重新选举一个新的 leader 出来，大家继续读写那个新的 leader 即可。

6.如何保证消息消费的幂等性（不被重复消费）
数据要写库，先根据主键查一下，如果这数据都有了，就别插入了，update 一下。
写 Redis，每次都是 set，天然幂等性。
让生产者发送每条数据的时候，里面加一个全局唯一的 id。消费前查一下之前有没有消费过。
基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

7.如何保证消息的可靠性传输（处理消息丢失的问题）
RabbitMQ：
生产者弄丢了数据：事务机制（同步）和confirm机制（异步）。一般在生产者这块避免数据丢失，都是用 confirm 机制的。
               
RabbitMQ 弄丢了数据：开启 RabbitMQ 的持久化。可以跟生产者那边的 confirm 机制配合起来。               
               
消费端弄丢了数据：ack 机制

Kafka：

               
               


