1.简介
Redis 是速度非常快的非关系型（NoSQL）内存键值数据库。  
键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。
Redis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能。

缓存的目的：高性能与高并发
缓存是走内存的，内存天然就支撑高并发。
命中率：当某个请求能够通过访问缓存而得到响应时，称为缓存命中。缓存命中率越高，缓存的利用率也就越高。
最大空间：缓存通常位于内存中，内存的空间通常比磁盘空间小的多，缓存的最大空间不可能非常大。当缓存存放的数据量超过最大空间时，就需要淘汰部分数据来存放新到达的数据。

2.数据类型&数据结构
数据类型
字符串、列表、集合、散列表、有序集合
STRING、LIST、SET（去重，交集、并集、差集）、HASH、ZSET（排序）

数据结构
字典dict：dictht 是一个散列表结构，使用拉链法保存哈希冲突。

跳跃表：是有序集合的底层实现之一（加散列表）
基于多指针有序链表实现的，可以看成多个有序链表。在查找时，从上层指针开始查找，找到对应的区间之后再到下一层去查找。
与红黑树等平衡树相比的优点：
插入速度非常快速，因为不需要进行旋转等操作来维护平衡性；
更容易实现；
支持无锁操作。

3.使用场景&缓存位置
使用场景
计数器，缓存，查找表，消息队列，会话缓存，分布式锁实现
LIST可以实现分页查询，Set 可以实现共同好友等功能，ZSet 可以实现排行榜等功能。

缓存位置
浏览器、ISP、反向代理、本地缓存、分布式缓存、数据库缓存、Java 内部的缓存、CPU 多级缓存

4.Redis 与 Memcached
两者都是非关系型内存键值数据库（分布式缓存），主要有以下不同：
redis 实际上是个单线程的多路 IO 复用模型（redis 内部使用文件事件处理器 file event handler是单线程的），Memcached是多线程的非阻塞IO复用的网络模型。
redis 原生支持集群模式，而memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。
redis 只使用单核，而 memcached 可以使用多核。
Memcached 仅支持字符串类型，而Redis有多种数据类型。
Redis 支持两种持久化策略：RDB 快照和 AOF 日志，而 Memcached 不支持持久化。
Memcached 不支持分布式，只能通过在客户端使用一致性哈希来实现分布式存储，这种方式在存储和查询时都需要先在客户端计算一次数据所在的节点。Redis Cluster 实现了分布式的支持。
在 Redis 中，并不是所有数据都一直存储在内存中，可以将一些很久没用的 value 交换到磁盘，而 Memcached 的数据则会一直在内存中。Memcached 将内存分割成特定长度的块来存储数据，以完全解决内存碎片的问题。但是这种方式会使得内存的利用率不高。

Java 自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。

5.键的过期时间
Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。
对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。

6.数据淘汰策略
redis 过期策略是：定期删除+惰性删除。
大量过期key堆积在内存里，导致 redis 内存块耗尽了走数据淘汰策略。
可以设置内存最大使用量，当内存使用量超出时，会施行数据淘汰策略。作为内存数据库，出于对性能和内存消耗的考虑，Redis 的淘汰算法实际实现上并非针对所有 key，而是抽样一小部分并且从中选出被淘汰的 key。

volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰
volatile-random：从已设置过期时间的数据集中任意选择数据淘汰
allkeys-lru：从所有数据集中挑选最近最少使用的数据淘汰
allkeys-random：从所有数据集中任意选择数据进行淘汰
noeviction：禁止驱逐数据

使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略
Redis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。

LRU：基于 双向链表 + HashMap
链表尾部存储的就是最近最久未使用的节点，头部存储最新节点。
get()和put()在O(1)时间完成

7.持久化
Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。
RDB 快照：将某个时间点的所有数据都存放到硬盘上。可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。如果系统发生故障，将会丢失最后一次创建快照之后的数据。如果数据量很大，保存快照的时间会很长。
AOF 文件：将写命令添加到 AOF 文件（Append Only File）的末尾，用来记录数据发生的变化。使用 AOF 持久化需要设置同步选项（always，everysec，no）。随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。

8.事务&事件
事务
多个命令被一次性发送给服务器，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能。
Redis 最简单的事务实现方式是使用 MULTI 和 EXEC 命令将事务操作包围起来。watch

事件
Redis 服务器是一个事件驱动程序。
文件事件，时间事件，事件的调度与执行

9.复制
主从架构，读写分离，支撑读高并发。建议开启 master node 的持久化和备份。支持主从复制的断点续传。无磁盘化复制，master 在内存中直接创建 RDB，然后发送给 slave。
通过使用 slave of host port 命令来让一个服务器成为另一个服务器的从服务器，采用异步方式复制数据到 slave 节点。一个从服务器只能有一个主服务器，并且不支持主主复制。
连接过程：
主服务器创建快照文件，发送给从服务器，并在发送期间使用缓冲区记录执行的写命令。快照文件发送完毕之后，开始向从服务器发送存储在缓冲区中的写命令；
从服务器丢弃所有旧数据，载入主服务器发来的快照文件，之后从服务器开始接受主服务器发来的写命令；
主服务器每执行一次写命令，就向从服务器发送相同的写命令。

随着负载不断上升，形成主从链。
复制会带来数据一致性问题。

通过主从架构的切换和哨兵实现高可用。

10.哨兵
Sentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。
功能：集群监控、消息通知、故障转移、配置中心
哨兵本身也是分布式的

11.分片
分片是将数据划分为多个部分的方法，可以将数据存储到多台机器里面，这种方法在解决某些问题时可以获得线性级别的性能提升。
范围分片、哈希分片
客户端分片、代理分片、服务器分片

12.redis cluster
集群元数据的维护有两种方式：集中式、Gossip 协议。redis cluster 节点间采用 gossip 协议进行通信。
gossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。

分布式寻址算法：hash 算法、一致性 hash 算法、redis cluster 的 hash slot 算法

redis cluster 的高可用：主备切换，和哨兵类似。

13.缓存问题
缓存穿透：指的是对某个一定不存在的数据进行请求，该请求将会穿透缓存到达数据库。
解决方案：对这些不存在的数据缓存一个空数据；对这类请求进行过滤（布隆过滤器）。

缓存雪崩：指的是由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库。而有缓存的系统中，系统非常依赖于缓存，缓存分担了很大一部分的数据请求。当发生缓存雪崩时，数据库无法处理这么大的请求，导致数据库崩溃。
解决方案：为了防止缓存在同一时间大面积过期导致的缓存雪崩，可以通过观察用户行为，合理设置缓存过期时间来实现；为了防止缓存服务器宕机出现的缓存雪崩，可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用。也可以进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。
事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。
事中：本地 ehcache 缓存 + hystrix 限流&降级，避免 MySQL 被打死。
事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。

*缓存一致性：
删除缓存代替更新缓存。脏数据。

先更新数据库，再删除缓存(Cache Aside Pattern设计模式)。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。在高并发下表现优异
删除缓存失败的解决思路：
将需要删除的key发送到消息队列中
自己消费消息，获得需要删除的key
不断重试删除操作，直到成功

先删除缓存，再更新数据库。线程A删除了缓存，线程B查询，发现缓存已不存在，线程B去数据库查询得到旧值，线程B将旧值写入缓存，线程A将新值写入数据库，所以也会导致数据库和缓存不一致的问题。在原子性被破坏时表现优异
高并发下解决数据库与缓存不一致的思路：将删除缓存、修改数据库、读取缓存等的操作积压到队列里边，实现串行化。使用数据的唯一标识。

读请求和写请求串行化，串到一个内存队列里去。会导致系统的吞吐量会大幅度的降低。
该解决方案要注意的问题：读请求长时阻塞，读请求并发量过高，多服务实例部署的请求路由，热点商品的路由问题，导致请求的倾斜。

缓存 “无底洞” 现象：为了满足业务要求添加了大量缓存节点，但是性能不但没有好转反而下降了的现象。
解决方案：优化批量数据操作命令；减少网络通信次数；降低接入成本，使用长连接 / 连接池，NIO 等。

14.CDN
内容分发网络（Content distribution network，CDN）是一种互连的网络系统，它利用更靠近用户的服务器从而更快更可靠地将 HTML、CSS、JavaScript、音乐、图片、视频等静态资源分发给用户。
优点：
更快地将数据分发给用户
通过部署多台服务器，从而提高系统整体的带宽性能
多台服务器可以看成是一种冗余机制，从而具有高可用性

15.数据分布
分布式存储
哈希分布：哈希分布就是将数据计算哈希值之后，按照哈希值分配到不同的节点上。
传统的哈希分布算法存在一个问题：当节点数量变化时，也就是 N 值变化，那么几乎所有的数据都需要重新分布，将导致大量的数据迁移。

顺序分布：将数据划分为多个连续的部分，按数据的 ID 或者时间分布到不同节点上。
顺序分布相比于哈希分布的主要优点如下：
能保持数据原有的顺序；
并且能够准确控制每台服务器存储的数据量，从而使得存储空间的利用率最大。

一致性哈希：
Distributed Hash Table（DHT） 是一种哈希分布方式，其目的是为了克服传统哈希分布在服务器节点数量变化时大量数据迁移的问题。
将哈希空间 [0, 2^(n-1)] 看成一个哈希环，每个服务器节点都配置到哈希环上。每个数据对象通过哈希取模得到哈希值之后，存放到哈希环中顺时针方向第一个大于等于该哈希值的节点上。
一致性哈希在增加或者删除节点时只会影响到哈希环中相邻的节点。

虚拟节点：
一致性哈希存在数据分布不均匀的问题，节点存储的数据量有可能会存在很大的不同。
数据不均匀主要是因为节点在哈希环上分布的不均匀，这种情况在节点数量很少的情况下尤其明显。
解决方式是通过增加虚拟节点，然后将虚拟节点映射到真实节点上。虚拟节点的数量比真实节点来得多，那么虚拟节点在哈希环上分布的均匀性就会比原来的真实节点好，从而使得数据分布也更加均匀。

16.redis 的并发竞争
多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同。
redis 自己就有天然解决这个问题的 CAS 类的乐观锁方案。
基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。
同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。Zookeeper更加可靠。

17热点key
大量请求访问的key

首先，发现热点key：
凭借业务经验预估
在客户端或Proxy层进行收集
redis自带命令monitor或redis-cli的热点key发现功能–hotkeys
还有自己抓包评估（Redis客户端使用TCP协议与服务端进行交互，通信协议采用的是RESP）。

然后解决：
利用二级缓存，在你发现热key以后，把热key缓存到系统的JVM中。针对这种热key请求，会直接从jvm中取，而不会走到redis层。分散了请求。
备份多台Redis服务器分摊热key请求

在项目运行过程中，自动发现热key，然后程序自动处理：监控热key，通知系统做处理。

18为什么redis快
一是因为都在内存里
二是因为读写都是单线程，减少了上下文切换带来的资源消耗
三是底层使用的是多路复用技术nio，即使用很少的线程也能快速处理大量任务
