## 简介

Nginx 是异步非阻塞的 web 服务器，也可以用作反向代理、负载均衡和 HTTP 缓存。免费开源，BSD 许可证。
同时也是 IMAP、POP3、SMTP 代理服务器。



## 1.特点

占用内存少，并发能力强，稳定性高，高性能。
基于 REST 风格。
基于事件驱动架构，使得其可以支持数以百万级别的 TCP 连接。
开源和高度的模块化使得第三方模块层出不穷。
跨平台，C 语言开发，支持热部署，可以做到不间断运行。
擅长于底层服务器端资源的处理。

Apache 重量级，不支持高并发，操作系统对其进行进程或线程间的切换也消耗了大量的 CPU 资源，导致 HTTP 请求的平均响应速度降低，性能差。



## 2.反向代理

客户端->代理->服务器
反向代理服务器位于用户与目标服务器之间，但是对于用户而言，反向代理服务器就相当于目标服务器，即用户直接访问反向代理服务器就可以获得目标服务器的资源。
同时，用户不需要知道目标服务器的地址，也无须在用户端作任何设定。
反向代理服务器通常可用来作为 web 加速，即使用反向代理作为 web 服务器的前置机来降低网络和服务器的负载，提高访问效率。
多台服务器，客户端是无感知代理的存在的，反向代理对外都是透明的，访问者并不知道自己访问的是一个代理。因为客户端不需要任何配置就可以访问。
代理的是服务端。

反向代理的作用：
保证内网的安全，通常将反向代理作为公网访问地址，web 服务器是内网。
负载均衡，通过反向代理服务器来优化网站的负载。

正向代理：客户端改为向代理服务器发送请求，并指定目标服务器，然后由代理服务器和目标服务器通信，转交请求并获得的内容，再返回给客户端。正向代理隐藏了真实的客户端。
客户端必须要进行一些特别的设置才能使用正向代理。
代理的是服务端。    

正向代理的作用：    
访问原来无法访问的资源。
可以做缓存，加速访问资源。
对客户端访问授权，上网进行认证。
代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息。

通常情况下，我们在实际项目操作时，正向代理和反向代理很有可能会存在同一个应用场景中。



## 3.负载均衡

请求爆发式增长，单个机器性能再强劲也无法满足要求了，这个时候产生了集群。
集群中的应用服务器节点通常被设计成无状态，用户可以请求任何一个节点。
负载均衡器会根据集群中每个节点的负载情况，将用户请求转发到合适的节点上。

负载均衡器可以用来实现高可用以及伸缩性：
高可用：当某个节点故障时，负载均衡器会将用户请求转发到另外的节点上，从而保证所有服务持续可用；
伸缩性：根据系统整体负载情况，可以很容易地添加或移除节点。

负载均衡器运行过程包含两个部分：根据负载均衡算法得到转发的节点；进行转发。

负载均衡算法
轮询 Round Robin：把每个请求轮流发送到每个服务器上。
比较适合每个服务器的性能差不多的场景，如果有性能存在差异的情况下，那么性能较差的服务器可能无法承担过大的负载。

加权轮询 Weighted Round Robbin：在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值，性能高的服务器分配更高的权值。

由于每个请求的连接时间不一样，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数过大，而另一台服务器的连接过小，造成负载不均衡。

最少连接 least Connections：将请求发送给当前最少连接数的服务器上。
加权最少连接 Weighted Least Connection：在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。

随机算法 Random：把请求随机发送到服务器上。
和轮询算法类似，该算法比较适合服务器性能差不多的场景。

源地址哈希法 IP Hash：通过对客户端 IP 计算哈希值之后，再对服务器数量取模得到目标服务器的序号。
可以保证同一 IP 的客户端的请求会转发到同一台服务器上，用来实现会话粘滞 Sticky Session。

转发实现
HTTP 重定向：使用某种负载均衡算法计算得到服务器的 IP 地址之后，将该地址写入 HTTP 重定向报文中，状态码为 302。客户端收到重定向报文之后，需要重新向服务器发起请求。
缺点：
需要两次请求，因此访问延迟比较高；
HTTP 负载均衡器处理能力有限，会限制集群的规模。
该负载均衡转发的缺点比较明显，实际场景中很少使用它。

DNS 域名解析：在 DNS 解析域名的同时使用负载均衡算法计算服务器 IP 地址。
优点：
DNS 能够根据地理位置进行域名解析，返回离用户最近的服务器 IP 地址。
缺点：
由于 DNS 具有多级结构，每一级的域名记录都可能被缓存，当下线一台服务器需要修改 DNS 记录时，需要过很长一段时间才能生效。
大型网站基本使用了 DNS 做为第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡。也就是说，域名解析的结果为内部的负载均衡服务器 IP 地址。

反向代理服务器：位于源服务器前面，用户的请求需要先经过反向代理服务器才能到达源服务器。反向代理可以用来进行缓存、日志记录等，同时也可以用来做为负载均衡服务器。
在这种负载均衡转发方式下，客户端不直接请求源服务器，因此源服务器不需要外部 IP 地址，而反向代理需要配置内部和外部两套 IP 地址。
优点：
与其它功能集成在一起，部署简单。
缺点：
所有请求和响应都需要经过反向代理服务器，它可能会成为性能瓶颈。

网络层：在操作系统内核进程获取网络数据包，根据负载均衡算法计算源服务器的 IP 地址，并修改请求数据包的目的 IP 地址，最后进行转发。
源服务器返回的响应也需要经过负载均衡服务器，通常是让负载均衡服务器同时作为集群的网关服务器来实现。
优点：
在内核进程中进行处理，性能比较高。
缺点：
和反向代理一样，所有的请求和响应都经过负载均衡服务器，会成为性能瓶颈。

链路层：在链路层根据负载均衡算法计算源服务器的 MAC 地址，并修改请求数据包的目的 MAC 地址，并进行转发。
通过配置源服务器的虚拟 IP 地址和负载均衡服务器的 IP 地址一致，从而不需要修改 IP 地址就可以进行转发。也正因为 IP 地址一样，所以源服务器的响应不需要转发回负载均衡服务器，可以直接转发给客户端，避免了负载均衡服务器的成为瓶颈。
这是一种三角传输模式，被称为直接路由。对于提供下载和视频服务的网站来说，直接路由避免了大量的网络传输数据经过负载均衡服务器。
这是目前大型网站使用最广负载均衡转发方式，在 Linux 平台可以使用的负载均衡服务器为 Linux 虚拟服务器 LVS。

Nginx 负载均衡是通过 upstream 模块来实现的：
upstream xx{
    server xx;
}
server{
    ...
    location / {
        proxy_pass xx;
        index xx;
    }
    ...
}

weight 轮循（默认）：接收到的请求按照顺序逐一分配到不同的后端服务器，即使在使用过程中，某一台后端服务器宕机，Nginx 会自动将该服务器剔除出队列，请求受理情况不会受到任何影响。
这种方式下，可以给不同的后端服务器设置一个权重值 weight，用于调整不同的服务器上请求的分配率。权重数据越大，被分配到请求的几率越大；该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的。

ip_hash：每个请求按照发起客户端的 IP 的 hash 结果进行匹配，这样的算法下一个固定 IP 地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下 Session 共享的问题。
fair：智能调整调度算法，动态的根据后端服务器的请求处理到响应的时间进行均衡分配。响应时间短处理效率高的服务器分配到请求的概率高，响应时间长处理效率低的服务器分配到的请求少，它是结合了前两者的优点的一种调度算法。
url_hash：按照访问的 URL 的 hash 结果分配请求，每个请求的 URL 会指向后端固定的某个服务器，可以在 Nginx 作为静态服务器的情况下提高缓存效率。

fair 和 url_hash 属于第三方负载策略，使用需安装模块和软件包。

最少连接：将请求分配给连接数最少的服务器。Nginx 会统计哪些服务器的连接数最少。

Nginx 实现限流：连接数限流模块 ngx_http_limit_conn_module 和漏桶算法实现的请求限流模块 ngx_http_limit_req_module。

负载均衡在实际项目操作过程中，有硬件负载均衡和软件负载均衡两种，硬件负载均衡也称为硬负载，如 F5 负载均衡，相对造价昂贵成本较高，但是数据的稳定性安全性等等有非常好的保障。



## 4.动静分离

为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度，降低原来单个服务器的压力。
由于 Nginx 的高并发和静态资源缓存等特性，经常将静态资源部署在 Nginx 上。如果请求的是静态资源，直接到静态资源目录获取资源。
如果是动态资源的请求，则利用反向代理的原理，把请求转发给对应后台应用去处理，从而实现动静分离。
使用前后端分离后，可以很大程度提升静态资源的访问速度，即使动态服务不可用，静态资源的访问也不会受到影响。