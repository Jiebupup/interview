## 简介

在分布式系统中，每个服务都可能会调用很多其他服务，被调用的那些服务就是依赖服务。
Hystrix 可以让我们在分布式系统中对服务间的调用进行控制，加入一些调用延迟或者依赖故障的容错机制。
Hystrix 通过将依赖服务进行资源隔离，进而阻止某个依赖服务出现故障时在整个系统所有的依赖服务调用中进行蔓延；同时 Hystrix 还提供故障时的 fallback 降级机制。
总而言之，Hystrix 通过这些方法帮助我们提升分布式系统的可用性和稳定性。
2018 年 11 月，Hystrix 在其 Github 主页宣布，不再开放新功能。 
Hystrix 仪表盘：用来实时监控 Hystrix 的各项指标信息。



## 1.设计原则

对依赖服务调用时出现的调用延迟和调用失败进行控制和容错保护。
在复杂的分布式系统中，阻止某一个依赖服务的故障在整个系统中蔓延。比如某一个服务故障了，导致其它服务也跟着故障。Hystrix 可以对其进行资源隔离。
提供 fail-fast（快速失败）和快速恢复的支持。
提供 fallback 优雅降级的支持。
支持近实时的监控、报警以及运维操作。

阻止任何一个依赖服务耗尽所有的资源，比如 tomcat 中的所有线程资源。
避免请求排队和积压，采用限流和 fail fast 来控制故障。
提供 fallback 降级机制来应对故障。
使用资源隔离技术，比如 bulkhead（舱壁隔离技术）、swimlane（泳道技术）、circuit breaker（断路技术）来限制任何一个依赖服务的故障的影响。
通过近实时的统计/监控/报警功能，来提高故障发现的速度。
通过近实时的属性和配置热修改功能，来提高故障处理和恢复的速度。
保护依赖服务调用的所有故障情况，而不仅仅只是网络故障情况。



## 2.Hystrix 底层的执行流程

Hystrix 最基本的支持高可用的技术：资源隔离 + 限流
创建 command
调用 command 执行方法
检查是否开启缓存 request cache
检查是否开启了断路器 circuit breaker。如果断路器被打开了，那么 Hystrix 就不会执行这个 command，而是直接去执行 fallback 降级机制，返回降级结果。 
检查线程池/队列/信号量是否已满。不会执行 command，而是直接去调用 fallback 降级机制，同时发送 reject 信息给断路器统计。
执行 command。超时和执行出错会走 fallback 降级。这两种情况下，Hystrix 都会发送异常事件给断路器统计。
断路健康检查。Hystrix 会把每一个依赖服务的调用成功、失败、Reject、Timeout 等事件发送给 circuit breaker 断路器。断路器就会对这些事件的次数进行统计，根据异常事件发生的比例来决定是否要进行断路（熔断）。如果打开了断路器，那么在接下来一段时间内，会直接断路，返回降级结果。如果在之后，断路器尝试执行 command，调用没有出错，返回了正常结果，那么 Hystrix 就会把断路器关闭。
调用 fallback 降级机制。一般在降级机制中，都建议给出一些默认的返回值，比如静态的一些代码逻辑，或者从内存中的缓存中提取一些数据，在这里尽量不要再进行网络请求了。在降级中，如果一定要进行网络调用的话，也应该将那个调用放在一个 HystrixCommand 中进行隔离。

基于 request cache 请求缓存技术优化批量商品数据查询接口：
每一次请求，就是一次请求上下文。在一次请求上下文中，如果有多个 command，参数都是一样的，调用的接口也是一样的，而结果可以认为也是一样的。那么这个时候，我们可以让第一个 command 执行返回的结果缓存在内存中，然后这个请求上下文后续的其它对这个依赖的调用全部从内存中取出缓存结果就可以了。
这样的话，好处在于不用在一次请求上下文中反复多次执行一样的 command，避免重复执行网络请求，提升整个请求的性能。
HystrixCommand 和 HystrixObservableCommand 都可以指定一个缓存 key，然后 Hystrix 会自动进行缓存，接着在同一个 request context 内，再次访问的话，就会直接取用缓存。

fallback 优雅降级
circuit breaker 断路器快速熔断：Hystrix 断路器有三种状态，分别是关闭、打开与半开。Metrics 统计器。

Hystrix 的线程池隔离与接口限流：
Hystrix 通过判断线程池或者信号量是否已满，超出容量的请求，直接 Reject 走降级，从而达到限流的作用。
限流是限制对后端的服务的访问量，比如说你对 MySQL、Redis、Zookeeper 以及其它各种后端中间件的资源的访问的限制，其实是为了避免过大的流量直接打死后端的服务。
信号量实现对某个依赖服务的并发访问量的限制，线程池通过线程池/队列的大小来限制流量。信号量可以用来限流和削峰，但是不能用来对调用延迟的服务进行 timeout 和隔离。
限流可以认为服务降级的一种，限流就是限制系统的输入和输出流量已达到保护系统的目的。一般来说系统的吞吐量是可以被测算的，为了保证系统的稳定运行，一旦达到的需要限制的阈值，就需要限制流量并采取一些措施以完成限制流量的目的。比如：延迟处理，拒绝处理，或者部分拒绝处理等等。
工作中限流的使用：spring cloud gateway 默认使用 redis 进行限流；sentinel 通过配置来控制每个 url 的流量。

基于 timeout 机制为服务接口调用超时提供安全保护：
一般来说，在调用依赖服务的接口的时候，比较常见的一个问题就是超时。超时是在一个复杂的分布式系统中，导致系统不稳定，或者系统抖动。出现大量超时，线程资源会被 hang 死，从而导致吞吐量大幅度下降，甚至服务崩溃。
在 Hystrix 中，我们可以手动设置 timeout 时长，如果一个 command 运行时间超过了设定的时长，那么就被认为是 timeout，然后 Hystrix command 标识为 timeout，同时执行 fallback 降级逻辑。



## 3.资源隔离

要把对某一个依赖服务的所有调用请求，全部隔离在同一份资源池内，不会去用其它资源了。
避免说对某一个依赖服务的调用，因为依赖服务的接口调用的延迟或者失败，导致服务所有的线程资源全部耗费在这个服务的接口调用上。一旦说某个服务的线程资源全部耗尽的话，就可能导致服务崩溃，甚至说这种故障会不断蔓延。
Hystrix 进行资源隔离，其实是提供了一个抽象，叫做 Command。这也是 Hystrix 最最基本的资源隔离技术。
Hystrix 采用了 Bulkhead Partition 舱壁隔离技术，来将外部依赖进行资源隔离，进而避免任何外部依赖的故障导致本服务崩溃。
Hystrix 对每个外部依赖用一个单独的线程池，这样的话，如果对那个外部依赖调用延迟很严重，最多就是耗尽那个依赖自己的线程池而已，不会影响其他的依赖调用。

小型电商网站的商品详情页系统架构：小型电商网站的页面展示采用页面全量静态化的思想。数据库中存放了所有的商品信息，页面静态化系统，将数据填充进静态模板中，形成静态化页面，推入 Nginx 服务器。用户浏览网站页面时，取用一个已经静态化好的 HTML 页面，直接返回回去，不涉及任何的业务逻辑处理。
好处在于，用户每次浏览一个页面，不需要进行任何的跟数据库的交互逻辑，也不需要执行任何的代码，直接返回一个 HTML 页面就可以了，速度和性能非常高。对于小网站，页面很少，很实用，非常简单，Java 中可以使用 velocity、freemarker、thymeleaf 等等，然后做个 cms 页面内容管理系统，模板变更的时候，点击按钮或者系统自动化重新进行全量渲染。
坏处在于，对于一些大型的电商网站，亿级数量的页面，你说你每次页面模板修改了，都需要将这么多页面全量静态化，每次渲染花的时间太多。

大型电商网站的商品详情页系统架构：当商品数据发生变更时，会将变更消息压入 MQ 消息队列中。缓存服务从消息队列中消费这条消息时，感知到有数据发生变更，便通过调用数据服务接口，获取变更后的数据，然后将整合好的数据推送至 Redis 中。Nginx 本地缓存的数据是有一定的时间期限的，比如说 10 分钟，当数据过期之后，它就会从 Redis 获取到最新的缓存数据，并且缓存到自己本地。用户浏览网页时，动态将 Nginx 本地数据渲染到本地 HTML 模板并返回给用户。
虽然没有直接返回 HTML 页面那么快，但是因为数据在本地缓存，所以也很快，其实耗费的也就是动态渲染一个 HTML 页面的性能。如果 HTML 模板发生了变更，不需要将所有的页面重新静态化，也不需要发送请求，没有网络请求的开销，直接将数据渲染进最新的 HTML 页面模板后响应即可。

商品接口服务故障导致缓存服务资源耗尽：
如果系统访问量很高，Nginx 本地缓存过期失效了，Redis 中的缓存也被 LRU 算法给清理掉了，那么会有较高的访问量，从缓存服务调用商品服务。
但如果此时商品服务的接口发生故障，调用出现了延时，缓存服务全部的线程都被这个调用商品服务接口给耗尽了，每个线程去调用商品服务接口的时候，都会卡住很长时间，后面大量的请求过来都会卡在那儿，此时缓存服务没有足够的线程去调用其它一些服务的接口，从而导致整个大量的商品详情页无法正常显示。      

从 Nginx 开始，缓存都失效了，Nginx 会直接通过缓存服务调用商品服务获取最新商品数据，有可能出现调用延时而把缓存服务资源耗尽的情况。此时需要通过资源隔离保证系统的高可用性。
阻塞时，请求会消耗占用系统的线程、IO 等资源，导致系统服务器崩溃。

默认情况下，Hystrix 使用线程池模式：
利用 HystrixCommand 获取单条数据：我们通过将调用商品服务的操作封装在 HystrixCommand 中，限定一个 key，在这里我们可以简单认为这是一个线程池，每次调用商品服务，就只会用该线程池中的资源，不会再去用其它线程资源了。
利用 HystrixObservableCommand 批量获取数据：只要是获取商品数据，全部都绑定到同一个线程池里面去，我们通过 HystrixObservableCommand 的一个线程去执行，而在这个线程里面，批量把多个 productId 的 productInfo 拉回来。
从 Nginx 开始，缓存都失效了，那么 Nginx 通过缓存服务去调用商品服务。线程池就存在于缓存服务中，即使商品服务接口故障了，最多就只有线程大小个线程会 hang 死在调用商品服务接口的路上。

通过 Hystrix 信号量实现资源隔离：只是起到一个开关的作用，其它的请求都会被拒绝，从而达到资源隔离和限流保护的作用。

线程池与信号量的区别：线程池隔离技术，是用 Hystrix 自己的线程去执行调用；而信号量隔离技术，是直接让 tomcat 线程去调用依赖服务。

适用场景：
线程池技术，适合绝大多数场景，比如说我们对依赖服务的网络请求的调用和访问、需要对调用的 timeout 进行控制（捕捉 timeout 超时异常）。
信号量技术，适合说你的访问不是对外部依赖的访问，而是对内部的一些比较复杂的业务逻辑的访问，并且系统内部的代码，其实不涉及任何的网络请求，那么只要做信号量的普通限流就可以了，因为不需要去捕获 timeout 类似的问题。

Hystrix 隔离策略细粒度控制：
线程池机制，每个 command 运行在一个线程中，限流是通过线程池的大小来控制的；信号量机制，command 是运行在调用线程中，通过信号量的容量来进行限流。
线程池其实最大的好处就是对于网络访问请求，如果有超时的话，可以避免调用线程阻塞住。
而使用信号量的场景，通常是针对超大并发量的场景下。限流保护，一般用信号量常见于那种基于纯内存的一些业务逻辑服务，而不涉及到任何网络访问请求。
command key & command group、command thread pool、command key & command group & command thread pool、coreSize、queueSizeRejectionThreshold、execution.isolation.semaphore.maxConcurrentRequests。

在线程池排队、超时等阻塞情况时可以快速失败，并可以提供 fallback 机制。
线程池隔离的好处是隔离度比较高，可以针对某个资源的线程池去进行处理而不影响其它资源，但是代价就是线程上下文切换的 overhead 比较大，特别是对低延时的调用有比较大的影响。
但是，实际情况下，线程池隔离并没有带来非常多的好处。最直接的影响，就是会让机器资源碎片化。
线程池模式比较彻底的隔离性使得 Hystrix 可以针对不同资源线程池的排队、超时情况分别进行处理，但这其实是超时熔断和流量控制要解决的问题，如果组件具备了超时熔断和流量控制的能力，线程池隔离就显得没有那么必要了。
Hystrix 的信号量隔离限制对某个资源调用的并发数。这样的隔离非常轻量级，仅限制对某个资源调用的并发数，而不是显式地去创建线程池，所以 overhead 比较小，但是效果不错。但缺点是无法对慢调用自动进行降级，只能等待客户端自己超时，因此仍然可能会出现级联阻塞的情况。



## 4.fallback 降级

当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。 
高峰期，为了保证核心服务正常运行，需要停掉一些不太重要的业务，或者某些服务不可用时，执行备用逻辑从故障服务中快速失败或快速返回，以保障主体业务不受影响。
Hystrix 提供的降级主要是为了容错，保证当前服务不受依赖服务故障的影响

Hystrix 出现以下四种情况，都会去调用 fallback 降级机制：
断路器处于打开的状态。
资源池已满（线程池+队列/信号量）。
Hystrix 调用各种接口，或者访问外部依赖出现了任何异常的情况。
访问外部依赖的时候，访问时间过长，报了 TimeoutException 异常。

两种最经典的降级机制
纯内存数据：在降级逻辑中，你可以在内存中维护一个 ehcache，作为一个纯内存的基于 LRU 自动清理的缓存，让数据放在缓存内。如果说外部依赖有异常，fallback 这里直接尝试从 ehcache 中获取数据。
默认值：fallback 降级逻辑中，也可以直接返回一个默认值。

降级回退方式：
Fail Fast 快速失败：快速失败是最普通的命令执行方法，命令没有重写降级逻辑。 如果命令执行发生任何类型的故障，它将直接抛出异常。
Fail Silent 无声失败：指在降级方法中通过返回 null，空 Map，空 List 或其他类似的响应来完成。
Fallback: Static：指在降级方法中返回静态默认值。 这不会导致服务以“无声失败”的方式被删除，而是导致默认行为发生。如：应用根据命令执行返回 true / false 执行相应逻辑，但命令执行失败，则默认为 true。
Fallback: Stubbed：当命令返回一个包含多个字段的复合对象时，适合以 Stubbed 的方式回退。
Fallback: Cache via Network：有时，如果调用依赖服务失败，可以从缓存服务（如 redis）中查询旧数据版本。由于又会发起远程调用，所以建议重新封装一个 Command，使用不同的 ThreadPoolKey，与主线程池进行隔离。
Primary + Secondary with Fallback：有时系统具有两种行为- 主要和次要，或主要和故障转移。主要和次要逻辑涉及到不同的网络调用和业务逻辑，所以需要将主次逻辑封装在不同的 Command 中，使用线程池进行隔离。
为了实现主从逻辑切换，可以将主次 command 封装在外观 HystrixCommand 的 run 方法中，并结合配置中心设置的开关切换主从逻辑。由于主次逻辑都是经过线程池隔离的 HystrixCommand，因此外观 HystrixCommand 可以使用信号量隔离，而没有必要使用线程池隔离引入不必要的开销。

自动降级分类：超时降级、失败次数降级、故障降级、限流降级。



## 5.Sentinel 和 Hystrix

Sentinel 是阿里中间件团队研发的面向分布式服务架构的轻量级高可用流量控制组件，于 2018 年 7 月正式开源。
Sentinel 主要以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度来帮助用户提升服务的稳定性。

Hystrix 的关注点在于以隔离和熔断为主的容错机制，超时或被熔断的调用将会快速失败，并可以提供 fallback 机制。
而 Sentinel 的侧重点在于：多样化的流量控制、熔断降级、系统负载保护、实时监控和控制台。

共同特性
资源模型和执行模型：
Hystrix 的资源模型设计上采用了命令模式，将对外部资源的调用和 fallback 逻辑封装成一个命令对象 HystrixCommand 或 HystrixObservableCommand，其底层的执行是基于 RxJava 实现的。
每个 Command 创建时都要指定 commandKey 和 groupKey（用于区分资源）以及对应的隔离策略（线程池隔离 or 信号量隔离）。
线程池隔离模式下需要配置线程池对应的参数（线程池名称、容量、排队超时等），然后 Command 就会在指定的线程池按照指定的容错策略执行。
信号量隔离模式下需要配置最大并发数，执行 Command 时 Hystrix 就会限制其并发调用。
Hystrix 的 Command 强依赖于隔离规则配置的原因是隔离规则会直接影响 Command 的执行。在执行的时候 Hystrix 会解析 Command 的隔离规则来创建 RxJava Scheduler 并在其上调度执行，若是线程池模式则 Scheduler 底层的线程池为配置的线程池，若是信号量模式则简单包装成当前线程执行的 Scheduler。

Sentinel 的设计则更为简单。相比 Hystrix Command 强依赖隔离规则，Sentinel 的资源定义与规则配置的耦合度更低。
Sentinel 在开发的时候只需要考虑这个方法/代码是否需要保护，置于用什么来保护，可以任何时候动态实时的区修改。

隔离设计：
Sentinel 可以通过并发线程数模式的流量控制来提供信号量隔离的功能。并且结合基于响应时间的熔断降级模式，可以在不稳定资源的平均响应时间比较高的时候自动降级，防止过多的慢调用占满并发数，影响整个系统。

熔断降级：
Sentinel 和 Hystrix 的熔断降级功能本质上都是基于熔断器模式 Circuit Breaker Pattern。
Sentinel 与 Hystrix 都支持基于失败比率（异常比率）的熔断降级，在调用达到一定量级并且失败比率达到设定的阈值时自动进行熔断，此时所有对该资源的调用都会被 block，直到过了指定的时间窗口后才启发性地恢复。
Sentinel 还支持基于平均响应时间的熔断降级，可以在服务响应时间持续飙高的时候自动熔断，拒绝掉更多的请求，直到一段时间后才恢复。这样可以防止调用非常慢造成级联阻塞的情况。

实时指标统计实现：
Hystrix 和 Sentinel 的实时指标数据统计实现都是基于滑动窗口的。
Hystrix 1.5 之前的版本是通过环形数组实现的滑动窗口，通过锁配合 CAS 的操作对每个桶的统计信息进行更新。
Hystrix 1.5 开始对实时指标统计的实现进行了重构，将指标统计数据结构抽象成了响应式流 reactive stream 的形式，方便消费者去利用指标信息。
同时底层改造成了基于 RxJava 的事件驱动模式，在服务调用成功/失败/超时的时候发布相应的事件，通过一系列的变换和聚合最终得到实时的指标统计数据流，可以被熔断器或 Dashboard 消费。

Sentinel 目前抽象出了 Metric 指标统计接口，底层可以有不同的实现，目前默认的实现是基于 LeapArray 的滑动窗口，后续根据需要可能会引入 reactive stream 等实现。

Sentinel 特性
轻量级、高性能：
Sentinel 作为一个功能完备的高可用流量管控组件，其核心 sentinel-core 没有任何多余依赖，非常轻量级。
同时，Sentinel 提供了多种扩展点，用户可以很方便地根据需求去进行扩展，并且无缝地切合到 Sentinel 中。
引入 Sentinel 带来的性能损耗非常小。只有在业务单机量级超过 25W QPS 的时候才会有一些显著的影响（5% - 10% 左右），单机 QPS 不太大的时候损耗几乎可以忽略不计。

流量控制：
Sentinel 可以针对不同的调用关系，以不同的运行指标（如 QPS、并发调用数、系统负载等）为基准，对资源调用进行流量控制，将随机的请求调整成合适的形状。
Sentinel 支持多样化的流量整形策略，在 QPS 过高的时候可以自动将流量调整成合适的形状。常用的有：直接拒绝模式、慢启动预热模式、匀速器模式。
目前 Sentinel 对异步调用链路的支持还不是很好，后续版本会着重改善支持异步调用。

系统负载保护：Sentinel 对系统的维度提供保护，负载保护算法借鉴了 TCP BBR 的思想。让系统的入口流量和系统的负载达到一个平衡，保证系统在能力范围之内处理最多的请求。

实时监控和控制面板：
Sentinel 提供 HTTP API 用于获取实时的监控信息，如调用链路统计信息、簇点信息、规则信息等。
如果用户正在使用 Spring Boot/Spring Cloud 并使用了 Sentinel Spring Cloud Starter，还可以方便地通过其暴露的 Actuator Endpoint 来获取运行时的一些信息，如动态规则等。
未来 Sentinel 还会支持标准化的指标监控 API，可以方便地整合各种监控系统和可视化系统，如 Prometheus、Grafana 等。
Sentinel 控制台 Dashboard 提供了机器发现、配置规则、查看实时监控、查看调用链路信息等功能，使得用户可以非常方便地去查看监控和进行配置。

生态良好：
Sentinel 目前已经针对 Servlet、Dubbo、Spring Boot/Spring Cloud、gRPC 等进行了适配，用户只需引入相应依赖并进行简单配置即可非常方便地享受 Sentinel 的高可用流量防护能力。
未来 Sentinel 还会对更多常用框架进行适配，并且会为 Service Mesh 提供集群流量防护的能力。