## 简介

**分布式**

不同的业务模块部署在不同的服务器上或者同一个业务模块分拆多个子业务，部署在不同的服务器上，解决高并发的问题。

**集群**

同一个业务部署在多台机器上，提高系统可用性。容量增加，处理能力增强，还可以按需要进行动态的扩容、缩容。



## 1.分布式锁

在单机场景下，可以使用语言的内置锁来实现进程同步。但是在分布式场景下，需要同步的进程可能位于不同的节点上，那么就需要使用分布式锁。

保证多个机器加的是同一个锁。

阻塞锁通常使用互斥量来实现。

#### 数据库唯一索引

创建一张锁表，当需要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录，用这个记录是否存在来判断是否存于锁定状态。

**问题**

- 锁没有失效时间，解锁失败的话其它进程无法再获得该锁。或因服务宕机导致的锁无法释放，从而产生死锁问题。

- 只能是非阻塞锁，插入失败直接就报错了，无法重试。

- 不可重入，已经获得锁的进程也必须重新获取锁。

#### Redis 的 SETNX 指令

set if not exist，插入一个键值对，如果 key 已经存在，那么会返回 False，否则插入成功并返回 True。

SETNX 指令和数据库的唯一索引类似，保证了只存在一个 key 的键值对，那么可以用一个 key 的键值对是否存在来判断是否处于锁定状态。

EXPIRE 指令可以为一个键值对设置一个过期时间，从而避免了数据库唯一索引实现方式中释放锁失败的问题。

**通过 Lua 脚本保证原子性**

现在的 SETNX 默认是指 SET key value NX PX milliseconds，是原子性操作。

在 Redis2.6 之前，Set 是不支持 NX 参数的，如果想要完成一个锁，那么需要放入 Key 和设置有效期这两条命令，理论上会出现前者刚执行完，程序挂掉，无法保证原子性。SETNX 可能在未来的版本中弃用并永久删除。

释放锁就是删除 key，有获取、判断和删除三个操作，为了保障原子性，我们需要用 Lua 脚本。value 使用唯一的客户端 ID，或者用 UUID 这种随机数，保证在足够长的一段时间内在所有客户端的所有获取锁的请求中都是唯一的。判断 value 一样才删除，判断是否是当前进程加的锁，再去删除，从而避免释放另一个进程创建的锁。

就算你在 Lua 里写出花，执行也是一个命令 eval/evalsha 去执行的，一条命令没执行完，其他客户端是看不到的。

**缺点**

- 如果是 Redis 的单实例，那就是单点故障。

- 或者是 Redis 的普通主从，那 Redis 的主从异步复制，如果主节点挂了，key 就没有了，key 还没同步到从节点，此时从节点切换为主节点，别人就可以 set key，从而拿到锁。锁丢失。

#### Redis 的 RedLock 算法

使用了多个 Redis 实例构成集群来实现分布式锁，这是为了保证在发生单点故障时仍然可用。

**步骤**

1. 尝试从 N 个互相独立的 Redis 实例获取锁。避免了 Redis 主从异步复制造成的锁丢失。

2. 计算获取锁消耗的时间，只有当这个时间小于锁的过期时间，并且从大多数 N/2+1 实例上获取了锁，那么就认为锁获取成功了。

3. 如果锁获取失败，就到每个实例上释放锁。为了解决有可能在加锁阶段，这个节点收到加锁请求了，也 set 成功了，但是由于返回给客户端的响应包丢了，导致客户端以为没有加锁成功。

**特性**

- 安全特性：互斥访问，即永远只有一个 client 能拿到锁。

- 避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区。

- 容错性：只要大部分 Redis 节点存活就可以正常提供服务。

**失败重试**

如果一个 client 申请锁失败了，那么它需要稍等一会在重试避免多个 client 同时申请锁的情况，最好的情况是一个 client 需要几乎同时向 5 个 master 发起锁申请。

另外就是如果 client 申请锁失败了它需要尽快在它曾经申请到锁的 master 上执行 unlock 操作，便于其他 client 获得这把锁，避免这些锁过期造成的时间浪费。如果这时候网络分区使得 client 无法联系上这些 master，那么这种浪费就得付出代价了。

**性能、崩溃恢复和 fsync**

如果没有持久化机制，client 从 5 个 master 中的 3 个处获得了锁，然后其中一个重启了，这时整个环境中又出现了 3 个 master 可供另一个 client 申请同一把锁！违反了互斥性。

如果我们开启了 AOF 持久化那么情况会稍微好转一些，因为 Redis 的过期机制是语义层面实现的，所以在 server 挂了的时候时间依旧在流逝，重启之后锁状态不会受到污染。

但是考虑断电之后呢，AOF 部分命令没来得及刷回磁盘直接丢失了，除非我们配置刷回策略为 fsnyc = always，但这会损伤性能。

解决这个问题的方法是延迟重启：当一个节点重启之后，我们规定在锁的过期时间 TTL 期间它是不可用的，这样它就不会干扰原本已经申请到的锁，等到它 crash 前的那部分锁都过期了，环境不存在历史锁了，那么再把这个节点加进来正常工作。

**antirez 和 Martin Kleppmann 的讨论**

锁服务是正常的，但是由于锁是有持有时间的，由于客户端阻塞、长时间的 GC 或者网络原因，导致共享资源被一个以上的客户端同时访问了，异常导致锁过期的那个节点影响其他正常的部分。

Martin Kleppmann 认为每次锁服务在授予锁或者租约时，还会同时返回一个 fencing token，该令牌每次授予都会递增。要求客户端每次向存储系统发送写请求时，都必须包含所持有的 fencing 令牌。存储系统需要对令牌进行校验，发现如果已经处理过更高令牌的请求，则拒绝执行该请求。服务端必须防范这种来自客户端的滥用。

Martin Kleppmann 还认为 Redlock 严重依赖系统时钟（如延迟启动），所以一旦系统的时间变得不准确了，那么该算法的安全性也就得不到保障了。在极其极端的情况下，分布式系统顶天了也就是在有限的时间内不能给出结果而已，而不能给出一个错误的结果。

antirez 同意大的系统时钟跳跃会造成 Redlock 失效的。在这一点上，他与长发哥的观点的不同在于，他认为在实际系统中是可以通过好的运维方式避免大的时钟跳跃的。

**Redission 实现 Redis 的分布式锁**

Redlock 实在不是一个好的选择，对于需求性能的分布式锁应用它太重了且成本高，对于需求正确性的应用来说它不够安全。

如果你的应用只需要高性能的分布式锁不要求多高的正确性，那么单节点 Redis 够了。如果你的应用想要保住正确性，那么不建议 Redlock，建议使用一个合适的一致性协调系统，例如 Zookeeper，且保证存在 fencing token。

#### ZooKeeper 的有序节点

创建临时有序节点来实现分布式锁，适用于顺序执行的程序。

**有序节点**

会在节点名的后面加一个数字后缀，并且是有序的。

**监听器**

为一个节点注册监听器，在节点状态发生改变时，会给客户端发送消息。

**实现**

1. 创建一个锁目录 /lock。

2. 当一个客户端需要获取锁时，在 /lock 下创建临时的且有序的子节点。
3. 客户端获取 /lock 下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则认为获得锁；否则监听自己的前一个子节点，获得子节点的变更通知后重复此步骤直至获得锁。
4. 执行业务代码，完成后，删除对应的子节点。

<img src="/Users/wangjie/Desktop/面试知识点/pic/dis1.jpg" alt="640"  />

**会话超时**

如果一个已经获得锁的会话超时了，因为创建的是临时节点，所以该会话对应的临时节点会被删除，其它会话就可以获得锁了。

不会出现数据库的唯一索引实现的分布式锁释放锁失败问题。

**羊群效应**

一个节点未获得锁，只需要监听自己的前一个子节点，这是因为如果监听所有的子节点，那么任意一个子节点状态改变，其它所有子节点都会收到通知（羊群效应），而我们只希望它的后一个子节点收到通知。

**Curator 实现 ZooKeeper 的分布式锁**

**Redis 分布式锁和 ZooKeeper 分布式锁的对比**

- Redis 分布式锁，其实需要自己不断去尝试获取锁，比较消耗性能。ZooKeeper 分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较小。

- 如果是 Redis 获取锁的那个客户端出现 bug 挂了，那么只能等待超时时间之后才能释放锁；而 ZooKeeper 的话，因为创建的是临时 znode，只要客户端挂了，znode 就没了，此时就自动释放锁。

- Redis 分布式锁麻烦，ZooKeeper 分布式锁语义清晰实现简单。

ZooKeeper 强一致性，锁的模型健壮，简单易用。在实践中，当然是从以可靠性为主，所以首推 ZooKeeper。



## 2.分布式事务

指事务的操作位于不同的节点上，且属于不同的应用，需要保证事务的 ACID 特性。

本质上来说，分布式事务就是为了保证不同数据库的数据一致性。

**分布式锁和分布式事务的区别**

锁问题的关键在于进程操作的互斥关系，而事务问题的关键则在于事务涉及的一系列操作需要满足 ACID 特性。

#### 两阶段提交 2PC

遵循 XA 协议，通过引入事务管理器 coordinator 来协调参与者的行为，并最终决定这些参与者是否要真正执行事务。

**运行过程**

**准备阶段**

协调者询问参与者事务是否执行成功，参与者发回事务执行结果。询问可以看成一种投票，需要参与者都同意才能执行。

未准备表示本参与者无法拿到全局事务所需的本地资源，因为它被其他本地事务锁住了。或超时。

**提交阶段**

如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。

在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。

**存在的问题**

**同步阻塞**

所有事务参与者在等待其它参与者响应的时候都处于同步阻塞状态，无法进行其它操作。性能差。

**单点问题**

协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响。特别是在提交阶段发生故障，所有参与者会一直同步阻塞等待，无法完成其它操作。

**数据不一致**

在提交阶段，如果协调者只发送了部分 commit 消息，此时网络发生异常，那么只有部分参与者接收到 commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。

**太过保守**

任意一个节点失败就会导致整个事务失败，没有完善的容错机制。

**评价**

这种分布式事务方案，比较适合单块应用里，跨多个库的分布式事务，而且因为严重依赖于数据库层面来搞定复杂的事务，效率很低，绝对不适合高并发的场景。如果要玩儿，那么基于 Spring + JTA 就可以搞定。

这个方案，我们很少用，一般来说某个系统内部如果出现跨多个库的这么一个操作，是不合规的。现在微服务，一个大的系统分成几十个甚至几百个服务。一般来说，我们的规定和规范，是要求每个服务只能操作自己对应的一个数据库。

如果你要操作别人的服务的库，你必须是通过调用别的服务的接口来实现，绝对不允许交叉访问别人的数据库。

在多个系统服务利用 API 接口相互调用的时候，就不遵守 XA 协议了，这时候 2PC 就不适用了。

#### 三阶段提交 3PC

是两阶段提交协议的改进版本。它通过超时机制解决了阻塞的问题，并且在准备阶段和提交阶段之间多了询问阶段。加强了整个事务过程的可靠性。

**询问阶段**

协调者询问参与者是否可以完成指令，协调者只需要回答是还是不是，而不需要做真正的操作，这个阶段超时导致中止。

**评价**

3PC 通过一系列的超时机制很好的缓解了阻塞问题，但是最重要的一致性并没有得到根本的解决，比如在 PreCommit 阶段，当一个参与者收到了请求之后其他参与者和协调者挂了或者出现了网络分区，这个时候收到消息的参与者都会进行事务提交，这就会出现数据不一致性问题。

**2PC 和 3PC 比较**

询问阶段可以确保尽可能早的发现无法执行操作而需要中止的行为，但是它并不能发现所有的这种行为，只会减少这种情况的发生。

在准备阶段以后，协调者和参与者执行的任务中都增加了超时，一旦超时，协调者和参与者都继续提交事务，默认为成功，这也是根据概率统计上超时后默认成功的正确性最大。

但是一旦发生超时，系统仍然会发生不一致，只不过这种情况很少见罢了，好处就是至少不会阻塞和永远锁定资源。

#### TCC

try、confirm、cancel，采用补偿机制，一般来说跟钱相关的，追求强一致性和更高的并发量。

**try 阶段**

对各个服务的资源做检测以及对资源进行锁定或者预留。

**confirm 阶段**

在各个服务中执行实际的操作，进行事务提交。

**cancel 阶段**

如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作。

**如何解决宕机问题**

不断重试。由于 try 操作锁住了全局事务涉及的所有资源，保证了业务操作的所有前置条件得到满足，因此无论是 confirm 阶段失败还是 cancel 阶段失败都能通过不断重试直至 confirm 或 cancel 成功。

**如何保证幂等性**

不断重试 confirm 和 cancel 的过程中，还要保证 confirm 和 cancel 操作具有幂等性。

每个参与者可以维护一个去重表（可以利用数据库表实现也可以使用内存型 KV 组件实现），记录每个全局事务（以全局事务标记 XID 区分）是否进行过 confirm 或 cancel 操作，若已经进行过，则不再重复执行。

**评价**

这种方案说实话几乎很少人使用，我们用的也比较少，但是也有使用的场景。因为这个事务回滚实际上是严重依赖于你自己写代码来回滚和补偿了，会造成补偿代码巨大，非常之恶心。

比如说我们，一般来说跟钱相关的，跟钱打交道的，支付、交易相关的场景，我们会用 TCC，严格保证分布式事务要么全部成功，要么全部自动回滚，严格保证资金的正确性，保证在资金上不会出现问题。银行账户中用于购买基金的那部分余额首先会被冻结，这个过程大概就是 TCC 的第一阶段。

而且最好是你的各个业务执行的时间都比较短。

但是说实话，一般尽量别这么搞，自己手写回滚逻辑，或者是补偿逻辑，实在太恶心了，那个业务代码是很难维护的。

#### Saga

适合最终一致即可、流程长、还可能要调用其它公司的服务。

选择 TCC 会导致：无法要求其它公司的服务也遵循 TCC 模式。事务边界太长，加锁时间长，会影响并发性能。

**优势**

- 一阶段提交本地事务，无锁，高性能。
- 参与者可异步执行，高吞吐。
- 补偿服务易于实现，因为一个更新操作的反向操作是比较容易理解的。

**缺点**

- 不保证事务的隔离性。

#### 本地消息表

本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终一致性。

不需要依赖本地数据库事务。

**过程**

1. 在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。

2. 之后将本地消息表中的消息转发到消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。

3. 在分布式事务操作的另一方从消息队列中读取一个消息，往自己本地消息表里插入一条数据，并执行消息中的操作。如果这个消息已经被处理过了，那么此时这个事务会回滚，这样保证不会重复处理消息。

如果 B 系统处理失败了，那么就不会更新消息表状态，那么此时 A 系统会定时扫描自己的消息表，如果有未处理的消息，会再次发送到 MQ 中去，让 B 再次处理。

**问题**

同样严重依赖于数据库的消息表来管理事务，不适合高并发场景，难扩展。

#### 事务状态表方案

类似 TCC 的事务解决方案，借助事务状态表来实现。幂等性实现同 TCC。

初始状态为 1，每成功调用一个服务则更新一次状态，最后所有的服务调用成功，状态更新到 3。

有了这张表，就可以启动一个后台任务，扫描这张表中事务的状态，如果一个分布式事务一直（设置一个事务周期阈值）未到状态 3，说明这条事务没有成功执行，于是可以重新调用 repo-service 扣减库存、调用 order-service 生成订单。直至所有的调用成功，事务状态到 3。

如果多次重试仍未使得状态到 3，可以将事务状态置为 error，通过人工介入进行干预。

#### 可靠消息最终一致性方案

**对比其他方案**

无论是 2PC & 3PC 还是 TCC、事务状态表，基本都遵守 XA 协议的思想，这些方案本质上都是事务协调者协调各个事务参与者的本地事务的进度，使所有本地事务共同提交或回滚，最终达成一种全局的 ACID 特性。在协调的过程中，协调者需要收集各个本地事务的当前状态，并根据这些状态发出下一阶段的操作指令。

但是这些全局事务方案由于操作繁琐、时间跨度大，或者在全局事务期间会排他地锁住相关资源，使得整个分布式系统的全局事务的并发度不会太高。

**基于 MQ 来实现事务**

RocketMQ 支持事务。

1. A 系统先发送一个 prepared 消息到 MQ，如果这个 prepared 消息发送失败那么就直接取消操作别执行了。
2. 如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉 MQ 发送确认消息，如果失败就告诉 MQ 回滚消息。
3. 如果发送了确认消息，那么此时 B 系统会接收到确认消息，然后执行本地的事务。
4. MQ 会自动定时轮询所有 prepared 消息回调你的接口，问你，这个消息是不是本地事务处理失败了，所有没发送确认的消息，是继续重试还是回滚？一般来说这里你就可以查下数据库看之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。
5. 这个方案里，要是系统 B 的事务失败了咋办？重试咯，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如 B 系统本地回滚后，想办法通知系统 A 也回滚；或者是发送报警由人工来手工回滚和补偿。
6. 这个还是比较合适的，目前国内互联网公司大都是这么玩儿的，要不你就用 RocketMQ 支持的，要不你就自己基于类似 ActiveMQ？RabbitMQ？自己封装一套类似的逻辑出来，总之思路就是这样子的。消息在发送方不丢失，消息在接收方不被重复消费，实现最终一致性。

#### 最大努力通知

系统 A 本地事务执行完之后，发送个消息到 MQ。

这里会有个专门消费 MQ 的最大努力通知服务，这个服务会消费 MQ 然后写入数据库中记录下来，或者是放入个内存队列也可以，接着调用系统 B 的接口。

要是系统 B 执行成功就 ok 了。要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B，反复 N 次，最后还是不行就放弃。



## 3.CAP

**一致性 consistency**

多个数据副本是否能保持一致的特性，在一致性的条件下，系统在执行数据更新操作之后能够从一致性状态转移到另一个一致性状态。

对系统的一个数据更新成功之后，如果所有用户都能够读取到最新的值，该系统就被认为具有强一致性。

**可用性 availability**

分布式系统在面对各种异常时可以提供正常服务的能力。

在可用性条件下，要求系统提供的服务一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。  

**分区容忍性 partition tolerance**

分布式系统在遇到任何网络分区故障的时候，仍然需要能对外提供一致性和可用性的服务。

网络分区指分布式系统中的节点被划分为多个区域，每个区域内部可以通信，但是区域之间无法通信。

**权衡**

在分布式系统中，分区容忍性必不可少（假设网络是不可靠的），可用性和一致性往往是冲突的。

CP：不能访问未同步完成的节点，也就失去了部分可用性。

AP：允许读取所有节点的数据，但是数据可能不一致。

CAP 仅适用于原子读写的 NoSQL 场景中，并不适合数据库系统。



## 4.BASE

BASE 理论是对 CAP 中一致性和可用性权衡的结果，它的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。

针对数据库领域，BASE 思想的主要实现是对业务数据进行拆分，让不同的数据分布在不同的机器上，以提升系统的可用性。拆分后会涉及分布式事务问题。

**基本可用 basically available**

指分布式系统在出现故障的时候，保证核心可用，允许损失部分可用性。

**软状态 soft state**

指允许系统中的数据存在中间状态，并认为该中间状态不会影响系统整体可用性，即允许系统不同节点的数据副本之间进行同步的过程存在时延。

**最终一致性 eventually consistent**

强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能达到一致的状态。

**ACID 与 BASE 的比较**

ACID 要求强一致性，通常运用在传统的数据库系统上。而 BASE 要求最终一致性，通过牺牲强一致性来达到可用性，通常运用在大型分布式系统中。

在实际的分布式场景中，不同业务单元和组件对一致性的要求是不同的，因此 ACID 和 BASE 往往会结合在一起使用。



## 5.分布式一致性算法

#### Paxos

用于达成共识性问题，即对多个节点产生的值，该算法能保证只选出唯一一个值。

主要有三类节点：提议者 Proposer，接受者 Acceptor，告知者 Learner。

#### **执行过程**

规定一个提议包含两个字段：[n, v]，其中 n 为序号（具有唯一性），v 为提议值。

**Prepare 阶段**

每个 Proposer 都会向所有 Acceptor 发送 Prepare 请求。

1. 当 Acceptor 接收到一个 Prepare 请求，包含的提议为 [n1, v1]，并且之前还未接收过 Prepare 请求，那么发送一个 Prepare 响应，设置当前接收到的提议为 [n1, v1]，并且保证以后不会再接受序号小于 n1 的提议。

2. 如果 Acceptor 接收到一个 Prepare 请求，包含的提议为 [n2, v2]，并且之前已经接收过提议 [n1, v1]。如果 n1 > n2，那么就丢弃该提议请求；否则，发送 Prepare 响应，该 Prepare 响应包含之前已经接收过的提议 [n1, v1]，设置当前接收到的提议为 [n2, v2]，并且保证以后不会再接受序号小于 n2 的提议。

**Accept 阶段**

当一个 Proposer 接收到超过一半 Acceptor 的 Prepare 响应时，就可以发送 Accept 请求。

**Learn 阶段**

Acceptor 接收到 Accept 请求时，如果序号大于等于该 Acceptor 承诺的最小序号，那么就发送 Learn 提议给所有的 Learner。当 Learner 发现有大多数的 Acceptor 接收了某个提议，那么该提议的提议值就被 Paxos 选择出来。

#### **约束条件**

**正确性**

指只有一个提议值会生效。

因为 Paxos 协议要求每个生效的提议被多数 Acceptor 接收，并且 Acceptor 不会接受两个不同的提议，因此可以保证正确性。

**可终止性**

指最后总会有一个提议生效。

Paxos 协议能够让 Proposer 发送的提议朝着能被大多数 Acceptor 接受的那个提议靠拢，因此能够保证可终止性。

**Raft**

用来竞选主节点。



## 6.如何设计一个高并发系统？

高峰期每秒并发量近万，数据库承受不住。大部分场景是读多写少。

dubbo 系统拆分，将一个系统拆分为多个子系统，每个系统连一个数据库。
redis 缓存，对于高并发读，在数据库和缓存里都写一份，读的时候大量走缓存。redis 轻轻松松单机几万的并发。
MQ，对于高并发写，redis 的数据随时就被 LRU 了，数据格式还无比简单，没有事务支持，无法应对写，还得用 mysql。大量的写请求灌入 MQ 里排队，后边系统消费后慢慢写，控制在 mysql 承载范围之内。MQ 单机抗几万并发也是 ok 的。
分库分表。
读写分离，主从架构。
ElasticSearch，es 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为可以扩容加机器来扛更高的并发。一些比较简单的查询、统计类和全文搜索类的操作，可以考虑用 es 来承载。



## 7.分布式计算

数据在各个计算机节点上流动，同时各个计算机节点都能以某种方式访问共享数据，最终分布式计算后的输出结果被持久化存储和输出。

Actor
并行计算模型，异步并发。
并行计算原语：一个 Actor 对接收到的消息做出响应，进行本地决策，可以创建更多的 Actor（子 Actor），或者发送更多的消息；同时准备接收下一条消息。
优点：
1）将消息收发、线程调度、处理竞争和同步的所有复杂逻辑都委托给了 Actor 框架本身，而且对应用来说是透明的，我们可以认为 Actor 只是一个实现了 Runnable 接口的对象。关注多线程并发问题时，只需要关注多个 Actor 之间的消息流即可。 
2）符合 Actor 模型的程序很容易进行测试，因为任意一个 Actor 都可以被单独进行单元测试。如果测试案例覆盖了该 Actor 所能响应的所有类型的消息，我们就可以确定该 Actor 的代码十分可靠。

缺点：
1) Actor 完全避免共享并且仅通过消息来进行交流，使得程序失去了精细化并发调控能力，所以不适合实施细粒度的并行且可能导致系统响应时延的增加。如果在 Actor 程序中引入一些并行框架，就可能会导致系统的不确定性。 
2）尽管使用 Actor 模型的程序 比使用线程和锁模型的程序更容易调试，Actor 模型仍会碰到死锁这一类的共性问题，也会碰到一些 Actor 模型独有的问题（例如信箱移溢出）。

AKKA
Akka 是一个用 Scala 编写的库，用于简化编写容错的、高可伸缩性的 Java 和 Scala 的 Actor 模型应用。
Akka 处理并发的方法基于 Actor 模型。在 Akka 里，Actor 之间通信的唯一机制就是消息传递。
好处：
AKKA 提供一种 Actor 并发模型，其粒度比线程小很多，这意味着你可以在项目中使用大量的 Actor。
Akka 提供了一套容错机制，允许在 Actor 出错时进行一些恢复或者重置操作
AKKA 不仅可以在单机上构建高并发程序，也可以在网络中构建分布式程序，并提供位置透明的 Actor 定位服务

Storm
提供的是面向连续的消息流（Stream）的一种通用的分布式计算解决框架。实时流式计算。
应用场景：日志处理和电商商品推荐
Hadoop 是强大的大数据处理系统（批处理），但是在实时计算方面不够擅长；Storm 的核心功能就是提供强大的实时处理能力，但没有涉及存储；所以 Storm 与 Hadoop 互补。

MapReduce
用于大规模数据集的并行运算
“分而治之”，Mapper 负责“分”，即把复杂的大任务分解为若干个小任务来处理，彼此之间没有依赖关系，以便可以分布到多个计算节点上实现高度的并行计算能力；Reducer 则负责对 map 阶段的结果进行汇总和输出。
这个框架充分利用了磁盘，处处存在着排序和合并。所以适合于实时性不高的离线计算。
Hadoop

Spark
Spark 使用了存储器内运算技术，能在数据尚未写入硬盘时即在存储器内分析运算。Spark 允许用户将数据加载至集群存储器，并多次对其进行查询，非常适合用于机器学习算法。内存计算框架，适合在线、离线快速的大数据处理。



## 8.幂等性

对一个接口多次发起同一个请求，必须保证操作只能执行一次。



Token 机制：防止页面重复提交。

悲观锁：获取数据的时候加锁，锁表或锁行。

乐观锁：基于版本号 version 实现，在更新数据那一刻校验数据。

分布式锁：Redis 或 ZooKeeper 实现。

状态机：状态变更，更新数据时判断状态。

数据要写库，先根据主键查一下，如果这数据都有了，就别插入了，update 一下。

数据库的唯一键约束，重复数据插入会报错，不会导致数据库中出现脏数据。

写 Redis，每次都是 set，天然幂等性。

前端拦截：指通过 HTML 页面来拦截重复请求，比如在用户点击完提交按钮后，我们可以把按钮设置为不可用或者隐藏状态。但前端拦截有一个致命的问题，就是可以直接绕过前端页面，通过模拟请求来重复提交请求。

单机高并发：将请求的业务 ID 存储在内存中，并且通过添加互斥锁来保证多线程下的程序执行安全。在方法执行之前，先判断此业务是否已经执行过，如果执行过则不再执行，否则就正常执行。使用 HashMap 或 LRUMap

#### Sprinig Boot + Redis 实现思路

为需要保证幂等性的每一次请求创建一个唯一标识 Token，先获取 Token，并将此 Token 存入 Redis，请求接口时，将此 Token 放到 header 或者作为请求参数请求接口，后端接口判断 Redis 中是否存在此 Token。

如果存在，正常处理业务逻辑，并从 Redis 中删除此 Token。如果是重复请求，由于 Token 已被删除，则不能通过校验，返回请勿重复操作提示。

每次请求保证唯一性，通过拦截器+注解，也可以利用 Spring AOP 实现。



## 9.顺序性

一旦引入顺序性保障，比如使用分布式锁，会导致系统复杂度上升，而且会带来效率低下，热点数据压力过大等问题。

从业务逻辑上设计的这个系统最好是不需要这种顺序性的保证，将多个操作合并成一个操作。

将某个订单 id 对应的请求扔一个内存队列里去，强制排队，这样来确保他们的顺序性。



## 10.系统拆分

拆分系统将项目分为多个服务，每个人负责每个人的部分，每个服务都独立部署，提高开发效率。

先拆分一轮，后面如果系统更复杂了，可以继续分拆。

http 接口通信维护起来成本很高，你要考虑超时重试、负载均衡等等各种乱七八糟的问题。dubbo 说白了，是一种 rpc 框架，就是说本地就是进行接口调用，但是 dubbo 会代理这个调用请求，跟远程机器网络通信，给你处理掉负载均衡、服务实例上下线自动感知、超时重试等等乱七八糟的问题。那你就不用自己做了，用 dubbo 就可以了。



## 11.大型网站系统架构

系统设计指标

#### **性能**

响应时间

吞吐量

**并发用户数**

多线程和 IO 多路复用处理的并发用户请求。

并发用户数不是越高越好，因为如果并发用户数太高，系统来不及处理这么多的请求，会使得过多的请求需要等待，那么响应时间就会大大提高。

**性能优化**

**集群**

将多台服务器组成集群，使用负载均衡将请求转发到集群中，避免单一服务器的负载压力过大导致性能降低。

**缓存**

- 缓存数据通常位于内存等介质中，这种介质对于读操作特别快。
- 缓存数据可以位于靠近用户的地理位置上。
- 可以将计算结果进行缓存，从而避免重复计算。

**异步**

某些流程可以将操作转换为消息，将消息发送到消息队列之后立即返回，之后这个操作会被异步处理。

#### 伸缩性

指不断向集群中添加服务器来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。

**伸缩性与性能**

如果系统存在性能问题，那么单个用户的请求总是很慢的。

如果系统存在伸缩性问题，那么单个用户的请求可能会很快，但是在并发数很高的情况下系统会很慢。

**实现伸缩性**

应用服务器只要不具有状态，那么就可以很容易地通过负载均衡器向集群中添加新的服务器。

关系型数据库的伸缩性通过 Sharding 来实现，将数据按一定的规则分布到不同的节点上，从而解决单台存储服务器的存储空间限制。

对于非关系型数据库，它们天生就是为海量数据而诞生，对伸缩性的支持特别好。

#### 扩展性

指的是添加新功能时对现有系统的其它应用无影响，这就要求不同应用具备低耦合的特点。

**实现扩展性**

使用消息队列进行解耦，应用之间通过消息传递进行通信；

使用分布式服务将业务和可复用的服务分离开来，业务使用分布式服务框架调用可复用的服务。新增的产品可以通过调用可复用的服务来实现业务逻辑，对其它产品没有影响。

#### 可用性

**冗余**

保证高可用的主要手段是使用冗余，当某个服务器故障时就请求其它服务器。

应用服务器的冗余比较容易实现，只要保证应用服务器不具有状态，那么某个应用服务器故障时，负载均衡器将该应用服务器原先的用户请求转发到另一个应用服务器上，不会对用户有任何影响。

存储服务器的冗余需要使用主从复制来实现，当主服务器故障时，需要提升从服务器为主服务器，这个过程称为切换。

**监控**

对 CPU、内存、磁盘、网络等系统负载信息进行监控，当某个信息达到一定阈值时通知运维人员，从而在系统发生故障之前及时发现问题。

**服务降级**

服务降级是系统为了应对大量的请求，主动关闭部分功能，从而保证核心功能可用。

#### 安全性

要求系统在应对各种攻击手段时能够有可靠的应对措施。

#### 哪些方法提升网站性能，可用性以及并发量

提高硬件能力、增加系统服务器。

使用缓存：本地缓存 JDK 自带的 Map、Guava Cache，分布式缓存 Redis、Memcache。

消息队列：解耦 + 削峰 + 异步。

采用分布式开发：不同的服务部署在不同的机器节点上，并且一个服务也可以部署在多台机器上，然后利用 Nginx 负载均衡访问。这样就解决了单点部署的缺点，大大提高的系统并发量。

数据库分库分表：读写分离、水平分表、垂直分表。

采用集群：多台机器提供相同的服务。

CDN 加速：将一些静态资源比如图片、视频等等缓存到离用户最近的网络节点。

浏览器缓存。

使用合适的连接池：数据库连接池、线程池等等。

适当使用多线程进行开发。

#### 设计高可用系统

高可用描述的是一个系统在大部分时间都是可用的，可以为我们提供服务的。高可用代表系统即使在发生硬件故障或者系统升级的时候，服务仍然是可用的。

一般情况下，我们使用多少个 9 来评判一个系统的可用性。除此之外，系统的可用性还可以用某功能的失败次数与总的请求次数之比来衡量。

**导致系统不可用的情况**

黑客攻击

硬件故障，如服务器宕机。

并发量/用户请求量激增导致整个服务宕掉或者部分服务不可用。

代码中的坏味道导致内存泄漏或者其他问题导致程序挂掉。

网站架构某个重要的角色比如 Nginx 或者数据库突然不可用。

自然灾害或者人为破坏。

**做法**

降级：服务降级是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。

降级往往会指定不同的级别，面临不同的异常等级执行不同的处理。根据服务方式：可以拒接服务，可以延迟服务，也有时候可以随机服务。根据服务范围：可以砍掉某个功能，也可以砍掉某些模块。

总之服务降级需要根据不同的业务需求采用不同的降级策略。主要的目的就是服务虽然有损但是总比没有好。 



代码质量：常见问题有内存泄漏和循环依赖。使用 code review 工具如 sonarqube 和 Arthas。

集群：避免单点故障。

限流：达到指定的阈值时对流量进行控制，以避免被瞬时的流量高峰冲垮。

超时和重试机制：一旦用户请求超过某个时间的得不到响应，就抛出异常。如果不进行超时设置可能会导致请求响应速度慢，甚至导致请求堆积进而让系统无法在处理请求（雪崩）。重试的次数一般设为 3 次，再多次的重试没有好处，反而会加重服务器压力。 

熔断：当所依赖的服务恶化或者调用失败次数达到某个阈值的时候就迅速失败，让当前系统立即切换依赖其他备用服务。Netflix 的 Hystrix 和 alibaba 的 Sentinel。

异步调用：不需要关心最后的结果，这样我们就可以用户请求完成之后就立即返回结果，具体处理我们可以后续再做。使用异步之后我们可能需要适当修改业务流程进行配合。秒杀场景用得比较多。

缓存：避免大量请求直接落到数据库，将数据库击垮。并且储存在内存中，速度相当地快。

回滚机制：快速修复错误版本。

其他：更好的硬件，监控系统资源使用情况增加报警设置，备份并在必要时回滚，灰度发布，定期检查和更换硬件，性能测试。

#### 现代互联网应用系统通常具有的特点

高并发，大流量。

高可用：系统 7×24 小时不间断服务。

海量数据：需要存储、管理海量数据，需要使用大量服务器。

用户分布广泛，网络情况复杂：许多大型互联网都是为全球用户提供服务的，用户分布范围广，各地网络情况千差万别。

安全环境恶劣：由于互联网的开放性，使得互联网更容易受到攻击，大型网站几乎每天都会被黑客攻击。

需求快速变更，发布频繁：和传统软件的版本发布频率不同，互联网产品为快速适应市场，满足用户需求，其产品发布频率是极高的。

渐进式发展：与传统软件产品或企业应用系统一开始就规划好全部的功能和非功能需求不同，几乎所有的大型互联网网站都是从一个小网站开始，渐进地发展起来。

#### 单台服务器无法处理越来越多的流量

简单的扩容，增加系统的服务器，提高硬件能力。

水平拆分和垂直拆分数据/应用，来提升系统的伸缩性，进一步扩容提升系统负载能力。

根据现有系统特性，架构层面进行重构甚至是重新设计。

对于系统设计，理想的情况下应支持线性扩容和弹性扩容，即在系统瓶颈时，只需要增加机器就可以解决系统瓶颈，如降低延迟提升吞吐量，从而实现扩容需求。

拆分需要适应自己的业务。