1.简介
消息队列 MQ 是一种进程间通信或同一进程的不同线程间的通信方式，软件的贮列用来处理一系列的输入，通常是来自用户。
消息队列提供了异步的通信协议，每一个贮列中的纪录包含详细说明的数据，包含发生的时间，输入设备的种类，以及特定的输入参数，也就是说：消息的发送者和接收者不需要同时与消息队列交互。消息会保存在队列中，直到接收者取回它。

请求服务方把请求队列放到队列中即可返回，然后等待服务提供方去队列中获取请求进行处理，之后通过回调等机制把结果返回给请求服务方。
MQ 用在解决分布式事务上，达到最终一致性。
不推荐用 Redis 做消息队列。
MQ 是跨进程通信的方式之一，可理解为异步 RPC，上游系统对调用结果的态度往往是重要不紧急。
分布式的产生是消息队列的基础。

2.消息模型
JMS 消息模型
点对点 P2P：消息生产者向消息队列中发送了一个消息之后，只能被一个消费者消费一次。队列作为消息通信载体，满足生产者与消费者模式。
发布/订阅：消息生产者向频道发送一个消息之后，多个消费者可以从该频道订阅到这条消息并消费。主题 Topic 作为消息通信载体，类似于广播模式。点对点是一种特殊的发布/订阅。

消息队列两者都是用到，比较常用的是发布-订阅模式。
事件驱动架构。对新增业务，只要对该类消息感兴趣，即可订阅该消息，对原有系统和业务没有任何影响，从而实现网站业务的可扩展性设计。

发布与订阅模式 Pub-Sub 和观察者模式 Observer 有以下不同：
观察者模式中，观察者和主题都知道对方的存在；而在发布与订阅模式中，生产者与消费者不知道对方的存在，它们之间通过频道进行通信。
观察者模式是同步的，当事件触发时，主题会调用观察者的方法，然后等待方法返回；而发布与订阅模式是异步的，生产者向频道发送一个消息之后，就不需要关心消费者何时去订阅这个消息，可以立即返回。

JMS 和 AMQP
JMS：Java 消息服务，JMS 的客户端之间可以通过 JMS 服务进行异步的消息传输。JMS API 是一个消息服务的标准或者说是规范，允许应用程序组件基于 JavaEE 平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。尽管 JMS 规范出台已经是很久的事情了,但是 JMS 在当今的 J2EE 应用中间仍然扮演着特殊的地位。
AMQP：高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计，兼容 JMS。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件同产品，不同的开发语言等条件的限制。

区别：
AMQP 为消息定义了线路层的协议，而 JMS 所定义的是 API 规范。
AMQP 天然具有跨平台、跨语言特性。而在 Java 体系中，多个 client 均可以通过 JMS 进行交互，不需要应用修改代码，但是其对跨平台的支持较差。
AMQP 仅支持 byte[] 消息类型（复杂的类型可序列化后发送），而 JMS 支持 TextMessage、MapMessage 等复杂的消息类型。
AMQP 可以提供多样化的路由方式来传递消息到消息队列（Exchange 提供的路由算法），而 JMS 仅支持队列和主题/订阅方式两种。

3.使用场景 (为什么使用消息队列？好处？)
异步处理：发送者将消息发送给消息队列之后，不需要同步等待消息接收者处理完毕，而是立即返回进行其它操作。消息接收者从消息队列中订阅消息之后异步处理。
流量削峰：在高并发的场景下，如果短时间有大量的请求到达会压垮服务器。可以将请求发送到消息队列中，服务器按照其处理能力从消息队列中订阅消息进行处理。
应用解耦：模块之间不直接进行调用，模块之间耦合度很低，修改一个模块或者新增一个模块对其它模块的影响会很小，从而实现可扩展性。通过使用消息队列，一个模块只需要向消息队列中发送消息，其它模块可以选择性地从消息队列中订阅消息从而完成调用。

其中异步达到了削峰的效果。只有在业务流程允许异步处理的情况下才能这么做。通过异步处理提高系统性能，减少响应所需时间。
消息队列服务器处理速度快于数据库，也比数据库有更好的伸缩性，因此响应速度得到大幅改善。
为了避免消息队列服务器宕机造成消息丢失，会将成功发送到消息队列的消息存储在消息生产者服务器上，等消息真正被消费者服务器处理后才删除消息。在消息队列服务器宕机后，生产者服务器会选择分布式消息队列服务器集群中的其他服务器发布消息。

缺点
系统可用性降低：引入 MQ 之后需要去考虑消息丢失或者说 MQ 挂掉等等的情况。系统引入的外部依赖越多，越容易挂掉。
复杂度提高：加入 MQ 之后需要保证消息没有被重复消费、处理消息丢失的情况和保证消息传递的顺序性等等问题。
带来一致性问题：消息的真正消费者并没有正确消费消息，就会导致数据不一致的情况。
还有消息堆积和分布式事务问题。 

4.可靠性
发送端：发送端完成操作后一定能将消息成功发送到消息队列中。
实现方法：在本地数据库建一张消息表，将消息数据与业务数据保存在同一数据库实例里，这样就可以利用本地数据库的事务机制。事务提交成功后，将消息表中的消息转移到消息队列中，若转移消息成功则删除消息表中的数据，否则继续重传。

接收端：接收端能够从消息队列成功消费一次消息。
实现方法：保证接收端处理消息的业务逻辑具有幂等性，只要具有幂等性，那么消费多少次消息，最后处理的结果都是一样的；保证消息具有唯一编号，并使用一张日志表来记录已经消费的消息编号。

5.常见消息队列 ActiveMQ、RabbitMQ、RocketMQ、Kafka 比较
ActiveMQ：Apache 出品。
吞吐量：比 RocketMQ 和 Kafka 低
延迟：ms 级
可用性：基于主从架构实现高可用	
可靠性：有较低的概率丢失数据
MQ 领域的功能极其完备
基于 JMS 规范实现
流行，性能差，没经过大规模吞吐量场景的验证，社区不是很活跃
点对点工作模式

RabbitMQ：Erlang 语言开发。
吞吐量：比 RocketMQ、Kafka 低
延迟：us 级，延迟最低，这是 RabbitMQ 的一大特点
可用性：基于主从架构实现高可用
可靠性：有较低的概率丢失数据
并发能力很强，性能极好，延时很低
基于 AMQP 协议实现
开源，有稳定的支持，活跃度也高

RocketMQ：阿里出品，Java 系开源项目。
吞吐量：高吞吐，topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic
延迟：ms 级
可用性：非常高，分布式架构
可靠性：高，经过参数优化配置可以做到 0 丢失
MQ 功能较为完善，扩展性好
活跃度不算高，有风险
接口这块不是按照标准 JMS 规范走的，有些系统要迁移需要修改大量代码
RocketMQ 思路起源于 Kafka

Kafka：
和 RocketMQ 相似，功能较为简单，主要支持简单的 MQ 功能。
大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准，社区活跃度很高。
Kafka 主要特点是基于 Pull 的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输。0.8 版本开始支持复制，不支持事务，对消息的重复、丢失、错误没有严格要求，适合产生大量数据的互联网服务的数据收集业务。
同时 kafka 最好是支撑较少的 topic 数量即可，保证其超高吞吐量。topic 从几十到几百个时候，吞吐量会大幅度下降。
kafka 唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响。
分布式、可分区、可复制、基于发布/订阅。

6.如何保证高可用
RabbitMQ 的高可用性（主从式）：
单机模式
普通集群模式：普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。
没做到分布式，无高可用，主要为了提高吞吐量。要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。
而且如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。

镜像集群模式：真正的高可用。创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。
宕机了 consumer 可以到其它节点上去消费数据。性能开销太大，不是分布式（RabbitMQ 一个 queue 的数据都是放在一个节点里），不能扩展。

Kafka 的高可用性（分布式）：
Kafka 由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。
天然的分布式消息队列，一个 topic 的数据，是分散放在多个机器上的，每个机器就放一部分数据。
Kafka 0.8 以后，提供了 HA 机制，就是复制品 replica 副本机制：每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。
写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。要是可以随意读写每个 follower，那么就要 care 数据一致性的问题，系统复杂度太高，很容易出问题。
Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。
如果某个 broker 宕机了，没事儿，那个 broker 上面的 partition 在其他机器上都有副本的。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中重新选举一个新的 leader 出来，大家继续读写那个新的 leader 即可。
写数据的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。
消费的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。

7.如何保证消息消费的幂等性（不被重复消费）
Kafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，每隔一段时间（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。
要是消费到第二次的时候，自己判断一下是否已经消费过了，若是就直接扔了，这样不就保留了一条数据，从而保证了数据的正确性。

数据要写库，先根据主键查一下，如果这数据都有了，就别插入了，update 一下。
写 Redis，每次都是 set，天然幂等性。
让生产者发送每条数据的时候，里面加一个全局唯一的 id。消费前查一下之前有没有消费过。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

这些实现幂等的方法也同样适用于互联网的其他领域。

8.如何保证消息的可靠性传输（处理消息丢失的问题）
用 MQ 有个基本原则，就是数据不能多一条，也不能少一条，不能多，就是前面说的重复消费和幂等性问题。不能少，就是说这数据别搞丢了。
RabbitMQ：
生产者弄丢了数据：事务机制（同步 Rollback 和 Commit，导致吞吐量下降，性能降低）和 confirm 机制（异步消息回调）可以选择。一般在生产者避免数据丢失，都是用 confirm 机制的。               
RabbitMQ 弄丢了数据：开启 RabbitMQ 的持久化，故障恢复。可以跟生产者那边的 confirm 机制配合起来,只有消息被持久化到磁盘之后，才会通知生产者 ack。                            
消费端弄丢了数据：ack 机制。

Kafka：
生产者设置了 acks=all，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。
Kafka 弄丢了数据：leader 所在的 broker 宕机，重新选举 leader 的过程中有 follower 刚好还有些数据没有同步。配置 topic，Kafka 服务端，producer 端。
消费端弄丢了数据：关闭自动提交 offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。此时可能会有重复消费，需要自己保证幂等性。

Kafka 中的可靠性保证有如下四点：
对于一个分区来说，它的消息是有序的。如果一个生产者向一个分区先写入消息 A，然后写入消息 B，那么消费者会先读取消息 A 再读取消息 B。
当消息写入所有 in-sync 状态的副本后，消息才会认为已提交 committed。这里的写入有可能只是写入到文件系统的缓存，不一定刷新到磁盘。生产者可以等待不同时机的确认，比如等待分区主副本写入即返回，后者等待所有 in-sync 状态副本写入才返回。
一旦消息已提交，那么只要有一个副本存活，数据不会丢失。
消费者只能读取到已提交的消息。

9.如何保证消息的顺序性？
RabbitMQ：拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点。
或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。 

Kafka：
一个 Topic，一个 Partition，一个 Consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。
写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue。然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。

顺序性包括局部有序和全局有序。Partition 内部具有顺序性（尾追加写、offset 读），而保证 Partition 间的顺序需要：
发送端不能异步发送。
存储端消息不能分区，发送消息的时候指定 key，发送到同一个 Partition。同步复制，且高可用问题里切机器之前，挂掉的机器上面，所有消息必须消费完。
接收端不能并行消费。

10.如何解决大量消息在 mq 里积压
临时紧急扩容：
先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。
新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。
然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。
接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。
等快速消费完积压数据之后，得恢复原先部署的架构。

mq 中的消息过期失效了导致数据丢失：批量重导，把丢失的数据补回来。
mq 都快写满了：临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后到了晚上再补数据吧。

原因：生产者生产太快或者消费者消费太慢。
限流降级，增加多个消费者实例去水平扩展增加消费能力来匹配生产的激增。同时你还需要增加每个主题的队列数量。
检查是否是消费者出现了大量的消费错误，或者打印一下日志查看是否是哪一个线程卡死，出现了锁资源不释放等等的问题。

11.让你写一个消息队列，该如何进行架构设计？
可伸缩性：需要的时候快速扩容以增加吞吐量和容量。参考 kakfa 分布式系统，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，给 topic 增加 partition，然后做数据迁移，增加机器。
持久化：保证数据不会丢失，落地磁盘时顺序写，没有磁盘随机读写的寻址开销，这就是 kafka 的思路。
可用性：多副本 -> leader&follower -> broker 挂了重新选举 leader。
可靠性

12.RabbitMQ
Exchange：
生产者与消费者模型，Producer->Exchange->Queue->Consumer。更像是一种交换机模型。
交换器 Exchange 用来接收生产者发送的消息并将这些消息路由给服务器中的队列中，如果路由不到，或许会返回给生产者 Producer，或许会被直接丢弃掉。
RabbitMQ 的 Exchange 有 4 种类型，不同的类型对应着不同的路由策略：direct（默认），fanout，topic，和 headers（不推荐）。AMQP 规范里还提到两种 Exchange Type，分别为 system 与自定义。
生产者将消息发给交换器的时候，一般会指定一个路由键 RoutingKey，用来指定这个消息的路由规则，而这个 RoutingKey 需要与交换器类型和绑定键 BindingKey 联合使用才能最终生效。
RabbitMQ 中通过绑定 Binding 将 Exchange 与消息队列 Queue 关联起来，在绑定的时候一般会指定一个 BindingKey，这样 RabbitMQ 就知道如何正确将消息路由到队列了。
可以将交换器理解成一个由绑定构成的路由表。Exchange 和 Queue 的绑定可以是多对多的关系。当 BindingKey 和 RoutingKey 相匹配时，消息会被路由到对应的队列中。

Queue：
Queue 用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。消息一直在队列里面，等待消费者连接到这个队列将其取走。
RabbitMQ 中消息只能存储在队列中，这一点和 Kafka 这种消息中间件相反。Kafka 将消息存储在主题 topic 这个逻辑层面，而相对应的队列逻辑只是 topic 实际存储文件中的位移标识。
一个消息可投入一个或多个队列。多个消费者可以订阅同一个队列，这时队列中的消息会被平均分摊（Round-Robin，即轮询）给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理，这样避免的消息被重复消费。RabbitMQ 不支持队列层面的广播消费。

Broker：消息中间件的服务节点或者服务实例，大多数情况下也可以将一个 RabbitMQ Broker 看作一台 RabbitMQ 服务器。

13.RocketMQ
角色：Producer Group 生产者组，Consumer Group 消费者组，Topic 主题。
主题中存在多个队列来提高并发能力，一个消费者集群多台机器共同消费一个 topic 的多个队列，一个队列只会被一个消费者消费。消费者组中的消费者个数和主题中队列个数相同。
有多个消费者组，那么消息被一个消费者组消费完之后是不会删除的，会为每个消费者组维护一个消费位移 offset，每次消费者组消费完会返回一个成功的响应，然后队列再把维护的消费位移加一，这样就不会出现刚刚消费过的消息再一次被消费了。

Broker：消息队列服务器。Topic 与 Broker 是多对多的关系。
NameServer：注册中心，Broker 管理和路由信息管理。NameServer 用来解决 Broker 集群修改时会牵连生产者和消费者，而产生的耦合问题。
Consumer 采用 push 和 pull 两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制。
Broker 还有主从部署
NameServer 也做了集群部署，但是请注意它是去中心化的。在 RocketMQ 中是通过单个 Broker 和所有 NameServer 保持长连接，并且在每隔 30 秒 Broker 会向所有 Nameserver 发送心跳，心跳包含了自身的 Topic 配置信息。
在 Producer 需要向 Broker 发送消息的时候，需要先从 NameServer 获取关于 Broker 的路由信息，然后通过轮询的方法去向每个队列中生产数据以达到负载均衡的效果。
Producer 通过 NameServer 获取所有 Broker 的路由信息后，向 Broker 发送 Pull 请求来获取消息数据。
Consumer 可以以两种模式启动：广播 Broadcast 和集群 Cluster。广播模式下，一条消息会发送给同一个消费组中的所有消费者，集群模式下消息只会发送给一个消费者。

消息丢失：当你系统需要保证百分百消息不丢失，你可以使用生产者每发送一个消息，Broker 同步返回一个消息发送成功的反馈消息。即每发送一个消息，同步落盘后才返回生产者消息发送成功，这样只要生产者得到了消息发送生成的返回，事后除了硬盘损坏，都可以保证不会消息丢失。
加快同步落盘：使用 FileChannel + DirectBuffer 池，使用堆外内存，加快内存拷贝。使用数据和索引分离，当消息需要写入时，使用 commitlog 文件顺序写，当需要定位某个消息时，查询 index 文件来定位，从而减少文件 IO 随机读写的性能损耗。
消息堆积：后台定时任务每隔 72 小时，删除旧的没有使用过的消息信息。根据不同的业务实现不同的丢弃任务。消息定时转移，或者对某些重要的 TAG 型（支付型）消息真正落库。
定时消息：实际 RocketMQ 没有实现任意精度的定时消息，它只支持某些特定的时间精度的定时消息。创建特定时间精度的 MessageQueue，newSingleThreadScheduledExecutor 定时执行任务。
顺序消息：与定时消息同原理，生产者生产消息时指定特定的 MessageQueue，消费者消费消息时，消费特定的 MessageQueue。前提是消费者串行消费，锁，阻塞。
消息的 push 延迟问题：因为这并不是真正的将消息主动的推送到消费者，而是 Broker 定时任务每 5s 将消息推送到消费者。
消息重复发送的避免：由于网络延迟不可避免，默认允许消息重复发送。RocketMQ 让使用者在消费者端去解决该问题。最简单的解决方案是每条消费记录有个消费状态字段，根据这个消费状态字段来是否消费或者使用一个集中式的表，来存储所有消息的消费状态，从而避免重复消费。
广播消费与集群消费：广播消费，订阅该 Topic 的消息者们都会消费每个消息，每个消费者都独立的去消费每个消息，因此每个消费者各自保存自己的消息消费进度。集群消费，订阅该 Topic 的消息者们只会有一个去消费某个消息，总体的消费进度保存在 Broker 上集中的管理。消息落盘。

RocketMQ 用 2PC 实现分布式消息。prepared->commit/rollback。注意，就算是事务消息最后回滚了也不会物理删除，只会逻辑删除该消息。
RocketMQ 不使用 ZooKeeper 作为注册中心，而使用自制的 NameServer。
ZooKeeper 支持顺序一致性，在某些情况下，它为了满足一致性，会丢失一定时间内的可用性。RocketMQ 需要注册中心只是为了发现组件地址，在某些情况下，NameServer 可以出现数据不一致性，因为 NameServer 集群间互不通信。 
当有新的服务器加入时，NameServer 并不会立马通知到 Produer，而是由 Produer 定时去请求 NameServer 获取最新的 Broker/Consumer 信息（这种情况是通过 Producer 发送消息时，负载均衡解决）。

组件通信间使用 Netty 的自定义协议。
Dubbo 负载均衡策略。
消息过滤器：Producer 发送消息到 Broker，Broker 存储消息信息，Consumer 消费时请求 Broker 端从磁盘文件查询消息文件时,在 Broker 端就使用过滤服务器进行过滤。
Broker 同步双写和异步双写中 Master 和 Slave 的交互。
Broker 在 4.5.0 版本更新中引入了基于 Raft 协议的多副本选举。

分布式事务：
在 RocketMQ 中使用的是事务消息加上事务反查机制来解决分布式事务问题。
第一步：发送 half 消息，它的意思是在事务提交之前，对于消费者来说，这个消息是不可见的。
如何做到写入消息但是对用户不可见呢？RocketMQ 事务消息的做法是：如果消息是 half 消息，将备份原消息的主题与消息消费队列，然后改变主题为 RMQ_SYS_TRANS_HALF_TOPIC。由于消费组未订阅该主题，故消费端无法消费 half 类型的消息。
然后 RocketMQ 会开启一个定时任务，从 Topic 为 RMQ_SYS_TRANS_HALF_TOPIC 中拉取消息进行消费，根据生产者组获取一个服务提供者发送回查事务状态请求，根据事务状态来决定是提交或回滚消息。

第二步：MQ 服务端响应消息
第三步：系统 A 事务处理
第四步：根据事务执行情况 commit 或 rollback，一般在这一步系统 A 就可以异步进行下一步操作了。
第五步：如果因为网络或者其他原因 MQ 服务端没有收到第四步的消息，则 MQ 服务端会发送消息进行事务反查。
第六步：检查本系统事务状态
第七步：根据事务状态再次进行 commit 或 rollback

3.1.2 之前的有事务消息回查功能的版本。消息回查功能基于文件系统，回查后得到的结果以及正常的处理结果 Commit/Rollback 都会修改 CommitLog 里 PREPARED 消息的状态，这会导致内存中脏页过多，有隐患。
在之后的版本移除了基于文件系统的状态修改机制，对事务消息的处理流程进行重做，移除了消息回查功能。事务消息回查改为基于数据库实现。

出现网路波动，MQ 不知道是不是需要给消费者消费的问题。Kafka 中通常是直接抛出一个异常让用户来自行解决。
在消息队列中的分布式事务是，本地事务和存储消息到消息队列才是同一个事务。这样也就产生了事务的最终一致性，因为整个过程是异步的，每个系统只要保证它自己那一部分的事务就行了。

回溯消费：Consumer 已经消费成功的消息，由于业务上需求需要重新消费。Broker 在向 Consumer 投递成功消息后，消息仍然需要保留。可以按照时间维度来回退消费进度。
同步刷盘：需要等待一个刷盘成功的 ACK，同步刷盘对 MQ 消息可靠性来说是一种不错的保障，但是性能上会有较大影响。
异步刷盘：往往是开启一个线程去异步地执行刷盘操作。消息刷盘采用后台异步线程提交的方式进行，降低了读写延迟，提高了 MQ 的性能和吞吐量。一般地，异步刷盘只有在 Broker 意外宕机的时候会丢失部分数据。
同步刷盘和异步刷盘是在单个结点层面的，而同步复制和异步复制主要是指的 Borker 主从模式下，主节点返回消息给客户端的时候是否需要同步从节点。
同步复制：也叫同步双写，也就是说，只有消息同步双写到主从结点上时才返回写入成功。
异步复制：消息写入主节点之后就直接返回写入成功。异步复制不会像异步刷盘那样影响消息的可靠性。异步同步复制策略仅仅是影响到了可用性。因为 RocketMQ 是不支持自动主从切换的，当主节点挂掉之后，生产者就不能再给这个主节点生产消息了。而消费者可以自动切换到从节点进行消费，在主节点挂掉的时间只会产生主从结点短暂的消息不一致的情况，降低了可用性。

Dledger 要求在写入消息的时候，要求至少消息复制到半数以上的节点之后，才给客⼾端返回写⼊成功，并且它是⽀持通过选举来动态切换主节点的。
在 Dledger 选举过程中是无法提供服务的，而且他必须要使用三个节点或以上，如果多数节点同时挂掉他也是无法保证可用性的，而且要求消息复制板书以上节点的效率和直接异步复制还是有一定的差距的。

存储机制

RocketMQ 在主题上是无序的，它只有在队列层面才是保证有序的。
普通顺序：同一个消费队列收到的消息是有顺序的，不同消息队列收到的消息则可能是无顺序的。普通顺序消息在 Broker 重启情况下不会保证消息顺序性 (短暂时间) 。
严格顺序：消费者收到的所有消息均是有顺序的。严格顺序消息即使在异常情况下也会保证消息的顺序性。实现严格顺序会付出巨大的代价，Broker 集群中只要有一台机器不可用，则整个集群都不可用。
一般而言，我们的 MQ 都是能容忍短暂的乱序，所以推荐使用普通顺序模式。Hash 法将消息放到同一队列实现顺序消息。

14.Kafka
Kafka 是一种分布式的，基于发布/订阅的消息系统。主要设计目标如下：
以时间复杂度为 O(1) 的方式提供消息持久化能力，即使对 TB 级以上数据也能保证常数时间复杂度的访问性能。
高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条以上消息的传输。
支持 Kafka Server 间的消息分区，及分布式消费，同时保证每个 Partition 内的消息顺序传输。
同时支持离线数据处理和实时数据处理。
Scale out：支持在线水平扩展。

优点
极致的性能：基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。
生态系统兼容性无可匹敌：Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。

功能
消息队列：发布和订阅消息流。
容错的持久方式存储记录消息流：Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。
流式处理平台

Kafka 的注册中心使用了 Zookeeper，主要为 Kafka 提供元数据的管理的功能。Zookeeper 主要为 Kafka 做了下面这些事情：
Broker 注册：在 Zookeeper 上会有一个专门用来进行 Broker 服务器列表记录的节点。每个 Broker 在启动时，都会到 Zookeeper 上进行注册。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去。
Topic 注册：在 Kafka 中，同一个 Topic 的消息会被分成多个 Partition 并将其分布在多个 Broker 上，这些 Partition 信息及与 Broker 的对应关系也都是由 Zookeeper 在维护。
负载均衡：当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。

基础概念
生产者与消费者。数据集成的 Kafka Connect API 和流式处理的 Kafka Streams 等高阶客户端的底层仍然是生产者和消费者 API。
服务器 Broker：多个 Broker 组成集群 Cluster，Cluster 内某个 Broker 会成为集群控制器 Cluster Controller。每个 Broker 上可以有多个 Topic。
主题 Topic：Kafka 通过 Topic 对消息进行归类，每个记录由一个键、一个值和一个时间戳组成。

分区 Partition：
顺序的、不可变的消息队列，并且可以持续的添加。
Kafka 中可以将 Topic 从物理上划分成一个或多个 Partition，同一 Topic 下的 Partion 可以分布在不同的 Broker 上。每个 Partition 在物理上对应一个文件夹，以 ”topicName_partitionIndex” 的命名方式命名，该 dir 包含了这个分区的所有消息 .log 和索引文件 .index，这使得 Kafka 的吞吐率可以水平扩展。
分区中的消息都被分了一个序列号，称之为偏移量 offset，在每个分区中此偏移量都是唯一的。
Producer 在发布消息的时候，可以为每条消息指定 key，这样消息被发送到 Broker 时，会根据分区算法把消息存储到对应的分区中（一个分区存储多个消息），如果分区规则设置的合理，那么所有的消息将会被均匀的分布到不同的分区中，这样就实现了负载均衡，能提供比较好的并发能力。             
消费者将从 Broker 拉取订阅的消息，生产者向 Broker 发送消息，生产者会根据 Topic 分发消息，并把消息关联到 Topic 上的具体 Partition。最简单的方式从分区列表中轮流选择。也可以根据某种算法依照权重选择分区。算法可由开发者定义。
Kafka 为 Partion 引入了多副本 replica 机制。Partion 中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。为了高可用，故障时主备切换和重新选举 leader。œ

消费组 Cousumer Group：Cousumer 用 Consumer Group 来标识自己。同一个 Consumer Group 可以并发地消费多个 Partition 的消息，同一个 Partition 也可以由多个 Consumer Group 并发消费，但是在 Consumer Group 中一个 Partition 只能由一个 Cousumer 消费。

Kafka 的一个关键性质是日志保留，我们可以配置主题的消息保留策略，譬如只保留一段时间的日志或者只保留特定大小的日志。当超过这些限制时，老的消息会被删除。我们也可以针对某个主题单独设置消息过期策略，这样对于不同应用可以实现个性化。
多集群的原因：基于数据的隔离；基于安全的隔离；多数据中心（容灾）。
多个数据中心需要实现消息互通。多个数据中心的数据需要汇总到一个总控中心来做数据分析。
对于多个 Kafka 集群消息同步可以使用 Kafka 提供的 MirrorMaker 工具。本质上来说，MirrorMaker 只是一个 Kafka 消费者和生产者，并使用一个队列连接起来而已。它从一个集群中消费消息，然后往另一个集群生产消息。

Kafka 的设计与实现
Kafka 的消息是存在于文件系统之上的，高度依赖文件系统来存储和缓存消息。现代的操作系统针对磁盘的读写已经做了一些优化方案来加快磁盘的访问速度。如果是针对磁盘的顺序访问，某些情况下它可能比随机的内存访问都要快，甚至可以和网络的速度相差无几。
Topic 其实是逻辑上的概念，面向消费者和生产者，物理上存储的其实是 Partition，每一个 Partition 最终对应一个目录，每一个目录又被平均分配成多个大小相等的 Segment File，里面存储所有的消息和索引文件。默认情况下，每一个 Topic 在创建时如果不指定 Partition 数量时只会创建 1 个 Partition。
任何发布到 Partition 的消息都会被追加到 Partition 数据文件的尾部，这样的顺序写磁盘操作让 Kafka 的效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是 Kafka 高吞吐率的一个很重要的保证）。
每一条消息被发送到 Broker 中，会根据 Partition 规则选择被存储到哪一个 Partition。如果 Partition 规则设置的合理，所有消息可以均匀分布到不同的 Partition 中。

Kafka 采取稀疏索引存储的方式，每隔一定字节的数据建立一条索引，它减少了索引文件大小，使得能够把 index 映射到内存，降低了查询时的磁盘 IO 开销，同时也并没有给查询带来太多的时间消耗。
当需要查找一个指定 offset 的 message 时，通过在所有 segment 的文件名中进行二分查找就能找到它归属的 segment，再在其 index 文件中找到其对应到文件上的物理位置，就能拿出该 message。
由于消息在 Partition 的 Segment 数据文件中是顺序读写的，且消息消费后不会删除（删除策略是针对过期的 Segment 文件），这种顺序磁盘 IO 存储设计是 Kafka 高性能很重要的原因。

生产者写消息的基本流程：
首先，我们需要创建一个 ProducerRecord，这个对象需要包含消息的主题 Topic 和值 value，可以选择性指定一个键值 key 或者分区 Partition。
发送消息时，生产者会对键值和值序列化成字节数组，然后发送到分配器 partitioner。
如果我们指定了分区，那么分配器返回该分区即可；否则，分配器将会基于键值来选择一个分区并返回。
选择完分区后，生产者知道了消息所属的主题和分区，它将这条记录添加到相同主题和分区的批量消息中，另一个线程负责发送这些批量消息到对应的 Kafka broker。
当 Broker 接收到消息后，如果成功写入则返回一个包含消息的主题、分区及位移的 RecordMetadata 对象，否则返回异常。
生产者接收到结果后，对于异常可能会进行重试。

消费者设计：
可以通过增加消费组的消费者来进行水平扩展提升消费能力。这也是为什么建议创建主题时使用比较多的分区数，这样可以在消费负载高的情况下增加消费者来提升性能。
另外，消费者的数量不应该比分区数多，因为多出来的消费者是空闲的，没有任何帮助。
为了使得每个应用都能读到全量消息，应用需要有不同的消费组。

当新的消费者加入消费组，它会消费一个或多个分区，而这些分区之前是由其他消费者负责的；另外，当消费者离开消费组（比如重启、宕机等）时，它所消费的分区会分配给其他分区。这种现象称为重平衡 rebalance。
重平衡是 Kafka 一个很重要的性质，这个性质保证了高可用和水平扩展。
不过也需要注意到，在重平衡期间，所有消费者都不能消费消息，因此会造成整个消费组短暂的不可用。
而且，将分区进行重平衡也会导致原来的消费者状态过期，从而导致消费者需要重新更新状态，这段期间也会降低消费性能。
消费者通过定期发送心跳 hearbeat 到一个作为组协调者 group coordinator 的 Broker 来保持在消费组内存活。这个 Broker 不是固定的，每个消费组都可能不同。当消费者拉取消息或者提交时，便会发送心跳。
如果消费者超过一定时间没有发送心跳，那么它的会话 session 就会过期，组协调者会认为该消费者已经宕机，然后触发重平衡。可以看到，从消费者宕机到会话过期是有一定时间的，这段时间内该消费者的分区都不能进行消息消费。
通常情况下，我们可以进行优雅关闭，这样消费者会发送离开的消息到组协调者，这样组协调者可以立即进行重平衡而不需要等待会话过期。
在 0.10.1 版本，Kafka 对心跳机制进行了修改，将发送心跳与拉取消息进行分离，这样使得发送心跳的频率不受拉取的频率影响。另外更高版本的 Kafka 支持配置一个消费者多长时间不拉取消息但仍然保持存活，这个配置可以避免活锁 livelock。活锁，是指应用没有故障但是由于某些原因不能进一步消费。

Partition 与消费模型：
Kafka 只会保证在 Partition 内消息是有序的，而不管全局的情况。
无论消息是否被消费，除非消息到期 Partition 从不删除消息。Partition 会为每个 Consumer Group 保存一个偏移量，记录 group 消费到的位置。

Kafka 是 pull 模型：
作为一个消息系统，Kafka 遵循了传统的方式，选择由 Producer 向 Broker push 消息并由 Consumer 从 Broker pull 消息。
push 模式很难适应消费速率不同的消费者，因为消息发送速率是由 Broker 决定的。push 模式的目标是尽可能以最快速度传递消息，但是这样很容易造成 Consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。
而 pull 模式则可以根据 Consumer 的消费能力以适当的速率消费消息。
对于 Kafka 而言，pull 模式更合适。pull 模式可简化 Broker 的设计，Consumer 可自主控制消费消息的速率，同时 Consumer 可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。

Kafka Producer 发送消息的流程：
序列化消息和计算 Partition。
发送到 batch 和唤醒 Sender 线程。
Sender 把消息有序发到 Broker（tp replia leader）：确定 tp relica leader 所在的 Broker，幂等性发送。
Sender 处理 Broker 发来的 produce response。

Consumer 设计
poll 消息：消费者通过 fetch 线程拉消息（单线程）。消费者通过心跳线程来与 Broker 发送心跳，超时会认为挂掉。每个 Consumer Group 在 Broker 上都有一个 coordnator 来管理，消费者加入和退出，以及消费消息的位移都由 coordnator 处理。
位移管理：Consumer 的消息位移代表了当前 group 对 Topic-Partition 的消费进度，Consumer 宕机重启后可以继续从该 offset 开始消费。在 kafka0.8 之前，位移信息存放在 ZooKeeper 上，由于 ZooKeeper 不适合高并发的读写，新版本 Kafka 把位移信息当成消息，发往__consumers_offsets 这个 Topic 所在的 Broker。
Kafka group 状态

重平衡 reblance：当一些原因导致 Consumer 对 Partition 消费不再均匀时，kafka 会自动执行 reblance，使得 Consumer 对 Partition 的消费再次平衡。存在的问题：
在大型系统中，一个 Topic 可能对应数百个 Consumer 实例。这些 Consumer 陆续加入到一个空消费组将导致多次的 rebalance；
此外 Consumer 实例启动的时间不可控，很有可能超出 coordinator 确定的 rebalance timeout，将会再次触发 rebalance，而每次 rebalance 的代价又相当地大，因为很多状态都需要在 rebalance 前被持久化，而在 rebalance 后被重新初始化。

新版本改进：通过延迟进入 PreparingRebalance 状态减少 reblance 次数。

Broker 设计
Broker ZK 注册
Broker 消息存储：Kafka 的消息以二进制的方式紧凑地存储，节省了很大空间。此外消息存在 ByteBuffer 而不是堆，这样 Broker 进程挂掉时，数据不会丢失，同时避免了 GC 问题。通过零拷贝和顺序寻址，让消息存储和读取速度都非常快。处理 fetch 请求的时候通过 zero-copy 加快速度。
Broker 状态数据：每台机器都保存了相同的状态数据。
Broker 负载均衡：分区数量负载，各台 Broker 的 Partition 数量应该均匀。
