1.简介
消息队列 MQ 是一种进程间通信或同一进程的不同线程间的通信方式，软件的贮列用来处理一系列的输入，通常是来自用户。
消息队列提供了异步的通信协议，每一个贮列中的纪录包含详细说明的数据，包含发生的时间，输入设备的种类，以及特定的输入参数，也就是说：消息的发送者和接收者不需要同时与消息队列交互。消息会保存在队列中，直到接收者取回它。
由于消息队列服务器处理速度快于数据库，因此响应速度得到大幅改善。

请求服务方把请求队列放到队列中即可返回，然后等待服务提供方去队列中获取请求进行处理，之后通过回调等机制把结果返回给请求服务方。
MQ 用在解决分布式事务上，达到最终一致性。
不推荐用 Redis 做消息队列。
MQ 是跨进程通信的方式之一，可理解为异步 rpc，上游系统对调用结果的态度往往是重要不紧急。
分布式的产生是消息队列的基础。

2.消息模型
JMS 消息模型
点对点：消息生产者向消息队列中发送了一个消息之后，只能被一个消费者消费一次。队列作为消息通信载体，满足生产者与消费者模式。
发布/订阅：消息生产者向频道发送一个消息之后，多个消费者可以从该频道订阅到这条消息并消费。主题 Topic 作为消息通信载体，类似于广播模式。

消息队列两者都是用到，比较常用的是发布-订阅模式。
事件驱动架构。对新增业务，只要对该类消息感兴趣，即可订阅该消息，对原有系统和业务没有任何影响，从而实现网站业务的可扩展性设计。

发布与订阅模式 Pub-Sub 和观察者模式 Observer 有以下不同：
观察者模式中，观察者和主题都知道对方的存在；而在发布与订阅模式中，生产者与消费者不知道对方的存在，它们之间通过频道进行通信。
观察者模式是同步的，当事件触发时，主题会调用观察者的方法，然后等待方法返回；而发布与订阅模式是异步的，生产者向频道发送一个消息之后，就不需要关心消费者何时去订阅这个消息，可以立即返回。

JMS 和 AMQP
JMS：Java 消息服务，JMS 的客户端之间可以通过 JMS 服务进行异步的消息传输。JMS API 是一个消息服务的标准或者说是规范，允许应用程序组件基于 JavaEE 平台创建、发送、接收和读取消息。它使分布式通信耦合度更低，消息服务更加可靠以及异步性。尽管 JMS 规范出台已经是很久的事情了,但是 JMS 在当今的 J2EE 应用中间仍然扮演着特殊的地位。
AMQP：高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计，兼容 JMS。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件同产品，不同的开发语言等条件的限制。

区别：
AMQP 为消息定义了线路层的协议，而 JMS 所定义的是 API 规范。
AMQP 天然具有跨平台、跨语言特性。在 Java 体系中，多个 client 均可以通过 JMS 进行交互，不需要应用修改代码，但是其对跨平台的支持较差。
AMQP 仅支持 byte[] 消息类型（复杂的类型可序列化后发送），而 JMS 支持 TextMessage、MapMessage 等复杂的消息类型。
AMQP 可以提供多样化的路由方式来传递消息到消息队列，而 JMS 仅支持队列和主题/订阅方式两种。

3.使用场景 (为什么使用消息队列|好处)
异步处理：发送者将消息发送给消息队列之后，不需要同步等待消息接收者处理完毕，而是立即返回进行其它操作。消息接收者从消息队列中订阅消息之后异步处理。
流量削峰：在高并发的场景下，如果短时间有大量的请求到达会压垮服务器。可以将请求发送到消息队列中，服务器按照其处理能力从消息队列中订阅消息进行处理。
应用解耦：模块之间不直接进行调用，模块之间耦合度很低，修改一个模块或者新增一个模块对其它模块的影响会很小，从而实现可扩展性。通过使用消息队列，一个模块只需要向消息队列中发送消息，其它模块可以选择性地从消息队列中订阅消息从而完成调用。

其中异步达到了削峰的效果。只有在业务流程允许异步处理的情况下才能这么做。通过异步处理提高系统性能（削峰、减少响应所需时间）。
消息队列服务器处理速度快于数据库，也比数据库有更好的伸缩性，因此响应速度得到大幅改善。
用户请求数据写入消息队列之后就立即返回给用户了，但是请求数据在后续的业务校验、写数据库等操作中可能失败。因此使用消息队列进行异步处理之后，需要适当修改业务流程进行配合。
比如用户在提交订单之后，订单数据写入消息队列，不能立即返回用户订单提交成功，需要在消息队列的订单消费者进程真正处理完该订单之后，甚至出库后，再通过电子邮件或短信通知用户订单成功。
为了避免消息队列服务器宕机造成消息丢失，会将成功发送到消息队列的消息存储在消息生产者服务器上，等消息真正被消费者服务器处理后才删除消息。

坏处：
系统可用性降低：在加入 MQ 之前，你不用考虑消息丢失或者说 MQ 挂掉等等的情况，但是，引入 MQ 之后你就需要去考虑了。
复杂度提高：加入 MQ 之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题。
带来一致性问题：万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了。
还有重复消费、顺序消费、消息堆积和分布式事务问题。 

4.可靠性
发送端：发送端完成操作后一定能将消息成功发送到消息队列中。
实现方法：在本地数据库建一张消息表，将消息数据与业务数据保存在同一数据库实例里，这样就可以利用本地数据库的事务机制。事务提交成功后，将消息表中的消息转移到消息队列中，若转移消息成功则删除消息表中的数据，否则继续重传。

接收端：接收端能够从消息队列成功消费一次消息。
实现方法：保证接收端处理消息的业务逻辑具有幂等性：只要具有幂等性，那么消费多少次消息，最后处理的结果都是一样的；保证消息具有唯一编号，并使用一张日志表来记录已经消费的消息编号。

5.常见消息队列 ActiveMQ、RabbitMQ、RocketMQ、Kafka 比较
ActiveMQ：Apache 出品
吞吐量比 RocketMQ、Kafka 低
延迟 ms 级
基于主从架构实现高可用	
有较低的概率丢失数据
MQ 领域的功能极其完备
基于 JMS 规范实现
社区比较成熟，版本迭代很慢，性能最差，流行

RabbitMQ：Erlang 语言开发
吞吐量比 RocketMQ、Kafka 低
延迟 us 级，延迟最低，这是 RabbitMQ 的一大特点
基于主从架构实现高可用
有较低的概率丢失数据
并发能力很强，性能极其好
RabbitMQ 有稳定的支持，活跃度也高
基于 AMQP 协议实现

RocketMQ：阿里出品，Java 系开源项目
高吞吐，topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic
延迟 ms 级
可用性高，分布式架构
消息可靠性高，经过参数优化配置可以做到 0 丢失
MQ 功能较为完善，扩展性好
活跃度不算高，有风险
接口这块不是按照标准 JMS 规范走的，有些系统要迁移需要修改大量代码
RocketMQ 思路起源于 Kafka，具有高吞吐量、高可用性、适合大规模分布式系统应用的特点

Kafka：
和 RocketMQ 相似，功能较为简单，主要支持简单的 MQ 功能。
大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准，社区活跃度很高。
Kafka 主要特点是基于 Pull 的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输。0.8 版本开始支持复制，不支持事务，对消息的重复、丢失、错误没有严格要求，适合产生大量数据的互联网服务的数据收集业务。
同时 kafka 最好是支撑较少的 topic 数量即可，保证其超高吞吐量。
kafka 唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响。
基于发布/订阅。

6.如何保证高可用
RabbitMQ 的高可用性（主从式）：
单机模式
普通集群模式：普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。
没做到分布式，无高可用，主要为了提高吞吐量。要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。

镜像集群模式：真正的高可用。创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。
性能开销太大，不是分布式，不能扩展。

Kafka 的高可用性（分布式）：
Kafka 由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。天然的分布式消息队列。
Kafka 0.8 以后，提供了 HA 机制，就是 replica（复制品） 副本机制：每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower。
写的时候，leader 会负责把数据同步到所有 follower 上去，读的时候就直接读 leader 上的数据即可。写每个 follower 时就要 care 数据一致性的问题。Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。
如果某个 broker 宕机了，没事儿，那个 broker 上面的 partition 在其他机器上都有副本的。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中重新选举一个新的 leader 出来，大家继续读写那个新的 leader 即可。
写数据的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。
消费的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。

7.如何保证消息消费的幂等性（不被重复消费）
Kafka 实际上有个 offset 的概念，就是每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，每隔一段时间（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。

要是消费到第二次的时候，自己判断一下是否已经消费过了，若是就直接扔了，这样不就保留了一条数据，从而保证了数据的正确性。
数据要写库，先根据主键查一下，如果这数据都有了，就别插入了，update 一下。
写 Redis，每次都是 set，天然幂等性。
让生产者发送每条数据的时候，里面加一个全局唯一的 id。消费前查一下之前有没有消费过。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据。

这些实现幂等的方法也同样适用于互联网的其他领域。

8.如何保证消息的可靠性传输（处理消息丢失的问题）
RabbitMQ：
生产者弄丢了数据：事务机制（同步 Rollback 和 Commit，导致吞吐量下降，性能降低）和 confirm 机制（异步消息回调）。一般在生产者避免数据丢失，都是用 confirm 机制的。               
RabbitMQ 弄丢了数据：开启 RabbitMQ 的持久化，故障恢复。可以跟生产者那边的 confirm 机制配合起来,只有消息被持久化到磁盘之后，才会通知生产者 ack。                            
消费端弄丢了数据：ack 机制。

Kafka：
生产者设置了 acks=all，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。。
Kafka 弄丢了数据: leader 所在的 broker 宕机，重新选举 leader 的过程中有 follower 刚好还有些数据没有同步。配置 topic,Kafka 服务端,producer 端。
消费端弄丢了数据:关闭自动提交 offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。此时可能会有重复消费，需要自己保证幂等性。

9.如何保证消息的顺序性？
RabbitMQ：拆分多个 queue，每个 queue 一个 consumer，就是多一些 queue 而已，确实是麻烦点；或者就一个 queue 但是对应一个 consumer，然后这个 consumer 内部用内存队列做排队，然后分发给底层不同的 worker 来处理。 
RocketMQ 在主题上是无序的，它只有在队列层面才是保证有序的。
普通顺序：同一个消费队列收到的消息是有顺序的，不同消息队列收到的消息则可能是无顺序的。普通顺序消息在 Broker 重启情况下不会保证消息顺序性 (短暂时间) 。
严格顺序：消费者收到的所有消息均是有顺序的。严格顺序消息即使在异常情况下也会保证消息的顺序性。实现严格顺序会付出巨大的代价，Broker 集群中只要有一台机器不可用，则整个集群都不可用。
一般而言，我们的 MQ 都是能容忍短暂的乱序，所以推荐使用普通顺序模式。Hash 法将消息放到同一队列实现顺序消息。

Kafka：
一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。
写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。

10.如何解决大量消息在 mq 里积压
先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。
新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。
然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的 10 倍数量的 queue。
接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和 consumer 资源扩大 10 倍，以正常的 10 倍速度来消费数据。
等快速消费完积压数据之后，得恢复原先部署的架构

mq 中的消息过期失效了导致数据丢失：批量重导，把丢失的数据补回来。

原因：生产者生产太快或者消费者消费太慢。
限流降级，增加多个消费者实例去水平扩展增加消费能力来匹配生产的激增。同时你还需要增加每个主题的队列数量。
检查是否是消费者出现了大量的消费错误，或者打印一下日志查看是否是哪一个线程卡死，出现了锁资源不释放等等的问题。

11.让你写一个消息队列，该如何进行架构设计？
可伸缩性：需要的时候快速扩容以增加吞吐量和容量。参考 kakfa 分布式系统，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，给 topic 增加 partition，然后做数据迁移，增加机器。
持久化：保证数据不会丢失，顺序 I/O 读写性能高。磁盘随机读写有寻址开销。
可用性：多副本 -> leader&follower -> broker 挂了重新选举 leader。
可靠性

12.RabbitMQ
Exchange：
生产者与消费者模型，Producer->Exchange->Queue->Consumer。更像是一种交换机模型。
交换器 Exchange 用来接收生产者发送的消息并将这些消息路由给服务器中的队列中，如果路由不到，或许会返回给生产者 Producer，或许会被直接丢弃掉。
RabbitMQ 的 Exchange 有 4 种类型，不同的类型对应着不同的路由策略：direct（默认），fanout，topic，和 headers（不推荐）。AMQP 规范里还提到两种 Exchange Type，分别为 system 与自定义。
生产者将消息发给交换器的时候，一般会指定一个路由键 RoutingKey，用来指定这个消息的路由规则，而这个 RoutingKey 需要与交换器类型和绑定键 BindingKey 联合使用才能最终生效。
RabbitMQ 中通过绑定 Binding 将 Exchange 与消息队列 Queue 关联起来，在绑定的时候一般会指定一个 BindingKey，这样 RabbitMQ 就知道如何正确将消息路由到队列了。
可以将交换器理解成一个由绑定构成的路由表。Exchange 和 Queue 的绑定可以是多对多的关系。当 BindingKey 和 RoutingKey 相匹配时，消息会被路由到对应的队列中。

Queue：
Queue 用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。消息一直在队列里面，等待消费者连接到这个队列将其取走。
RabbitMQ 中消息只能存储在队列中，这一点和 Kafka 这种消息中间件相反。Kafka 将消息存储在主题 topic 这个逻辑层面，而相对应的队列逻辑只是 topic 实际存储文件中的位移标识。
一个消息可投入一个或多个队列。多个消费者可以订阅同一个队列，这时队列中的消息会被平均分摊（Round-Robin，即轮询）给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理，这样避免的消息被重复消费。RabbitMQ 不支持队列层面的广播消费。

Broker：消息中间件的服务节点或者服务实例，大多数情况下也可以将一个 RabbitMQ Broker 看作一台 RabbitMQ 服务器。

13.RocketMQ
角色：Producer Group 生产者组，Consumer Group 消费者组，Topic 主题。
主题中存在多个队列来提高并发能力，一个消费者集群多台机器共同消费一个 topic 的多个队列，一个队列只会被一个消费者消费。消费者组中的消费者个数和主题中队列个数相同。
有多个消费者组，那么消息被一个消费者组消费完之后是不会删除的，会为每个消费者组维护一个消费位移 offset，每次消费者组消费完会返回一个成功的响应，然后队列再把维护的消费位移加一，这样就不会出现刚刚消费过的消息再一次被消费了。

Broker：消息队列服务器。Topic 与 Broker 是多对多的关系。
NameServer：注册中心，Broker 管理和路由信息管理。NameServer 用来解决 Broker 集群修改时会牵连生产者和消费者，而产生的耦合问题。
Consumer 采用 push 和 pull 两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制。
Broker 还有主从部署
NameServer 也做了集群部署，但是请注意它是去中心化的。在 RocketMQ 中是通过单个 Broker 和所有 NameServer 保持长连接，并且在每隔 30 秒 Broker 会向所有 Nameserver 发送心跳，心跳包含了自身的 Topic 配置信息。
在 Producer 需要向 Broker 发送消息的时候，需要先从 NameServer 获取关于 Broker 的路由信息，然后通过轮询的方法去向每个队列中生产数据以达到负载均衡的效果。
Producer 通过 NameServer 获取所有 Broker 的路由信息后，向 Broker 发送 Pull 请求来获取消息数据。
Consumer 可以以两种模式启动：广播 Broadcast 和集群 Cluster。广播模式下，一条消息会发送给同一个消费组中的所有消费者，集群模式下消息只会发送给一个消费者。

消息丢失：当你系统需要保证百分百消息不丢失，你可以使用生产者每发送一个消息，Broker 同步返回一个消息发送成功的反馈消息。即每发送一个消息，同步落盘后才返回生产者消息发送成功，这样只要生产者得到了消息发送生成的返回，事后除了硬盘损坏，都可以保证不会消息丢失。
加快同步落盘：使用 FileChannel + DirectBuffer 池，使用堆外内存，加快内存拷贝。使用数据和索引分离，当消息需要写入时，使用 commitlog 文件顺序写，当需要定位某个消息时，查询 index 文件来定位，从而减少文件 IO 随机读写的性能损耗。
消息堆积：后台定时任务每隔 72 小时，删除旧的没有使用过的消息信息。根据不同的业务实现不同的丢弃任务。消息定时转移，或者对某些重要的 TAG 型（支付型）消息真正落库。
定时消息：实际 RocketMQ 没有实现任意精度的定时消息，它只支持某些特定的时间精度的定时消息。创建特定时间精度的 MessageQueue，newSingleThreadScheduledExecutor 定时执行任务。
顺序消息：与定时消息同原理，生产者生产消息时指定特定的 MessageQueue，消费者消费消息时，消费特定的 MessageQueue。前提是消费者串行消费，锁，阻塞。
消息的 push 延迟问题：因为这并不是真正的将消息主动的推送到消费者，而是 Broker 定时任务每 5s 将消息推送到消费者。
消息重复发送的避免：由于网络延迟不可避免，默认允许消息重复发送。RocketMQ 让使用者在消费者端去解决该问题。最简单的解决方案是每条消费记录有个消费状态字段，根据这个消费状态字段来是否消费或者使用一个集中式的表，来存储所有消息的消费状态，从而避免重复消费。
广播消费与集群消费：广播消费，订阅该 Topic 的消息者们都会消费每个消息，每个消费者都独立的去消费每个消息，因此每个消费者各自保存自己的消息消费进度。集群消费，订阅该 Topic 的消息者们只会有一个去消费某个消息，总体的消费进度保存在 Broker 上集中的管理。消息落盘。

RocketMQ 用 2PC 实现分布式消息。prepared->commit/rollback。注意，就算是事务消息最后回滚了也不会物理删除，只会逻辑删除该消息。
RocketMQ 不使用 ZooKeeper 作为注册中心，而使用自制的 NameServer。
ZooKeeper 支持顺序一致性，在某些情况下，它为了满足一致性，会丢失一定时间内的可用性。RocketMQ 需要注册中心只是为了发现组件地址，在某些情况下，NameServer 可以出现数据不一致性，因为 NameServer 集群间互不通信。 
当有新的服务器加入时，NameServer 并不会立马通知到 Produer，而是由 Produer 定时去请求 NameServer 获取最新的 Broker/Consumer 信息（这种情况是通过 Producer 发送消息时，负载均衡解决）。

组件通信间使用 Netty 的自定义协议。
Dubbo 负载均衡策略。
消息过滤器：Producer 发送消息到 Broker，Broker 存储消息信息，Consumer 消费时请求 Broker 端从磁盘文件查询消息文件时,在 Broker 端就使用过滤服务器进行过滤。
Broker 同步双写和异步双写中 Master 和 Slave 的交互。
Broker 在 4.5.0 版本更新中引入了基于 Raft 协议的多副本选举。

分布式事务：
在 RocketMQ 中使用的是事务消息加上事务反查机制来解决分布式事务问题。
第一步：发送 half 消息，它的意思是在事务提交之前，对于消费者来说，这个消息是不可见的。
如何做到写入消息但是对用户不可见呢？RocketMQ 事务消息的做法是：如果消息是 half 消息，将备份原消息的主题与消息消费队列，然后改变主题为 RMQ_SYS_TRANS_HALF_TOPIC。由于消费组未订阅该主题，故消费端无法消费 half 类型的消息。
然后 RocketMQ 会开启一个定时任务，从 Topic 为 RMQ_SYS_TRANS_HALF_TOPIC 中拉取消息进行消费，根据生产者组获取一个服务提供者发送回查事务状态请求，根据事务状态来决定是提交或回滚消息。

第二步：MQ 服务端响应消息
第三步：系统 A 事务处理
第四步：根据事务执行情况 commit 或 rollback，一般在这一步系统 A 就可以异步进行下一步操作了。
第五步：如果因为网络或者其他原因 MQ 服务端没有收到第四步的消息，则 MQ 服务端会发送消息进行事务反查。
第六步：检查本系统事务状态
第七步：根据事务状态再次进行 commit 或 rollback

3.1.2 之前的有事务消息回查功能的版本。消息回查功能基于文件系统，回查后得到的结果以及正常的处理结果 Commit/Rollback 都会修改 CommitLog 里 PREPARED 消息的状态，这会导致内存中脏页过多，有隐患。
在之后的版本移除了基于文件系统的状态修改机制，对事务消息的处理流程进行重做，移除了消息回查功能。事务消息回查改为基于数据库实现。

出现网路波动，MQ 不知道是不是需要给消费者消费的问题。Kafka 中通常是直接抛出一个异常让用户来自行解决。
在消息队列中的分布式事务是，本地事务和存储消息到消息队列才是同一个事务。这样也就产生了事务的最终一致性，因为整个过程是异步的，每个系统只要保证它自己那一部分的事务就行了。

回溯消费：Consumer 已经消费成功的消息，由于业务上需求需要重新消费。Broker 在向 Consumer 投递成功消息后，消息仍然需要保留。可以按照时间维度来回退消费进度。
同步刷盘：需要等待一个刷盘成功的 ACK，同步刷盘对 MQ 消息可靠性来说是一种不错的保障，但是性能上会有较大影响。
异步刷盘：往往是开启一个线程去异步地执行刷盘操作。消息刷盘采用后台异步线程提交的方式进行，降低了读写延迟，提高了 MQ 的性能和吞吐量。一般地，异步刷盘只有在 Broker 意外宕机的时候会丢失部分数据。
同步刷盘和异步刷盘是在单个结点层面的，而同步复制和异步复制主要是指的 Borker 主从模式下，主节点返回消息给客户端的时候是否需要同步从节点。
同步复制：也叫同步双写，也就是说，只有消息同步双写到主从结点上时才返回写入成功。
异步复制：消息写入主节点之后就直接返回写入成功。异步复制不会像异步刷盘那样影响消息的可靠性。异步同步复制策略仅仅是影响到了可用性。因为 RocketMQ 是不支持自动主从切换的，当主节点挂掉之后，生产者就不能再给这个主节点生产消息了。而消费者可以自动切换到从节点进行消费，在主节点挂掉的时间只会产生主从结点短暂的消息不一致的情况，降低了可用性。

Dledger 要求在写入消息的时候，要求至少消息复制到半数以上的节点之后，才给客⼾端返回写⼊成功，并且它是⽀持通过选举来动态切换主节点的。
在 Dledger 选举过程中是无法提供服务的，而且他必须要使用三个节点或以上，如果多数节点同时挂掉他也是无法保证可用性的，而且要求消息复制板书以上节点的效率和直接异步复制还是有一定的差距的。

存储机制

14.Kafka
Kafka 是一种分布式的，基于发布/订阅的消息系统。主要设计目标如下：
以时间复杂度为 O(1) 的方式提供消息持久化能力，即使对 TB 级以上数据也能保证常数时间复杂度的访问性能。
高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条以上消息的传输。
支持 Kafka Server 间的消息分区，及分布式消费，同时保证每个 Partition 内的消息顺序传输。
同时支持离线数据处理和实时数据处理。
Scale out：支持在线水平扩展。

Kafka 的注册中心使用了 Zookeeper，它的分区就相当于 RocketMQ 中的队列。

Kafka 的一个关键性质是日志保留，我们可以配置主题的消息保留策略，譬如只保留一段时间的日志或者只保留特定大小的日志。当超过这些限制时，老的消息会被删除。我们也可以针对某个主题单独设置消息过期策略，这样对于不同应用可以实现个性化。
多集群的原因：基于数据的隔离；基于安全的隔离；多数据中心（容灾）。
多个数据中心需要实现消息互通。多个数据中心的数据需要汇总到一个总控中心来做数据分析。
对于多个 Kafka 集群消息同步可以使用 Kafka 提供的 MirrorMaker 工具。本质上来说，MirrorMaker 只是一个 Kafka 消费者和生产者，并使用一个队列连接起来而已。它从一个集群中消费消息，然后往另一个集群生产消息。

Kafka 的消息是存在于文件系统之上的。现代的操作系统针对磁盘的读写已经做了一些优化方案来加快磁盘的访问速度。
预读会提前将一个比较大的磁盘快读入内存。后写会将很多小的逻辑写操作合并起来组合成一个大的物理写操作。并且，操作系统还会将主内存剩余的所有空闲内存空间都用作磁盘缓存，所有的磁盘读写操作都会经过统一的磁盘缓存（除了直接 I/O 会绕过磁盘缓存）。
综合这几点优化特点，如果是针对磁盘的顺序访问，某些情况下它可能比随机的内存访问都要快，甚至可以和网络的速度相差无几。
Topic 其实是逻辑上的概念，面向消费者和生产者，物理上存储的其实是 Partition，每一个 Partition 最终对应一个目录，每一个目录又被平均分配成多个大小相等的 Segment File，里面存储所有的消息和索引文件。默认情况下，每一个 Topic 在创建时如果不指定 Partition 数量时只会创建 1 个 Partition。
任何发布到 Partition 的消息都会被追加到 Partition 数据文件的尾部，这样的顺序写磁盘操作让 Kafka 的效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是 Kafka 高吞吐率的一个很重要的保证）。
每一条消息被发送到 Broker 中，会根据 Partition 规则选择被存储到哪一个 Partition。如果 Partition 规则设置的合理，所有消息可以均匀分布到不同的 Partition 中。

Kafka 采取稀疏索引存储的方式，每隔一定字节的数据建立一条索引，它减少了索引文件大小，使得能够把 index 映射到内存，降低了查询时的磁盘 IO 开销，同时也并没有给查询带来太多的时间消耗。
当需要查找一个指定 offset 的 message 时，通过在所有 segment 的文件名中进行二分查找就能找到它归属的 segment，再在其 index 文件中找到其对应到文件上的物理位置，就能拿出该 message。
由于消息在 Partition 的 Segment 数据文件中是顺序读写的，且消息消费后不会删除（删除策略是针对过期的 Segment 文件），这种顺序磁盘 IO 存储设计是 Kafka 高性能很重要的原因。

生产者写消息的基本流程：
首先，我们需要创建一个 ProducerRecord，这个对象需要包含消息的主题 Topic 和值 value，可以选择性指定一个键值 key 或者分区 Partition。
发送消息时，生产者会对键值和值序列化成字节数组，然后发送到分配器 partitioner。
如果我们指定了分区，那么分配器返回该分区即可；否则，分配器将会基于键值来选择一个分区并返回。
选择完分区后，生产者知道了消息所属的主题和分区，它将这条记录添加到相同主题和分区的批量消息中，另一个线程负责发送这些批量消息到对应的 Kafka broker。
当 Broker 接收到消息后，如果成功写入则返回一个包含消息的主题、分区及位移的 RecordMetadata 对象，否则返回异常。
生产者接收到结果后，对于异常可能会进行重试。

消费者设计：
可以通过增加消费组的消费者来进行水平扩展提升消费能力。这也是为什么建议创建主题时使用比较多的分区数，这样可以在消费负载高的情况下增加消费者来提升性能。
另外，消费者的数量不应该比分区数多，因为多出来的消费者是空闲的，没有任何帮助。
为了使得每个应用都能读到全量消息，应用需要有不同的消费组。

当新的消费者加入消费组，它会消费一个或多个分区，而这些分区之前是由其他消费者负责的；另外，当消费者离开消费组（比如重启、宕机等）时，它所消费的分区会分配给其他分区。这种现象称为重平衡 rebalance。
重平衡是 Kafka 一个很重要的性质，这个性质保证了高可用和水平扩展。
不过也需要注意到，在重平衡期间，所有消费者都不能消费消息，因此会造成整个消费组短暂的不可用。
而且，将分区进行重平衡也会导致原来的消费者状态过期，从而导致消费者需要重新更新状态，这段期间也会降低消费性能。
消费者通过定期发送心跳 hearbeat 到一个作为组协调者 group coordinator 的 Broker 来保持在消费组内存活。这个 Broker 不是固定的，每个消费组都可能不同。当消费者拉取消息或者提交时，便会发送心跳。
如果消费者超过一定时间没有发送心跳，那么它的会话 session 就会过期，组协调者会认为该消费者已经宕机，然后触发重平衡。可以看到，从消费者宕机到会话过期是有一定时间的，这段时间内该消费者的分区都不能进行消息消费。
通常情况下，我们可以进行优雅关闭，这样消费者会发送离开的消息到组协调者，这样组协调者可以立即进行重平衡而不需要等待会话过期。
在 0.10.1 版本，Kafka 对心跳机制进行了修改，将发送心跳与拉取消息进行分离，这样使得发送心跳的频率不受拉取的频率影响。另外更高版本的 Kafka 支持配置一个消费者多长时间不拉取消息但仍然保持存活，这个配置可以避免活锁 livelock。活锁，是指应用没有故障但是由于某些原因不能进一步消费。

Partition 与消费模型：
Kafka 只会保证在 Partition 内消息是有序的，而不管全局的情况。
无论消息是否被消费，除非消息到期 Partition 从不删除消息。Partition 会为每个 Consumer Group 保存一个偏移量，记录 group 消费到的位置。

Kafka 是 pull 模型：
作为一个消息系统，Kafka 遵循了传统的方式，选择由 Producer 向 Broker push 消息并由 Consumer 从 Broker pull 消息。
push 模式很难适应消费速率不同的消费者，因为消息发送速率是由 Broker 决定的。push 模式的目标是尽可能以最快速度传递消息，但是这样很容易造成 Consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。
而 pull 模式则可以根据 Consumer 的消费能力以适当的速率消费消息。
对于 Kafka 而言，pull 模式更合适。pull 模式可简化 Broker 的设计，Consumer 可自主控制消费消息的速率，同时 Consumer 可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。

Kafka 中的可靠性保证有如下四点：
对于一个分区来说，它的消息是有序的。如果一个生产者向一个分区先写入消息 A，然后写入消息 B，那么消费者会先读取消息 A 再读取消息 B。
当消息写入所有 in-sync 状态的副本后，消息才会认为已提交 committed。这里的写入有可能只是写入到文件系统的缓存，不一定刷新到磁盘。生产者可以等待不同时机的确认，比如等待分区主副本写入即返回，后者等待所有 in-sync 状态副本写入才返回。
一旦消息已提交，那么只要有一个副本存活，数据不会丢失。
消费者只能读取到已提交的消息。

Topic：消息的主题、队列，每一个消息都有它的 Topic，Kafka 通过 Topic 对消息进行归类。Kafka 中可以将 Topic 从物理上划分成一个或多个分区 Partition，每个分区在物理上对应一个文件夹，以 ”topicName_partitionIndex” 的命名方式命名，该 dir 包含了这个分区的所有消息（.log）和索引文件（.index），这使得 Kafka 的吞吐率可以水平扩展。
Partition：每个分区都是一个顺序的、不可变的消息队列，并且可以持续的添加。分区中的消息都被分了一个序列号，称之为偏移量 offset，在每个分区中此偏移量都是唯一的。Producer 在发布消息的时候，可以为每条消息指定 key，这样消息被发送到 Broker 时，会根据分区算法把消息存储到对应的分区中（一个分区存储多个消息），如果分区规则设置的合理，那么所有的消息将会被均匀的分布到不同的分区中，这样就实现了负载均衡。             
Broker：Kafka server，用来存储消息，Kafka 集群中的每一个服务器都是一个 Broker，消费者将从 Broker 拉取订阅的消息，Producer 向 Kafka 发送消息，生产者会根据 Topic 分发消息。生产者也负责把消息关联到 Topic 上的哪一个分区。最简单的方式从分区列表中轮流选择。也可以根据某种算法依照权重选择分区。算法可由开发者定义。
Cousumer：Cousumer 实例可以是独立的进程，负责订阅和消费消息。消费者用 Consumer Group 来标识自己。同一个消费组可以并发地消费多个分区的消息，同一个 Partition 也可以由多个 Consumer Group 并发消费，但是在 Consumer Group 中一个 Partition 只能由一个 Cousumer 消费。

Kafka Producer 发送消息的流程：
计算 Partition：先根据 key 和 value 的配置对消息进行序列化，ProducerRecord 对象中如果指定了 Partition，就使用这个 Partition。否则根据 key 和 Topic 的 Partition 数目取余，如果 key 也没有的话就随机生成一个 counter，使用这个 counter 来和 Partition 数目取余。这个 counter 每次使用的时候递增。
发送到 batch 和唤醒 Sender 线程：根据 topic-partition 获取对应的 batchs（Dueue），然后将消息 append 到 batch 中。如果有 batch 满了则唤醒 Sender 线程。队列的操作是加锁执行，所以 batch 内消息时有序的。后续的 Sender 操作当前方法异步操作。
Sender 把消息有序发到 Broker（tp replia leader）：
确定 tp relica leader 所在的 Broker：Kafka 中每台 Broker 都保存了 kafka 集群的 metadata 信息，metadata 信息里包括了每个 Topic 的所有 Partition 的信息。metadata 更新策略：定期更新 metadata.max.age.ms、失效检测，强制更新：检查到 metadata 失效以后，调用 metadata.requestUpdate() 强制更新。

Sender 有序性和幂等性发送消息：
为实现 Producer 的幂等性，Kafka 引入了 Producer ID（即 PID）和 Sequence Number。对于每个 PID，该 Producer 发送消息的每个 <Topic, Partition> 都对应一个单调递增的 Sequence Number。同样，Broker 端也会为每个 <PID, Topic, Partition> 维护一个序号，并且每 Commit 一条消息时将其对应序号递增。对于接收的每条消息，如果其序号比 Broker 维护的序号大一，则 Broker 会接受它，否则将其丢弃。
如果消息序号比 Broker 维护的序号差值比一大，说明中间有数据尚未写入，即乱序，此时 Broker 拒绝该消息，Producer 抛出 InvalidSequenceNumber。如果消息序号小于等于 Broker 维护的序号，说明该消息已被保存，即为重复消息，Broker 直接丢弃该消息，Producer 抛出 DuplicateSequenceNumber。Sender 发送失败后会重试，这样可以保证每个消息都被发送到 Broker。

Sender 处理 Broker 发来的 produce response：一旦 Broker 处理完 Sender 的 produce 请求，就会发送 produce response 给 Sender，此时 producer 将执行我们为 send（）设置的回调函数。至此 Poducer 的 send 执行完毕。

吞吐性、延时和数据可靠性：buffer 设置大了有助于提升吞吐性，但是 batch 太大会增大延迟。Producer 无需等待 leader 的确认则吞吐最高，但数据可靠性最差。

Sender 线程和长连接：每初始化一个 Producer 实例，都会初始化一个 Sender 实例，新增到 Broker 的长连接。

Consumer 设计：
poll 消息：消费者通过 fetch 线程拉消息（单线程）。消费者通过心跳线程来与 Broker 发送心跳，超时会认为挂掉。每个 Consumer Group 在 Broker 上都有一个 coordnator 来管理，消费者加入和退出，以及消费消息的位移都由 coordnator 处理。
位移管理：Consumer 的消息位移代表了当前 group 对 topic-partition 的消费进度，Consumer 宕机重启后可以继续从该 offset 开始消费。在 kafka0.8 之前，位移信息存放在 ZooKeeper 上，由于 ZooKeeper 不适合高并发的读写，新版本 Kafka 把位移信息当成消息，发往__consumers_offsets 这个 Topic 所在的 Broker，__consumers_offsets 默认有 50 个分区。消息的 key 是 groupId+topic_partition，value 是 offset。
Kafka group 状态

重平衡 reblance：当一些原因导致 Consumer 对 Partition 消费不再均匀时，kafka 会自动执行 reblance，使得 Consumer 对 Partition 的消费再次平衡。发生 rebalance 的时机：
组订阅 Topic 数变更
Topic Partition 数变更
Consumer 成员变更
Consumer 加入群组或者离开群组的时候
Consumer 被检测为崩溃的时候

过程：
举例 1 consumer 被检测为崩溃引起的 reblance：比如心跳线程在 timeout 时间内没和 broker 发送心跳，此时 coordnator 认为该 group 应该进行 reblance。
接下来其他 consumer 发来 fetch 请求后，coordnator 将回复他们进行 reblance 通知。当 consumer 成员收到请求后，只有 leader 会根据分配策略进行分配，然后把各自的分配结果返回给 coordnator。这个时候只有 consumer leader 返回的是实质数据，其他返回的都为空。收到分配方法后，consumer 将会把分配策略同步给各 consumer。
举例 2 consumer 加入引起的 reblance：使用 join 协议，表示有 consumer 要加入到 group 中 使用 sync 协议，根据分配规则进行分配。

存在的问题：
在大型系统中，一个 topic 可能对应数百个 consumer 实例。这些 consumer 陆续加入到一个空消费组将导致多次的 rebalance；
此外 consumer 实例启动的时间不可控，很有可能超出 coordinator 确定的 rebalance timeout(即 max.poll.interval.ms)，将会再次触发 rebalance，而每次 rebalance 的代价又相当地大，因为很多状态都需要在 rebalance 前被持久化，而在 rebalance 后被重新初始化。

新版本改进：通过延迟进入PreparingRebalance状态减少reblance次数

broker 设计：
broker zk 注册
broker 消息存储：Kafka的消息以二进制的方式紧凑地存储，节省了很大空间 此外消息存在ByteBuffer而不是堆，这样broker进程挂掉时，数据不会丢失，同时避免了gc问题 通过零拷贝和顺序寻址，让消息存储和读取速度都非常快 处理fetch请求的时候通过zero-copy 加快速度。
broker 状态数据：每台机器都保存了相同的状态数据，controller所在的broker ID，集群中所有节点的信息，集群中所有分区的信息
broker 负载均衡：各台broker的partition数量应该均匀，partition Replica分配算法，在Kafka1.1中增加了副本跨路径迁移功能kafka-reassign-partitions.sh，我们可以结合它和监控系统，实现自动化的负载均衡

Kafka 高可用：
Isr：Kafka结合同步复制和异步复制，使用ISR（与Partition Leader保持同步的Replica列表）的方式在确保数据不丢失和吞吐率之间做了平衡。Producer只需把消息发送到Partition Leader，Leader将消息写入本地Log。Follower则从Leader pull数据。Follower在收到该消息向Leader发送ACK。一旦Leader收到了ISR中所有Replica的ACK，该消息就被认为已经commit了，Leader将增加HW并且向Producer发送ACK。这样如果leader挂了，只要Isr中有一个replica存活，就不会丢数据。
Isr 动态更新：Leader会跟踪ISR，如果ISR中一个Follower宕机，或者落后太多，Leader将把它从ISR中移除。
controller 负责 broker 故障检查&&故障转移（fail/recover）
controller 挂掉

幂等性：consumer 拉取到消息先保存，commit 成功后删除缓存数据。
可靠性：首先 kafka 保证了对已提交消息的 at least 保证 sender 有重试机制 producer 业务方在使用 producer 发送消息时，注册回调函数。在 onError 方法中重发消息 consumer 拉取到消息后，处理完毕再 commit，保证 commit 的消息一定被处理完毕。
高性能：partition 提升了并发，zero-copy 顺序写入，消息聚集 batch，页缓存，业务方对 Kafka producer 的优化。增大 producer 数量，ack 配置，batch。
