## 简介

操作系统本质上是运行在计算机上的软件程序，用于管理计算机硬件与软件资源，屏蔽了硬件层的复杂性，为用户提供一个与系统交互的操作界面，是计算机系统的基石。

**内核与外壳**

操作系统分内核与外壳，我们可以把外壳理解成围绕着内核的应用程序，而内核可以理解为能直接操作硬件的程序。内核是连接应用程序和硬件的桥梁，决定着系统的性能和稳定性，是操作系统背后黑盒的核心。应用进程通过系统调用，可间接控制所需的硬件资源（特别是 CPU 及 IO 设备）。

**中断分类**

**外中断**

由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。

**异常**

由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。

**陷入**

在用户程序中使用系统调用。

#### **系统调用**

根据进程访问资源的特点，我们可以把进程在系统上的运行分为用户态和系统态。

我们运行的程序基本都是运行在用户态，如果我们需要调用操作系统提供的内核态级别的子功能（进程，文件，设备，安全等）时，就需要系统调用了。

**用户态 user mode**

用户态运行的进程或可以直接读取用户程序的数据。

**内核态 kernel mode**

可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。

**系统调用按功能分类**

设备管理：完成设备的请求或释放，以及设备启动等功能。

文件管理：完成文件的读、写、创建及删除等功能。

进程控制：完成进程的创建、撤销、阻塞及唤醒等功能。

进程通信：完成进程之间的消息传递或信号传递等功能。

内存管理：完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。

#### 链接

**编译系统**

在 Unix 系统上，由编译器把源文件转换为目标文件：

```
gcc -o hello hello.c
```

这个过程大致如下：

- 预处理阶段：处理以 # 开头的预处理命令。
- 编译阶段：翻译成汇编文件。
- 汇编阶段：将汇编文件翻译成可重定位目标文件。
- 链接阶段：将可重定位目标文件和 printf.o 等单独预编译好的目标文件进行合并，得到最终的可执行目标文件。

**静态链接**

静态链接器以一组可重定位目标文件为输入，生成一个完全链接的可执行目标文件作为输出。链接器主要完成以下两个任务：

- 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。
- 重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。

**静态链接的缺点**

- 生成的可执行文件较大。

- 当静态库更新时整个程序都要重新进行链接。
- 重复代码太多。

**动态链接**

共享库是为了解决静态库的这两个问题而设计的，在 Linux 系统中通常用 .so 后缀来表示，Windows 系统上它们被称为 DLL。它具有以下特点：

- 在给定的文件系统中一个库只有一个文件，所有引用该库的可执行目标文件都共享这个文件，它不会被复制到引用它的可执行文件中；
- 在内存中，一个共享库的 .text 节（已编译程序的机器代码）的一个副本可以被不同的正在运行的进程共享。



## 1.基本特征和功能

#### 特性

- 并发：并发是指宏观上在一段时间内能同时运行多个程序，而并行则指同一时刻能运行多个指令。
  

操作系统通过引入进程和线程，使得程序能够并发运行。并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。

并发是逻辑上的同时发生，指单个 CPU 内，通过 CPU 调度算法，让用户感觉在同时运行多个任务。

- 共享：指系统中的资源可以被多个并发进程共同使用。
  

有两种共享方式：互斥共享和同时共享。互斥共享的资源称为临界资源，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。

- 虚拟：虚拟技术把一个物理实体转换为多个逻辑实体。
  

主要有两种虚拟技术：时分复用技术（多个进程能在同一个处理器上并发执行）和空分复用技术（虚拟内存）。

- 异步：异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。

#### 功能

- 进程管理：进程控制、进程同步、进程通信、死锁处理、处理机调度等。
- 内存管理：内存分配、地址映射、内存保护与共享、虚拟内存等。
- 文件管理：文件存储空间的管理、目录管理、文件读写管理和保护等。
- 设备管理：I/O、缓冲管理、设备分配、设备处理、虛拟设备等。



## 2.进程与线程

#### 进程

操作系统对一个正在运行的程序的一种抽象。进入到内存执行的程序叫作进程。

程序是静态的代码，而进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。

在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。main 线程和多个其他线程同时运行。

进程方便资源的管理和保护。

**进程控制块 PCB**

描述进程的基本信息和运行状态，创建进程和撤销进程都是指对 PCB 的操作。 

**进程状态**

就绪，运行，阻塞（三种进程的基本状态），新建，终止。

就绪和运行可以互相转换，其余不行。就绪进程通过调度算法从而获得 CPU 时间转为运行状态，而运行进程在分配给它的 CPU 时间片用完之后就会转为就绪状态。

阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间。

单核 CPU 下任意时刻只有一个进程处于运行状态。

#### 线程

一个进程实际上可以由多个称为线程的执行单元组成，每个线程都运行在进程的上下文中，它们共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈。所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。

#### 进程和线程的区别

- 进程是资源分配的基本单位。线程不拥有资源，可以访问隶属进程的资源。
- 线程是独立调度的基本单位。在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。
- 创建和撤销进程，和在进行进程切换时，系统开销大于线程。
- 进程通信需要借助进程通信 IPC，而线程间可以通过直接读写同一进程中的数据进行通信。
- 健壮性：多线程程序只要有一个线程死掉，整个进程也死掉了（线程可能会相互影响）。而一个进程死掉并不会对另外一个进程造成影响，因为进程有自己独立的地址空间。

#### 进程线程模型

**内核线程**

内核线程就是内核的分身，一个分身可以处理一件特定事情。这在处理异步事件如异步 IO 时特别有用。内核线程的使用是廉价的，唯一使用的资源就是内核栈和上下文切换时保存寄存器的空间。

**用户线程**

用户线程是完全建立在用户空间的线程库，用户线程的创建、调度、同步和销毁全又库函数在用户空间完成，不需要内核的帮助。因此这种线程是极其低消耗和高效的。

**轻量级进程**

建立在内核之上并由内核支持的用户线程，它是内核线程的高度抽象，每一个轻量级进程都与一个特定的内核线程关联。内核线程只能由内核管理并像普通进程一样被调度。



## 3.进程调度

为了实现最大 CPU 利用率。

#### **批处理系统**

没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间。

**先来先服务 FCFS**

非抢占式的调度算法，按照请求的顺序进行调度。

有利于长作业，但不利于短作业。

**短作业优先 SJF**

非抢占式的调度算法，按估计运行时间最短的顺序进行调度。

长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

**最短剩余时间优先 SRTN**

短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

**高响应比优先 HRRN**

FCFS 和 SJF 的综合平衡。

#### 交互式系统

有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

**时间片轮转 round robin**

将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系。

**优先级调度**

为每个进程分配一个优先级，按优先级进行调度。

为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

**多级反馈队列**

设置了多个队列，每个队列时间片大小都不同。

看成是时间片轮转调度算法和优先级调度算法的结合。

既能使高优先级的作业得到响应又能使短作业迅速完成，因而它是目前被公认的一种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法。

**实时系统**

实时系统要求一个请求在一个确定时间内得到响应。

分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

**线程调度**

分时调度和抢占式调度（优先级）。

#### **完全公平调度器 CFS**

Linux 进程调度，为每个任务分配一定比例的 CPU 处理时间，每个任务分配的具体比例是根据 nice 值来计算的。具有较低 nice 值的任务，会得到更高比例的处理器处理时间。

CFS 调度程序没有直接分配优先级。相反，它通过每个任务的变量 vruntime 以便维护虚拟运行时间，进而记录每个任务运行多久。虚拟运行时间与基于任务优先级的衰减因子有关，更低优先级的任务比更高优先级的任务具有更高衰减速率。对于正常优先级的任务（nice 值为 0），虚拟运行时间与实际物理运行时间是相同的。

假设有两个任务，它们具有相同的 nice 值。一个任务是 I/O 密集型而另一个为 CPU 密集型。通常，I/O 密集型任务在运行很短时间后就会阻塞以便等待更多的 I/O；而 CPU 密集型任务只要有在处理器上运行的机会，就会用完它的时间片。

因此，I/O 密集型任务的虚拟运行时间最终将会小于 CPU 密集型任务的，从而使得 I/O 密集型任务具有更高的优先级。这时，如果 CPU 密集型任务在运行，而 I/O 密集型任务变得有资格可以运行（如该任务所等待的 I/O 已成为可用)，那么 I/O 密集型任务就会抢占 CPU 密集型任务。



## 4.进程同步

**临界区**

对临界资源进行访问的那段代码称为临界区。

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

**同步**

多个进程按一定顺序执行。

避免多个共享关键资源的使用冲突。

**互斥**

多个进程在同一时刻只有一个进程能进入临界区。

#### **信号量 semaphore**

是整型变量，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

down 和 up 操作设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。

**互斥量 mutex**

信号量的取值只能为 0 或者 1，0 表示临界区已经加锁，1 表示临界区解锁。

可以保证公共资源不会被多个线程同时访问。

Java 中的 synchronized 关键词和各种 Lock 都是这种机制。

#### **用信号量实现生产者-消费者问题**

**问题描述**

使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。

```java
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer() {
    while(TRUE) {
        int item = produce_item();
        down(&empty);
        down(&mutex);
        insert_item(item);
        up(&mutex);
        up(&full);
    }
}

void consumer() {
    while(TRUE) {
        down(&full);
        down(&mutex);
        int item = remove_item();
        consume_item(item);
        up(&mutex);
        up(&empty);
    }
}
```

**对 empty 和 full 变量的 P 操作必须在 mutex 的 P 操作之前**

1. 生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。

2. 消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。

**管程**

把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。

管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。

还可以方便实现多线程优先级的比较操作。

**管程的条件变量和 wait()&signal() 来实现同步操作**

条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。

可以使用管程实现生产者-消费者问题。

**协程**

是计算机程序的一类组件，推广了协作式多任务的子程序，允许执行被挂起与被恢复。

**经典同步问题**

生产者-消费者问题

哲学家进餐问题：死锁。设置必须同时拿起左右两根筷子，只有在两个邻居都没有进餐的情况下才允许进餐。

读者-写者问题：允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。用一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。




## 5.进程通信

**管道**

只支持半双工通信，只能在父子或者兄弟进程中使用。

只存在于内存中的文件。

**命名管道 FIFO**

去除了管道只能在有亲缘关系的进程中使用的限制。

以磁盘文件的方式存在，可以实现本机任意两个进程通信。

FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。

**消息队列**

存放在内核中并由消息队列标识符（即队列 ID）标识。其中的消息具有特定的格式以及特定的优先级。进程终止时，消息队列及其内容并不会被删除。

**消息队列相比命名管道的优点**

- 消息队列可以独立于读写进程存在，从而避免了命名管道中同步管道的打开和关闭时可能产生的困难。

- 消息队列避免了命名管道的同步阻塞问题，不需要进程自己提供同步方法。
- 消息队列读进程可以根据消息类型有选择地接收消息，可以实现消息的随机查询，而不像命名管道那样只能默认地以 FIFO 的次序读取接收。
- 消息队列克服了信号量承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。

**信号量**

一个计数器，用于多进程对共享数据的访问，通知接收进程某个事件已经发生。

信号量的意图在于进程间同步，主要用于解决与同步相关的问题并避免竞争条件。若要在进程间传递数据需要结合共享存储。

**共享内存**

多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。

数据不需要在进程之间复制，所以这是最快的一种 IPC。

需要使用信号量用来同步对共享存储的访问。

多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

**套接字**

主要用于在客户端和服务器两台机器之间通过网络进行通信。

套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。

**五种方式总结**

管道：速度慢，容量有限，只有父子进程能通讯    

FIFO：任何进程间都能通讯，但速度慢    

消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题    

信号量：不能传递复杂消息，只能用来同步    

共享内存区：能够很容易控制容量，速度快，但要保持同步



## 6.死锁

多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。

**必要条件**

互斥，占有和请求，不可抢占，循环等待。

#### 处理方法

**鸵鸟策略**

假装根本没发生问题。

因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。

当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。

**死锁检测与恢复**

不试图阻止死锁，而是当检测到死锁发生时，采取抢占、回滚、杀死进程进行恢复。

**死锁检测算法**

每种类型一个资源的死锁检测算法是通过检测有向图是否存在环来实现，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。每种类型多个资源的死锁检测。

**死锁预防**

破坏死锁发生的必要条件。

- 破坏互斥条件：同时进行。

- 破坏占有和请求条件：一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。

- 破坏不可抢占条件

- 破坏循环等待条件：给资源统一编号，进程只能按编号顺序来请求资源。

**死锁避免**

在程序运行时避免发生死锁。

**安全状态**

如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。

安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。

**银行家算法**

银行家算法与死锁检测算法非常类似。也分单个资源和多个资源。

**活锁**

活锁是指进程互相谦让，都释放资源给别的进程，导致资源在进程之间跳动但是进程却一直不执行。

**饥饿**

饥饿是指将低优先级的进程长时间请求不到所需要的资源。但是饥饿中进程最后可以请求到资源，只要不再有高优先级的进程使用资源，这和死锁有所不同。



## 7.内存管理

主要负责内存的分配与回收，另外还有地址转换也就是将逻辑地址转换成相应的物理地址等功能。

#### 虚拟内存

为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。每个程序拥有自己私有的地址空间，这个地址空间被分割成多个块，每一块称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。

内存管理单元 MMU 管理着地址空间和物理内存的转换，其中的页表存储着页（程序地址空间）和页框（物理内存空间）的映射表。一部分存储页面号，一部分存储偏移量。

**通过虚拟地址访问内存的优势**

- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。

- 程序可以使用一系列连续的虚拟地址来访问物理内存中不连续的大内存缓冲区。
- 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。
- 如果直接把物理地址暴露出来的话会带来严重问题，比如可能破坏操作系统并造成操作系统崩溃，以及给同时运行多个程序造成困难。

#### 页面置换算法

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。

页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

**最佳 OPT**

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。

是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

***最近最久未使用 LRU**

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

**最近未使用 NRU**

**最少使用 LFU**

内存内使用越频繁的页面，被保留的时间也相对越长。

**先进先出 FIFO**

该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。

**第二次机会算法**

避免了 FIFO 可能会把经常使用的页面置换出去的问题。

记录 R 位，R 位是 0，页面既老又没有被使用，可以立刻置换掉。

R 位是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。

**时钟**

时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。

解决第二次机会算法在链表中移动页面降低效率的问题。

#### 分页与分段

内存中都是不连续的，每个页和段中的内存是连续的。都是为了提高内存利用率，较少内存碎片。

**分页**

将地址空间划分成固定大小的页，每一页再与内存进行映射。

页式管理通过页表对应逻辑地址和物理地址。

**分段**

分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。

段是有实际意义的，每个段定义了一组逻辑信息。

**段页式**

程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。

这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。

段与段之间以及段的内部的都是离散的。

**分页与分段的比较**

- 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。
- 地址空间的维度：分页是一维地址空间，分段是二维的。
- 大小是否可以改变：页的大小固定且由系统决定。段的大小可以动态改变，取决于我们当前运行的程序。
- 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

**块式管理**

连续分配。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块。会产生浪费的内存碎片。

**快表 TLB**

在分页基础之上引入了快表来加速虚拟地址到物理地址的转换，提高内存的时间性能。理解为特殊的高速缓冲存储器，加速查找并提高指令执行速度。

和 Redis 相似。

使用快表之后的地址转换流程：

根据虚拟地址中的页号查快表。
如果该页在快表中，直接从快表中读取相应的物理地址。
如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中。
当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。

**多级页表**

为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中，提高内存的空间性能。多级页表属于时间换空间的典型场景。

**局部性原理**

在某个较短的时间段内，程序执行局限于某一小部分，程序访问的存储空间也局限于某个区域。

局部性原理是虚拟内存技术的基础。时间换空间的策略，用 CPU 的计算时间，页的调入调出花费的时间，换来了一个虚拟的更大的空间来支持程序的运行。

时间局部性是通过将近来使用的指令和数据保存到高速缓存存储器中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是建立了内存-外存的两级存储器的结构，利用局部性原理实现髙速缓存。

局部性原理既适用于程序结构，也适用于数据结构，是非常重要的一个概念。

**时间局部性**

如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。

**空间局部性**

一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。




## 8.磁盘

#### 磁盘调度算法

读写一个磁盘块的时间的影响因素有：

- 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）
- 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）
- 实际的数据传输时间

其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。

**先来先服务 FCFS**

按照磁盘请求的顺序进行调度。

优点是公平和简单。

缺点是未对寻道做任何优化，使平均寻道时间可能较长。

**最短寻道时间优先 SSTF**

优先调度与当前磁头所在磁道距离最近的磁道。

虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。

**电梯算法 SCAN**

又叫扫描算法。和电梯的运行过程类似，总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。

因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。